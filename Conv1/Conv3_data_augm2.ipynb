{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mitbih_test.csv', 'mitbih_test.csv.zip', 'mitbih_train.csv', 'mitbih_train.csv.zip', 'ptbdb_abnormal.csv', 'ptbdb_abnormal.csv.zip', 'ptbdb_normal.csv', 'ptbdb_normal.csv.zip']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed0\n",
    "# For example, here's several helpful packages to load in \n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import pickle\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Softmax, Add, Flatten, Activation , Dropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"/UFS/F2 - Copia/database\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/UFS/F2 - Copia/database/mitbih_train.csv\", header=None)\n",
    "test_df = pd.read_csv(\"/UFS/F2 - Copia/database/mitbih_test.csv\", header=None)\n",
    "#df = pd.concat([df, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "494fc8a26ba40beb73fc1a4f7b219b213fb7705e",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.154412</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.085784</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.356808</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.977941  0.926471  0.681373  0.245098  0.154412  0.191176  0.151961   \n",
       "1  0.960114  0.863248  0.461538  0.196581  0.094017  0.125356  0.099715   \n",
       "2  1.000000  0.659459  0.186486  0.070270  0.070270  0.059459  0.056757   \n",
       "3  0.925414  0.665746  0.541436  0.276243  0.196133  0.077348  0.071823   \n",
       "4  0.967136  1.000000  0.830986  0.586854  0.356808  0.248826  0.145540   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.085784  0.058824  0.049020  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.088319  0.074074  0.082621  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.043243  0.054054  0.045946  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.060773  0.066298  0.058011  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.089202  0.117371  0.150235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5281cb19f54f3bd379f875c24ae52b3b15fcafaf",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87554 entries, 0 to 87553\n",
      "Columns: 188 entries, 0 to 187\n",
      "dtypes: float64(188)\n",
      "memory usage: 125.6 MB\n",
      "17510\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "dataset_row = train_df.shape[0]\n",
    "dataset_size= int(dataset_row/5)\n",
    "print(dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    72471\n",
      "4     6431\n",
      "2     5788\n",
      "1     2223\n",
      "3      641\n",
      "Name: 187, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df[187]=train_df[187].astype(int)\n",
    "equilibre= train_df[187].value_counts()\n",
    "print(equilibre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0fac0fb658ea34b48055838b4ad85078e883360d",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_df[187].value_counts()\n",
    "equilibre = train_df[187].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "plt.pie(equilibre, labels=['n','q','v','s','f'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "k=72471\n",
    "#dataset_size= 2000\n",
    "df_1=train_df[train_df[187]==1]\n",
    "df_2=train_df[train_df[187]==2]\n",
    "df_3=train_df[train_df[187]==3]\n",
    "df_4=train_df[train_df[187]==4]\n",
    "df_0=(train_df[train_df[187]==0]).sample(n=dataset_size,random_state=42)\n",
    "\n",
    "df_1_upsample=resample(df_1,replace=True,n_samples=dataset_size,random_state=123)\n",
    "df_2_upsample=resample(df_2,replace=True,n_samples=dataset_size,random_state=124)\n",
    "df_3_upsample=resample(df_3,replace=True,n_samples=dataset_size,random_state=125)\n",
    "df_4_upsample=resample(df_4,replace=True,n_samples=dataset_size,random_state=126)\n",
    "\n",
    "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17510\n",
      "1    17510\n",
      "2    17510\n",
      "3    17510\n",
      "4    17510\n",
      "Name: 187, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "equilibre=train_df[187].value_counts()\n",
    "print(equilibre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(equilibre, labels=['n','q','v','s','f'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "147b7604bd8a389d7f6aa111f38ae308af7c4eb7",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "M = train_df.values\n",
    "X = M[:, :-1]\n",
    "y = M[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "504d95532114efa4cc581d80bf02159c3ce519c6",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#del train_df\n",
    "#del test_df\n",
    "#del M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(signal):\n",
    "    noise=np.random.normal(0,0.5,186)\n",
    "    return (signal+noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tempo=c.iloc[0,:186]\n",
    "#bruiter=add_gaussian_noise(tempo)\n",
    "\n",
    "#plt.subplot(2,1,1)\n",
    "#plt.plot(c.iloc[0,:186])\n",
    "\n",
    "#plt.subplot(2,1,2)\n",
    "#plt.plot(bruiter)\n",
    "\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train_df[187]\n",
    "target_test=test_df[187]\n",
    "y_train=to_categorical(target_train)\n",
    "y_test=to_categorical(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df.iloc[:,:186].values\n",
    "X_test=test_df.iloc[:,:186].values\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i,:186]= add_gaussian_noise(X_train[i,:186])\n",
    "X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
    "X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train_df[187]\n",
    "target_test=test_df[187]\n",
    "y_train=to_categorical(target_train)\n",
    "y_test=to_categorical(target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c269ab78773e4b5a960a5e55d2b48c53d5f9c446"
   },
   "source": [
    "# Data augmentation\n",
    "\n",
    "To train properly the model, we sould have to augment all data to the same level. Nevertheless, for a first try, we will just augment the smallest class to the same level as class 1. With that we will be able to have a test set of around 5x800 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c42605d020fd51885437f4af3cf10cebbeafc9bb"
   },
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "16c106c2702045790367fc49d7223560fc613d75",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (87550, 186, 1)\n",
      "y_train (87550, 5)\n",
      "X_test (21892, 186, 1)\n",
      "y_test (21892, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4de23b85abe34a726eab268171da0e827bafa35"
   },
   "source": [
    "# Model\n",
    "\n",
    "Now let's re-create the model from the ArXiv Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "fb0dc9775ddfa761c0ad948d59020fcbd2681c57",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_obs, feature, depth = X_train.shape\n",
    "batch_size = 1500\n",
    "#batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "e70fab0b07290e042ba9cd7c6cba37462a457b03",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 186, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 182, 32)      192         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 182, 32)      5152        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 182, 32)      0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 182, 32)      5152        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 182, 32)      0           ['conv1d_2[0][0]',               \n",
      "                                                                  'conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 182, 32)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 89, 32)       0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 89, 32)       5152        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 89, 32)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 89, 32)       5152        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 89, 32)       0           ['conv1d_4[0][0]',               \n",
      "                                                                  'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 89, 32)       0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 43, 32)      0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 43, 32)       5152        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 43, 32)       0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 43, 32)       5152        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 43, 32)       0           ['conv1d_6[0][0]',               \n",
      "                                                                  'max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 43, 32)       0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 20, 32)      0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 20, 32)       5152        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 20, 32)       0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 20, 32)       5152        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 20, 32)       0           ['conv1d_8[0][0]',               \n",
      "                                                                  'max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 20, 32)       0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 8, 32)       0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 8, 32)        5152        ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 8, 32)        0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 8, 32)        5152        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 32)        0           ['conv1d_10[0][0]',              \n",
      "                                                                  'max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 8, 32)        0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 2, 32)       0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2, 32)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           2080        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 32)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           1056        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5)            165         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 5)            0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 55,013\n",
      "Trainable params: 55,013\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inp = Input(shape=(feature, depth))\n",
    "C = Conv1D(filters=32, kernel_size=5, strides=1)(inp)\n",
    "C11 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(C)\n",
    "A11 = Activation(\"relu\")(C11)\n",
    "C12 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A11)\n",
    "S11 = Add()([C12, C])\n",
    "A12 = Activation(\"relu\")(S11)\n",
    "M11 = MaxPooling1D(pool_size=5, strides=2)(A12)\n",
    "\n",
    "\n",
    "C21 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M11)\n",
    "A21 = Activation(\"relu\")(C21)\n",
    "C22 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A21)\n",
    "S21 = Add()([C22, M11])\n",
    "A22 = Activation(\"relu\")(S21)\n",
    "M21 = MaxPooling1D(pool_size=5, strides=2)(A22)\n",
    "\n",
    "\n",
    "C31 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M21)\n",
    "A31 = Activation(\"relu\")(C31)\n",
    "C32 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A31)\n",
    "S31 = Add()([C32, M21])\n",
    "A32 = Activation(\"relu\")(S31)\n",
    "M31 = MaxPooling1D(pool_size=5, strides=2)(A32)\n",
    "\n",
    "\n",
    "C41 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M31)\n",
    "A41 = Activation(\"relu\")(C41)\n",
    "C42 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A41)\n",
    "S41 = Add()([C42, M31])\n",
    "A42 = Activation(\"relu\")(S41)\n",
    "M41 = MaxPooling1D(pool_size=5, strides=2)(A42)\n",
    "\n",
    "\n",
    "C51 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M41)\n",
    "A51 = Activation(\"relu\")(C51)\n",
    "C52 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A51)\n",
    "S51 = Add()([C52, M41])\n",
    "A52 = Activation(\"relu\")(S51)\n",
    "M51 = MaxPooling1D(pool_size=5, strides=2)(A52)\n",
    "\n",
    "M52 = (Dropout(0.25))(M51)\n",
    "\n",
    "F1 = Flatten()(M52)\n",
    "\n",
    "D1 = Dense(32)(F1)\n",
    "A6 = Activation(\"relu\")(D1)\n",
    "D2 = Dense(32)(A6)\n",
    "D3 = Dense(5)(D2)\n",
    "A7 = Softmax()(D3)\n",
    "\n",
    "model = Model(inputs=inp, outputs=A7)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "fdc0d8aa8475330af8d8e652d0b9ce214da66956",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    k = 0.75\n",
    "    t = n_obs//(10000 * batch_size)  # every epoch we do n_obs/batch_size iteration\n",
    "    lrate = initial_lrate * math.exp(-k*t)\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(exp_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "abcd2f0e8488c8f3b33cd6ed9ca7fd60fa44404b",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate = 0.01, beta_1 = 0.9, beta_2 = 0.99)\n",
    "#adam = Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "812e637ae56f6a4be9c8e98d3b501cfb11ef78cb",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "1e6ef643f6a55ab5b3c1b46126832c3ac45a6a2b",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: categorical_crossentropy\n",
      "Epoch number: 75\n",
      "fitting with batch size: 20\n",
      "Epoch 1/75\n",
      "4378/4378 - 76s - loss: 0.9509 - accuracy: 0.6359 - val_loss: 0.8852 - val_accuracy: 0.6629 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 2/75\n",
      "4378/4378 - 71s - loss: 0.8597 - accuracy: 0.6765 - val_loss: 0.7773 - val_accuracy: 0.7514 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 3/75\n",
      "4378/4378 - 71s - loss: 0.8331 - accuracy: 0.6855 - val_loss: 0.7742 - val_accuracy: 0.6989 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 4/75\n",
      "4378/4378 - 71s - loss: 0.8204 - accuracy: 0.6905 - val_loss: 0.7686 - val_accuracy: 0.7517 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 5/75\n",
      "4378/4378 - 71s - loss: 0.8106 - accuracy: 0.6945 - val_loss: 0.8149 - val_accuracy: 0.6986 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 6/75\n",
      "4378/4378 - 71s - loss: 0.8014 - accuracy: 0.6974 - val_loss: 0.8385 - val_accuracy: 0.6750 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 7/75\n",
      "4378/4378 - 71s - loss: 0.7957 - accuracy: 0.6990 - val_loss: 0.7816 - val_accuracy: 0.7267 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 8/75\n",
      "4378/4378 - 71s - loss: 0.7870 - accuracy: 0.7049 - val_loss: 0.7617 - val_accuracy: 0.7442 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 9/75\n",
      "4378/4378 - 71s - loss: 0.7825 - accuracy: 0.7066 - val_loss: 0.8300 - val_accuracy: 0.6822 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 10/75\n",
      "4378/4378 - 71s - loss: 0.7781 - accuracy: 0.7070 - val_loss: 0.7023 - val_accuracy: 0.7483 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 11/75\n",
      "4378/4378 - 71s - loss: 0.7747 - accuracy: 0.7100 - val_loss: 0.7710 - val_accuracy: 0.7250 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 12/75\n",
      "4378/4378 - 71s - loss: 0.7720 - accuracy: 0.7114 - val_loss: 0.7523 - val_accuracy: 0.7190 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 13/75\n",
      "4378/4378 - 71s - loss: 0.7645 - accuracy: 0.7127 - val_loss: 0.7336 - val_accuracy: 0.7491 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 14/75\n",
      "4378/4378 - 70s - loss: 0.7631 - accuracy: 0.7130 - val_loss: 0.7857 - val_accuracy: 0.7254 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 15/75\n",
      "4378/4378 - 71s - loss: 0.7636 - accuracy: 0.7139 - val_loss: 0.7622 - val_accuracy: 0.7585 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 16/75\n",
      "4378/4378 - 71s - loss: 0.7594 - accuracy: 0.7153 - val_loss: 0.7860 - val_accuracy: 0.7339 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 17/75\n",
      "4378/4378 - 71s - loss: 0.7563 - accuracy: 0.7165 - val_loss: 0.7453 - val_accuracy: 0.7193 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 18/75\n",
      "4378/4378 - 71s - loss: 0.7536 - accuracy: 0.7162 - val_loss: 0.7257 - val_accuracy: 0.7293 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 19/75\n",
      "4378/4378 - 71s - loss: 0.7525 - accuracy: 0.7164 - val_loss: 0.7670 - val_accuracy: 0.7128 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 20/75\n",
      "4378/4378 - 71s - loss: 0.7480 - accuracy: 0.7206 - val_loss: 0.7533 - val_accuracy: 0.7304 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 21/75\n",
      "4378/4378 - 71s - loss: 0.7478 - accuracy: 0.7192 - val_loss: 0.7338 - val_accuracy: 0.7389 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 22/75\n",
      "4378/4378 - 71s - loss: 0.7482 - accuracy: 0.7191 - val_loss: 0.6270 - val_accuracy: 0.8039 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 23/75\n",
      "4378/4378 - 71s - loss: 0.7453 - accuracy: 0.7202 - val_loss: 0.7906 - val_accuracy: 0.7305 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 24/75\n",
      "4378/4378 - 71s - loss: 0.7444 - accuracy: 0.7209 - val_loss: 0.6770 - val_accuracy: 0.7455 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 25/75\n",
      "4378/4378 - 71s - loss: 0.7419 - accuracy: 0.7216 - val_loss: 0.8355 - val_accuracy: 0.7183 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 26/75\n",
      "4378/4378 - 72s - loss: 0.7406 - accuracy: 0.7219 - val_loss: 0.7428 - val_accuracy: 0.7579 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 27/75\n",
      "4378/4378 - 71s - loss: 0.7399 - accuracy: 0.7228 - val_loss: 0.7571 - val_accuracy: 0.7680 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 28/75\n",
      "4378/4378 - 71s - loss: 0.7389 - accuracy: 0.7217 - val_loss: 0.7342 - val_accuracy: 0.7440 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 29/75\n",
      "4378/4378 - 71s - loss: 0.7410 - accuracy: 0.7218 - val_loss: 0.6528 - val_accuracy: 0.8194 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 30/75\n",
      "4378/4378 - 71s - loss: 0.7374 - accuracy: 0.7233 - val_loss: 0.6837 - val_accuracy: 0.7774 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 31/75\n",
      "4378/4378 - 71s - loss: 0.7349 - accuracy: 0.7252 - val_loss: 0.6736 - val_accuracy: 0.7634 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 32/75\n",
      "4378/4378 - 70s - loss: 0.7369 - accuracy: 0.7224 - val_loss: 0.7918 - val_accuracy: 0.7294 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 33/75\n",
      "4378/4378 - 71s - loss: 0.7331 - accuracy: 0.7239 - val_loss: 0.7239 - val_accuracy: 0.7869 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 34/75\n",
      "4378/4378 - 71s - loss: 0.7326 - accuracy: 0.7253 - val_loss: 0.8259 - val_accuracy: 0.7059 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 35/75\n",
      "4378/4378 - 71s - loss: 0.7327 - accuracy: 0.7242 - val_loss: 0.7430 - val_accuracy: 0.7684 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 36/75\n",
      "4378/4378 - 71s - loss: 0.7320 - accuracy: 0.7271 - val_loss: 0.7533 - val_accuracy: 0.7521 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 37/75\n",
      "4378/4378 - 71s - loss: 0.7309 - accuracy: 0.7266 - val_loss: 0.7393 - val_accuracy: 0.7615 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 38/75\n",
      "4378/4378 - 71s - loss: 0.7301 - accuracy: 0.7271 - val_loss: 0.7685 - val_accuracy: 0.7360 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 39/75\n",
      "4378/4378 - 71s - loss: 0.7304 - accuracy: 0.7265 - val_loss: 0.8535 - val_accuracy: 0.6883 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 40/75\n",
      "4378/4378 - 71s - loss: 0.7294 - accuracy: 0.7277 - val_loss: 0.8441 - val_accuracy: 0.6920 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 41/75\n",
      "4378/4378 - 71s - loss: 0.7304 - accuracy: 0.7283 - val_loss: 0.7993 - val_accuracy: 0.7325 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 42/75\n",
      "4378/4378 - 71s - loss: 0.7285 - accuracy: 0.7287 - val_loss: 0.6489 - val_accuracy: 0.7913 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 43/75\n",
      "4378/4378 - 71s - loss: 0.7271 - accuracy: 0.7280 - val_loss: 0.6747 - val_accuracy: 0.7583 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 44/75\n",
      "4378/4378 - 71s - loss: 0.7263 - accuracy: 0.7274 - val_loss: 0.7234 - val_accuracy: 0.7766 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 45/75\n",
      "4378/4378 - 71s - loss: 0.7255 - accuracy: 0.7285 - val_loss: 0.7333 - val_accuracy: 0.7475 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 46/75\n",
      "4378/4378 - 72s - loss: 0.7265 - accuracy: 0.7281 - val_loss: 0.7672 - val_accuracy: 0.7333 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 47/75\n",
      "4378/4378 - 71s - loss: 0.7234 - accuracy: 0.7291 - val_loss: 0.7096 - val_accuracy: 0.7637 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 48/75\n",
      "4378/4378 - 71s - loss: 0.7241 - accuracy: 0.7293 - val_loss: 0.6560 - val_accuracy: 0.8185 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 49/75\n",
      "4378/4378 - 71s - loss: 0.7243 - accuracy: 0.7290 - val_loss: 0.6348 - val_accuracy: 0.7783 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 50/75\n",
      "4378/4378 - 71s - loss: 0.7258 - accuracy: 0.7282 - val_loss: 0.6555 - val_accuracy: 0.7977 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 51/75\n",
      "4378/4378 - 71s - loss: 0.7215 - accuracy: 0.7304 - val_loss: 0.7384 - val_accuracy: 0.7250 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 52/75\n",
      "4378/4378 - 71s - loss: 0.7205 - accuracy: 0.7287 - val_loss: 0.7250 - val_accuracy: 0.7689 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 53/75\n",
      "4378/4378 - 71s - loss: 0.7229 - accuracy: 0.7298 - val_loss: 0.7636 - val_accuracy: 0.7525 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 54/75\n",
      "4378/4378 - 71s - loss: 0.7206 - accuracy: 0.7300 - val_loss: 0.7587 - val_accuracy: 0.7424 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 55/75\n",
      "4378/4378 - 70s - loss: 0.7229 - accuracy: 0.7292 - val_loss: 0.7627 - val_accuracy: 0.7386 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 56/75\n",
      "4378/4378 - 71s - loss: 0.7244 - accuracy: 0.7291 - val_loss: 0.8740 - val_accuracy: 0.6782 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 57/75\n",
      "4378/4378 - 71s - loss: 0.7265 - accuracy: 0.7273 - val_loss: 0.7626 - val_accuracy: 0.7384 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 58/75\n",
      "4378/4378 - 71s - loss: 0.7256 - accuracy: 0.7287 - val_loss: 0.7789 - val_accuracy: 0.7164 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 59/75\n",
      "4378/4378 - 70s - loss: 0.7293 - accuracy: 0.7282 - val_loss: 0.7521 - val_accuracy: 0.7211 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 60/75\n",
      "4378/4378 - 71s - loss: 0.7309 - accuracy: 0.7271 - val_loss: 0.8087 - val_accuracy: 0.7443 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 61/75\n",
      "4378/4378 - 71s - loss: 0.7296 - accuracy: 0.7268 - val_loss: 0.7674 - val_accuracy: 0.7484 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 62/75\n",
      "4378/4378 - 71s - loss: 0.7239 - accuracy: 0.7275 - val_loss: 0.7438 - val_accuracy: 0.7381 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 63/75\n",
      "4378/4378 - 71s - loss: 0.7233 - accuracy: 0.7304 - val_loss: 0.7210 - val_accuracy: 0.7821 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 64/75\n",
      "4378/4378 - 71s - loss: 0.7255 - accuracy: 0.7290 - val_loss: 0.7409 - val_accuracy: 0.7269 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 65/75\n",
      "4378/4378 - 71s - loss: 0.7277 - accuracy: 0.7283 - val_loss: 0.6947 - val_accuracy: 0.7699 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 66/75\n",
      "4378/4378 - 71s - loss: 0.7254 - accuracy: 0.7296 - val_loss: 0.7568 - val_accuracy: 0.7520 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 67/75\n",
      "4378/4378 - 71s - loss: 0.7282 - accuracy: 0.7290 - val_loss: 0.7286 - val_accuracy: 0.7430 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 68/75\n",
      "4378/4378 - 71s - loss: 0.7240 - accuracy: 0.7281 - val_loss: 0.8682 - val_accuracy: 0.6640 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 69/75\n",
      "4378/4378 - 71s - loss: 0.7271 - accuracy: 0.7287 - val_loss: 0.7059 - val_accuracy: 0.7506 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 70/75\n",
      "4378/4378 - 71s - loss: 0.7279 - accuracy: 0.7284 - val_loss: 0.7953 - val_accuracy: 0.7304 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 71/75\n",
      "4378/4378 - 71s - loss: 0.7311 - accuracy: 0.7269 - val_loss: 0.7696 - val_accuracy: 0.7326 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 72/75\n",
      "4378/4378 - 71s - loss: 0.7310 - accuracy: 0.7283 - val_loss: 0.7379 - val_accuracy: 0.7426 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 73/75\n",
      "4378/4378 - 71s - loss: 0.7289 - accuracy: 0.7277 - val_loss: 0.7102 - val_accuracy: 0.7663 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 74/75\n",
      "4378/4378 - 71s - loss: 0.7248 - accuracy: 0.7305 - val_loss: 0.7691 - val_accuracy: 0.7827 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 75/75\n",
      "4378/4378 - 71s - loss: 0.7333 - accuracy: 0.7272 - val_loss: 0.7524 - val_accuracy: 0.7375 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/75\n",
      "876/876 - 20s - loss: 0.6752 - accuracy: 0.7472 - val_loss: 0.7724 - val_accuracy: 0.7321 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 2/75\n",
      "876/876 - 17s - loss: 0.6627 - accuracy: 0.7518 - val_loss: 0.6993 - val_accuracy: 0.7603 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 3/75\n",
      "876/876 - 17s - loss: 0.6588 - accuracy: 0.7526 - val_loss: 0.6401 - val_accuracy: 0.7976 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 4/75\n",
      "876/876 - 17s - loss: 0.6514 - accuracy: 0.7564 - val_loss: 0.7059 - val_accuracy: 0.7588 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 5/75\n",
      "876/876 - 17s - loss: 0.6522 - accuracy: 0.7560 - val_loss: 0.7526 - val_accuracy: 0.7293 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 6/75\n",
      "876/876 - 17s - loss: 0.6544 - accuracy: 0.7560 - val_loss: 0.6707 - val_accuracy: 0.7820 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 7/75\n",
      "876/876 - 17s - loss: 0.6423 - accuracy: 0.7585 - val_loss: 0.6703 - val_accuracy: 0.7822 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 8/75\n",
      "876/876 - 17s - loss: 0.6435 - accuracy: 0.7580 - val_loss: 0.7019 - val_accuracy: 0.7629 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 9/75\n",
      "876/876 - 17s - loss: 0.6379 - accuracy: 0.7606 - val_loss: 0.6738 - val_accuracy: 0.7849 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 10/75\n",
      "876/876 - 17s - loss: 0.6405 - accuracy: 0.7609 - val_loss: 0.7475 - val_accuracy: 0.7288 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 11/75\n",
      "876/876 - 17s - loss: 0.6366 - accuracy: 0.7610 - val_loss: 0.7133 - val_accuracy: 0.7548 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 12/75\n",
      "876/876 - 17s - loss: 0.6593 - accuracy: 0.7631 - val_loss: 0.7034 - val_accuracy: 0.7443 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 13/75\n",
      "876/876 - 17s - loss: 0.6316 - accuracy: 0.7625 - val_loss: 0.7203 - val_accuracy: 0.7491 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 14/75\n",
      "876/876 - 17s - loss: 0.6295 - accuracy: 0.7649 - val_loss: 0.6731 - val_accuracy: 0.7851 - lr: 0.0010 - 17s/epoch - 19ms/step\n",
      "Epoch 15/75\n",
      "876/876 - 17s - loss: 0.6283 - accuracy: 0.7625 - val_loss: 0.7029 - val_accuracy: 0.7551 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 16/75\n",
      "876/876 - 17s - loss: 0.6257 - accuracy: 0.7651 - val_loss: 0.7221 - val_accuracy: 0.7578 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 17/75\n",
      "876/876 - 17s - loss: 0.6233 - accuracy: 0.7665 - val_loss: 0.6652 - val_accuracy: 0.7757 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 18/75\n",
      "876/876 - 17s - loss: 0.6256 - accuracy: 0.7629 - val_loss: 0.7238 - val_accuracy: 0.7592 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 19/75\n",
      "876/876 - 17s - loss: 0.6197 - accuracy: 0.7667 - val_loss: 0.6536 - val_accuracy: 0.7803 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 20/75\n",
      "876/876 - 17s - loss: 0.6176 - accuracy: 0.7677 - val_loss: 0.7004 - val_accuracy: 0.7720 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 21/75\n",
      "876/876 - 17s - loss: 0.6194 - accuracy: 0.7652 - val_loss: 0.6696 - val_accuracy: 0.7712 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 22/75\n",
      "876/876 - 17s - loss: 0.6153 - accuracy: 0.7682 - val_loss: 0.6510 - val_accuracy: 0.7758 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 23/75\n",
      "876/876 - 17s - loss: 0.6129 - accuracy: 0.7686 - val_loss: 0.7317 - val_accuracy: 0.7544 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 24/75\n",
      "876/876 - 17s - loss: 0.6144 - accuracy: 0.7695 - val_loss: 0.5879 - val_accuracy: 0.8170 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 25/75\n",
      "876/876 - 17s - loss: 0.6120 - accuracy: 0.7703 - val_loss: 0.6078 - val_accuracy: 0.7994 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 26/75\n",
      "876/876 - 17s - loss: 0.6107 - accuracy: 0.7717 - val_loss: 0.6967 - val_accuracy: 0.7518 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 27/75\n",
      "876/876 - 17s - loss: 0.6072 - accuracy: 0.7719 - val_loss: 0.6482 - val_accuracy: 0.7839 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 28/75\n",
      "876/876 - 17s - loss: 0.6108 - accuracy: 0.7705 - val_loss: 0.6606 - val_accuracy: 0.7743 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 29/75\n",
      "876/876 - 17s - loss: 0.6061 - accuracy: 0.7726 - val_loss: 0.7103 - val_accuracy: 0.7648 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 30/75\n",
      "876/876 - 17s - loss: 0.6061 - accuracy: 0.7713 - val_loss: 0.6602 - val_accuracy: 0.7855 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 31/75\n",
      "876/876 - 17s - loss: 0.6034 - accuracy: 0.7728 - val_loss: 0.7053 - val_accuracy: 0.7548 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 32/75\n",
      "876/876 - 17s - loss: 0.6038 - accuracy: 0.7721 - val_loss: 0.6506 - val_accuracy: 0.7769 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 33/75\n",
      "876/876 - 17s - loss: 0.6042 - accuracy: 0.7716 - val_loss: 0.7423 - val_accuracy: 0.7377 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 34/75\n",
      "876/876 - 17s - loss: 0.6002 - accuracy: 0.7735 - val_loss: 0.7376 - val_accuracy: 0.7513 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 35/75\n",
      "876/876 - 17s - loss: 0.6001 - accuracy: 0.7757 - val_loss: 0.6726 - val_accuracy: 0.7642 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 36/75\n",
      "876/876 - 17s - loss: 0.5972 - accuracy: 0.7767 - val_loss: 0.6510 - val_accuracy: 0.7838 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 37/75\n",
      "876/876 - 17s - loss: 0.5963 - accuracy: 0.7766 - val_loss: 0.6951 - val_accuracy: 0.7605 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 38/75\n",
      "876/876 - 17s - loss: 0.5949 - accuracy: 0.7758 - val_loss: 0.6953 - val_accuracy: 0.7388 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 39/75\n",
      "876/876 - 18s - loss: 0.5979 - accuracy: 0.7754 - val_loss: 0.6668 - val_accuracy: 0.7635 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 40/75\n",
      "876/876 - 17s - loss: 0.5930 - accuracy: 0.7771 - val_loss: 0.6874 - val_accuracy: 0.7650 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 41/75\n",
      "876/876 - 17s - loss: 0.5962 - accuracy: 0.7754 - val_loss: 0.6623 - val_accuracy: 0.7717 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 42/75\n",
      "876/876 - 17s - loss: 0.5883 - accuracy: 0.7784 - val_loss: 0.7259 - val_accuracy: 0.7489 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 43/75\n",
      "876/876 - 17s - loss: 0.5939 - accuracy: 0.7764 - val_loss: 0.6824 - val_accuracy: 0.7492 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 44/75\n",
      "876/876 - 17s - loss: 0.6051 - accuracy: 0.7745 - val_loss: 0.6110 - val_accuracy: 0.8044 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 45/75\n",
      "876/876 - 17s - loss: 0.5894 - accuracy: 0.7788 - val_loss: 0.7240 - val_accuracy: 0.7466 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 46/75\n",
      "876/876 - 17s - loss: 0.5896 - accuracy: 0.7776 - val_loss: 0.6858 - val_accuracy: 0.7733 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 47/75\n",
      "876/876 - 17s - loss: 0.5892 - accuracy: 0.7784 - val_loss: 0.6704 - val_accuracy: 0.7593 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 48/75\n",
      "876/876 - 17s - loss: 0.5858 - accuracy: 0.7789 - val_loss: 0.6437 - val_accuracy: 0.7818 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 49/75\n",
      "876/876 - 17s - loss: 0.5857 - accuracy: 0.7801 - val_loss: 0.7473 - val_accuracy: 0.7387 - lr: 0.0010 - 17s/epoch - 19ms/step\n",
      "Epoch 50/75\n",
      "876/876 - 17s - loss: 0.5837 - accuracy: 0.7808 - val_loss: 0.6154 - val_accuracy: 0.7890 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 51/75\n",
      "876/876 - 17s - loss: 0.5844 - accuracy: 0.7805 - val_loss: 0.6419 - val_accuracy: 0.7708 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 52/75\n",
      "876/876 - 17s - loss: 0.5831 - accuracy: 0.7808 - val_loss: 0.6363 - val_accuracy: 0.7924 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 53/75\n",
      "876/876 - 17s - loss: 0.5793 - accuracy: 0.7821 - val_loss: 0.6369 - val_accuracy: 0.7740 - lr: 0.0010 - 17s/epoch - 19ms/step\n",
      "Epoch 54/75\n",
      "876/876 - 17s - loss: 0.5797 - accuracy: 0.7819 - val_loss: 0.7385 - val_accuracy: 0.7337 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 55/75\n",
      "876/876 - 17s - loss: 0.5837 - accuracy: 0.7807 - val_loss: 0.7627 - val_accuracy: 0.7124 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 56/75\n",
      "876/876 - 17s - loss: 0.5775 - accuracy: 0.7831 - val_loss: 0.6325 - val_accuracy: 0.7755 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 57/75\n",
      "876/876 - 17s - loss: 0.5766 - accuracy: 0.7827 - val_loss: 0.6531 - val_accuracy: 0.7559 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 58/75\n",
      "876/876 - 17s - loss: 0.5759 - accuracy: 0.7837 - val_loss: 0.6544 - val_accuracy: 0.7729 - lr: 0.0010 - 17s/epoch - 19ms/step\n",
      "Epoch 59/75\n",
      "876/876 - 17s - loss: 0.5765 - accuracy: 0.7827 - val_loss: 0.7243 - val_accuracy: 0.7550 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 60/75\n",
      "876/876 - 17s - loss: 0.5744 - accuracy: 0.7841 - val_loss: 0.6993 - val_accuracy: 0.7488 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 61/75\n",
      "876/876 - 17s - loss: 0.5764 - accuracy: 0.7833 - val_loss: 0.6832 - val_accuracy: 0.7457 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 62/75\n",
      "876/876 - 17s - loss: 0.5741 - accuracy: 0.7847 - val_loss: 0.6121 - val_accuracy: 0.7911 - lr: 0.0010 - 17s/epoch - 19ms/step\n",
      "Epoch 63/75\n",
      "876/876 - 17s - loss: 0.5751 - accuracy: 0.7837 - val_loss: 0.6848 - val_accuracy: 0.7571 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 64/75\n",
      "876/876 - 17s - loss: 0.5725 - accuracy: 0.7845 - val_loss: 0.6325 - val_accuracy: 0.7690 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 65/75\n",
      "876/876 - 17s - loss: 0.5736 - accuracy: 0.7848 - val_loss: 0.6362 - val_accuracy: 0.7831 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 66/75\n",
      "876/876 - 17s - loss: 0.5840 - accuracy: 0.7843 - val_loss: 0.6461 - val_accuracy: 0.7811 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 67/75\n",
      "876/876 - 17s - loss: 0.5739 - accuracy: 0.7837 - val_loss: 0.7476 - val_accuracy: 0.7217 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 68/75\n",
      "876/876 - 17s - loss: 0.5732 - accuracy: 0.7854 - val_loss: 0.6821 - val_accuracy: 0.7483 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 69/75\n",
      "876/876 - 18s - loss: 0.5763 - accuracy: 0.7827 - val_loss: 0.6741 - val_accuracy: 0.7607 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 70/75\n",
      "876/876 - 17s - loss: 0.5680 - accuracy: 0.7854 - val_loss: 0.6436 - val_accuracy: 0.7554 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 71/75\n",
      "876/876 - 17s - loss: 0.5665 - accuracy: 0.7869 - val_loss: 0.6652 - val_accuracy: 0.7560 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 72/75\n",
      "876/876 - 17s - loss: 0.5636 - accuracy: 0.7882 - val_loss: 0.7126 - val_accuracy: 0.7440 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 73/75\n",
      "876/876 - 17s - loss: 0.5721 - accuracy: 0.7859 - val_loss: 0.7063 - val_accuracy: 0.7466 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 74/75\n",
      "876/876 - 17s - loss: 0.5649 - accuracy: 0.7878 - val_loss: 0.7104 - val_accuracy: 0.7553 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 75/75\n",
      "876/876 - 17s - loss: 0.5680 - accuracy: 0.7868 - val_loss: 0.6441 - val_accuracy: 0.7788 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/75\n",
      "176/176 - 11s - loss: 0.5212 - accuracy: 0.8037 - val_loss: 0.6640 - val_accuracy: 0.7573 - lr: 0.0010 - 11s/epoch - 63ms/step\n",
      "Epoch 2/75\n",
      "176/176 - 9s - loss: 0.5168 - accuracy: 0.8062 - val_loss: 0.6264 - val_accuracy: 0.7743 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 3/75\n",
      "176/176 - 9s - loss: 0.5114 - accuracy: 0.8076 - val_loss: 0.6655 - val_accuracy: 0.7447 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 4/75\n",
      "176/176 - 9s - loss: 0.5136 - accuracy: 0.8061 - val_loss: 0.6747 - val_accuracy: 0.7400 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 5/75\n",
      "176/176 - 9s - loss: 0.5092 - accuracy: 0.8091 - val_loss: 0.7054 - val_accuracy: 0.7356 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 6/75\n",
      "176/176 - 9s - loss: 0.5085 - accuracy: 0.8093 - val_loss: 0.6630 - val_accuracy: 0.7596 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 7/75\n",
      "176/176 - 9s - loss: 0.5075 - accuracy: 0.8095 - val_loss: 0.6755 - val_accuracy: 0.7438 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 8/75\n",
      "176/176 - 9s - loss: 0.5078 - accuracy: 0.8097 - val_loss: 0.6902 - val_accuracy: 0.7427 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 9/75\n",
      "176/176 - 9s - loss: 0.5011 - accuracy: 0.8123 - val_loss: 0.7083 - val_accuracy: 0.7458 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 10/75\n",
      "176/176 - 9s - loss: 0.5053 - accuracy: 0.8105 - val_loss: 0.7287 - val_accuracy: 0.7268 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 11/75\n",
      "176/176 - 9s - loss: 0.4997 - accuracy: 0.8129 - val_loss: 0.7121 - val_accuracy: 0.7327 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 12/75\n",
      "176/176 - 9s - loss: 0.5014 - accuracy: 0.8126 - val_loss: 0.7411 - val_accuracy: 0.7253 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 13/75\n",
      "176/176 - 9s - loss: 0.4966 - accuracy: 0.8133 - val_loss: 0.6859 - val_accuracy: 0.7408 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 14/75\n",
      "176/176 - 9s - loss: 0.4960 - accuracy: 0.8158 - val_loss: 0.6797 - val_accuracy: 0.7478 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 15/75\n",
      "176/176 - 9s - loss: 0.5025 - accuracy: 0.8127 - val_loss: 0.7243 - val_accuracy: 0.7309 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 16/75\n",
      "176/176 - 9s - loss: 0.4984 - accuracy: 0.8130 - val_loss: 0.6768 - val_accuracy: 0.7536 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 17/75\n",
      "176/176 - 9s - loss: 0.4933 - accuracy: 0.8153 - val_loss: 0.6966 - val_accuracy: 0.7424 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 18/75\n",
      "176/176 - 9s - loss: 0.4922 - accuracy: 0.8153 - val_loss: 0.7189 - val_accuracy: 0.7342 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 19/75\n",
      "176/176 - 9s - loss: 0.4937 - accuracy: 0.8144 - val_loss: 0.7144 - val_accuracy: 0.7421 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 20/75\n",
      "176/176 - 9s - loss: 0.4928 - accuracy: 0.8158 - val_loss: 0.6778 - val_accuracy: 0.7548 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 21/75\n",
      "176/176 - 9s - loss: 0.4855 - accuracy: 0.8183 - val_loss: 0.7010 - val_accuracy: 0.7415 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 22/75\n",
      "176/176 - 9s - loss: 0.4869 - accuracy: 0.8174 - val_loss: 0.6709 - val_accuracy: 0.7526 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 23/75\n",
      "176/176 - 9s - loss: 0.4898 - accuracy: 0.8170 - val_loss: 0.7077 - val_accuracy: 0.7380 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 24/75\n",
      "176/176 - 9s - loss: 0.4863 - accuracy: 0.8195 - val_loss: 0.6682 - val_accuracy: 0.7520 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 25/75\n",
      "176/176 - 9s - loss: 0.4874 - accuracy: 0.8178 - val_loss: 0.7314 - val_accuracy: 0.7349 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 26/75\n",
      "176/176 - 9s - loss: 0.4841 - accuracy: 0.8189 - val_loss: 0.7300 - val_accuracy: 0.7378 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 27/75\n",
      "176/176 - 9s - loss: 0.4848 - accuracy: 0.8191 - val_loss: 0.6699 - val_accuracy: 0.7452 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 28/75\n",
      "176/176 - 9s - loss: 0.4837 - accuracy: 0.8189 - val_loss: 0.6698 - val_accuracy: 0.7528 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 29/75\n",
      "176/176 - 9s - loss: 0.4862 - accuracy: 0.8178 - val_loss: 0.7077 - val_accuracy: 0.7352 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 30/75\n",
      "176/176 - 9s - loss: 0.4812 - accuracy: 0.8204 - val_loss: 0.7366 - val_accuracy: 0.7293 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 31/75\n",
      "176/176 - 9s - loss: 0.4776 - accuracy: 0.8210 - val_loss: 0.6819 - val_accuracy: 0.7435 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 32/75\n",
      "176/176 - 9s - loss: 0.4826 - accuracy: 0.8204 - val_loss: 0.6539 - val_accuracy: 0.7614 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 33/75\n",
      "176/176 - 9s - loss: 0.4780 - accuracy: 0.8213 - val_loss: 0.6784 - val_accuracy: 0.7560 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 34/75\n",
      "176/176 - 9s - loss: 0.4775 - accuracy: 0.8223 - val_loss: 0.7134 - val_accuracy: 0.7325 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 35/75\n",
      "176/176 - 9s - loss: 0.4786 - accuracy: 0.8210 - val_loss: 0.7479 - val_accuracy: 0.7201 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 36/75\n",
      "176/176 - 9s - loss: 0.4793 - accuracy: 0.8205 - val_loss: 0.6998 - val_accuracy: 0.7383 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 37/75\n",
      "176/176 - 9s - loss: 0.4742 - accuracy: 0.8230 - val_loss: 0.7470 - val_accuracy: 0.7188 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 38/75\n",
      "176/176 - 9s - loss: 0.4792 - accuracy: 0.8221 - val_loss: 0.6519 - val_accuracy: 0.7563 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 39/75\n",
      "176/176 - 9s - loss: 0.4749 - accuracy: 0.8220 - val_loss: 0.6924 - val_accuracy: 0.7378 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 40/75\n",
      "176/176 - 9s - loss: 0.4736 - accuracy: 0.8229 - val_loss: 0.7133 - val_accuracy: 0.7287 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 41/75\n",
      "176/176 - 9s - loss: 0.4760 - accuracy: 0.8218 - val_loss: 0.6921 - val_accuracy: 0.7439 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 42/75\n",
      "176/176 - 9s - loss: 0.4735 - accuracy: 0.8235 - val_loss: 0.7024 - val_accuracy: 0.7334 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 43/75\n",
      "176/176 - 9s - loss: 0.4700 - accuracy: 0.8255 - val_loss: 0.6719 - val_accuracy: 0.7534 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 44/75\n",
      "176/176 - 9s - loss: 0.4715 - accuracy: 0.8238 - val_loss: 0.6700 - val_accuracy: 0.7538 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 45/75\n",
      "176/176 - 9s - loss: 0.4710 - accuracy: 0.8239 - val_loss: 0.6796 - val_accuracy: 0.7468 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 46/75\n",
      "176/176 - 9s - loss: 0.4686 - accuracy: 0.8251 - val_loss: 0.6940 - val_accuracy: 0.7405 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 47/75\n",
      "176/176 - 9s - loss: 0.4654 - accuracy: 0.8259 - val_loss: 0.6967 - val_accuracy: 0.7371 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 48/75\n",
      "176/176 - 9s - loss: 0.4661 - accuracy: 0.8259 - val_loss: 0.6728 - val_accuracy: 0.7433 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 49/75\n",
      "176/176 - 9s - loss: 0.4673 - accuracy: 0.8248 - val_loss: 0.6918 - val_accuracy: 0.7474 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 50/75\n",
      "176/176 - 9s - loss: 0.4658 - accuracy: 0.8256 - val_loss: 0.6674 - val_accuracy: 0.7498 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 51/75\n",
      "176/176 - 9s - loss: 0.4673 - accuracy: 0.8261 - val_loss: 0.7137 - val_accuracy: 0.7276 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 52/75\n",
      "176/176 - 9s - loss: 0.4636 - accuracy: 0.8267 - val_loss: 0.7127 - val_accuracy: 0.7287 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 53/75\n",
      "176/176 - 9s - loss: 0.4697 - accuracy: 0.8239 - val_loss: 0.6939 - val_accuracy: 0.7426 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 54/75\n",
      "176/176 - 9s - loss: 0.4612 - accuracy: 0.8275 - val_loss: 0.6930 - val_accuracy: 0.7338 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 55/75\n",
      "176/176 - 9s - loss: 0.4674 - accuracy: 0.8260 - val_loss: 0.7225 - val_accuracy: 0.7249 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 56/75\n",
      "176/176 - 9s - loss: 0.4631 - accuracy: 0.8260 - val_loss: 0.6914 - val_accuracy: 0.7416 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 57/75\n",
      "176/176 - 9s - loss: 0.4652 - accuracy: 0.8255 - val_loss: 0.7181 - val_accuracy: 0.7276 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 58/75\n",
      "176/176 - 9s - loss: 0.4606 - accuracy: 0.8275 - val_loss: 0.6799 - val_accuracy: 0.7416 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 59/75\n",
      "176/176 - 9s - loss: 0.4673 - accuracy: 0.8240 - val_loss: 0.7433 - val_accuracy: 0.7152 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 60/75\n",
      "176/176 - 9s - loss: 0.4600 - accuracy: 0.8283 - val_loss: 0.7222 - val_accuracy: 0.7275 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 61/75\n",
      "176/176 - 9s - loss: 0.4578 - accuracy: 0.8285 - val_loss: 0.6789 - val_accuracy: 0.7464 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 62/75\n",
      "176/176 - 9s - loss: 0.4592 - accuracy: 0.8288 - val_loss: 0.6977 - val_accuracy: 0.7430 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 63/75\n",
      "176/176 - 9s - loss: 0.4682 - accuracy: 0.8243 - val_loss: 0.7328 - val_accuracy: 0.7278 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 64/75\n",
      "176/176 - 9s - loss: 0.4581 - accuracy: 0.8295 - val_loss: 0.6713 - val_accuracy: 0.7516 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 65/75\n",
      "176/176 - 9s - loss: 0.4551 - accuracy: 0.8307 - val_loss: 0.7263 - val_accuracy: 0.7246 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 66/75\n",
      "176/176 - 9s - loss: 0.4580 - accuracy: 0.8289 - val_loss: 0.7394 - val_accuracy: 0.7133 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 67/75\n",
      "176/176 - 9s - loss: 0.4577 - accuracy: 0.8280 - val_loss: 0.7550 - val_accuracy: 0.7173 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 68/75\n",
      "176/176 - 9s - loss: 0.4571 - accuracy: 0.8293 - val_loss: 0.7150 - val_accuracy: 0.7308 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 69/75\n",
      "176/176 - 9s - loss: 0.4581 - accuracy: 0.8281 - val_loss: 0.7418 - val_accuracy: 0.7129 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 70/75\n",
      "176/176 - 9s - loss: 0.4651 - accuracy: 0.8262 - val_loss: 0.7523 - val_accuracy: 0.7123 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 71/75\n",
      "176/176 - 9s - loss: 0.4532 - accuracy: 0.8310 - val_loss: 0.7024 - val_accuracy: 0.7324 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 72/75\n",
      "176/176 - 9s - loss: 0.4535 - accuracy: 0.8304 - val_loss: 0.6956 - val_accuracy: 0.7415 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 73/75\n",
      "176/176 - 9s - loss: 0.4540 - accuracy: 0.8308 - val_loss: 0.7358 - val_accuracy: 0.7230 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 74/75\n",
      "176/176 - 9s - loss: 0.4571 - accuracy: 0.8290 - val_loss: 0.7511 - val_accuracy: 0.7152 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 75/75\n",
      "176/176 - 9s - loss: 0.4531 - accuracy: 0.8313 - val_loss: 0.7144 - val_accuracy: 0.7199 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch number: 100\n",
      "fitting with batch size: 20\n",
      "Epoch 1/100\n",
      "4378/4378 - 75s - loss: 0.6900 - accuracy: 0.7439 - val_loss: 0.6762 - val_accuracy: 0.7811 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 2/100\n",
      "4378/4378 - 71s - loss: 0.6883 - accuracy: 0.7442 - val_loss: 0.8233 - val_accuracy: 0.7313 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "4378/4378 - 71s - loss: 0.7495 - accuracy: 0.7368 - val_loss: 0.7635 - val_accuracy: 0.7765 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "4378/4378 - 71s - loss: 0.6923 - accuracy: 0.7408 - val_loss: 0.6325 - val_accuracy: 0.8023 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "4378/4378 - 71s - loss: 0.6975 - accuracy: 0.7387 - val_loss: 0.6462 - val_accuracy: 0.7828 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "4378/4378 - 71s - loss: 0.7006 - accuracy: 0.7375 - val_loss: 0.7348 - val_accuracy: 0.7339 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "4378/4378 - 71s - loss: 0.7008 - accuracy: 0.7409 - val_loss: 0.7251 - val_accuracy: 0.7611 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "4378/4378 - 71s - loss: 0.7018 - accuracy: 0.7372 - val_loss: 0.6971 - val_accuracy: 0.7888 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "4378/4378 - 71s - loss: 0.7023 - accuracy: 0.7375 - val_loss: 0.7691 - val_accuracy: 0.7199 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "4378/4378 - 71s - loss: 0.7012 - accuracy: 0.7376 - val_loss: 0.6188 - val_accuracy: 0.8140 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "4378/4378 - 71s - loss: 0.7047 - accuracy: 0.7367 - val_loss: 1.0913 - val_accuracy: 0.6554 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "4378/4378 - 71s - loss: 0.7190 - accuracy: 0.7375 - val_loss: 0.8146 - val_accuracy: 0.7068 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "4378/4378 - 71s - loss: 0.7127 - accuracy: 0.7349 - val_loss: 0.7350 - val_accuracy: 0.7745 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "4378/4378 - 69s - loss: 0.7325 - accuracy: 0.7372 - val_loss: 0.8625 - val_accuracy: 0.7055 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "4378/4378 - 70s - loss: 0.7047 - accuracy: 0.7380 - val_loss: 0.8100 - val_accuracy: 0.7074 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "4378/4378 - 70s - loss: 0.7067 - accuracy: 0.7372 - val_loss: 0.7896 - val_accuracy: 0.7567 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "4378/4378 - 70s - loss: 0.7063 - accuracy: 0.7360 - val_loss: 0.7007 - val_accuracy: 0.7805 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "4378/4378 - 69s - loss: 0.7117 - accuracy: 0.7362 - val_loss: 0.8086 - val_accuracy: 0.7246 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "4378/4378 - 70s - loss: 0.7197 - accuracy: 0.7333 - val_loss: 0.7176 - val_accuracy: 0.7537 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "4378/4378 - 70s - loss: 0.7191 - accuracy: 0.7357 - val_loss: 0.7347 - val_accuracy: 0.7438 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "4378/4378 - 70s - loss: 1.7427 - accuracy: 0.5640 - val_loss: 1.7618 - val_accuracy: 0.8176 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "4378/4378 - 70s - loss: 1.6119 - accuracy: 0.1977 - val_loss: 4.4613 - val_accuracy: 0.0736 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "4378/4378 - 69s - loss: 1.6110 - accuracy: 0.1981 - val_loss: 3.9381 - val_accuracy: 0.0742 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "4378/4378 - 69s - loss: 1.6109 - accuracy: 0.2025 - val_loss: 3.4483 - val_accuracy: 0.8124 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "4378/4378 - 70s - loss: 1.6108 - accuracy: 0.1991 - val_loss: 3.0945 - val_accuracy: 0.0656 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "4378/4378 - 70s - loss: 1.6107 - accuracy: 0.1998 - val_loss: 2.6598 - val_accuracy: 0.0253 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "4378/4378 - 69s - loss: 1.6105 - accuracy: 0.2024 - val_loss: 2.2100 - val_accuracy: 0.0744 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "4378/4378 - 70s - loss: 1.6105 - accuracy: 0.1994 - val_loss: 2.0624 - val_accuracy: 0.0695 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "4378/4378 - 70s - loss: 1.6104 - accuracy: 0.1982 - val_loss: 2.4571 - val_accuracy: 0.0257 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "4378/4378 - 70s - loss: 1.6102 - accuracy: 0.1998 - val_loss: 3.1396 - val_accuracy: 0.0651 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "4378/4378 - 70s - loss: 1.6101 - accuracy: 0.2003 - val_loss: 2.9132 - val_accuracy: 0.0100 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "4378/4378 - 69s - loss: 1.6101 - accuracy: 0.1984 - val_loss: 1.9574 - val_accuracy: 0.8154 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "4378/4378 - 69s - loss: 1.6100 - accuracy: 0.2006 - val_loss: 2.1679 - val_accuracy: 0.0742 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "4378/4378 - 70s - loss: 1.6099 - accuracy: 0.2017 - val_loss: 2.1472 - val_accuracy: 0.0252 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "4378/4378 - 69s - loss: 1.6099 - accuracy: 0.1985 - val_loss: 4.7336 - val_accuracy: 0.0658 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "4378/4378 - 70s - loss: 1.6099 - accuracy: 0.1994 - val_loss: 2.1194 - val_accuracy: 0.0663 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "4378/4378 - 70s - loss: 1.6100 - accuracy: 0.1961 - val_loss: 2.4345 - val_accuracy: 0.0652 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "4378/4378 - 69s - loss: 1.6099 - accuracy: 0.1975 - val_loss: 3.1413 - val_accuracy: 0.8120 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "4378/4378 - 70s - loss: 1.6098 - accuracy: 0.2001 - val_loss: 3.2228 - val_accuracy: 0.0740 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "4378/4378 - 69s - loss: 1.6098 - accuracy: 0.2003 - val_loss: 1.7645 - val_accuracy: 0.8273 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "4378/4378 - 70s - loss: 1.6098 - accuracy: 0.1997 - val_loss: 4.6293 - val_accuracy: 0.0739 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "4378/4378 - 69s - loss: 1.6098 - accuracy: 0.2003 - val_loss: 5.8905 - val_accuracy: 0.0736 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "4378/4378 - 70s - loss: 1.6098 - accuracy: 0.1985 - val_loss: 2.0514 - val_accuracy: 0.0894 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "4378/4378 - 70s - loss: 1.6098 - accuracy: 0.1992 - val_loss: 4.6227 - val_accuracy: 0.0252 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.1984 - val_loss: 1.9138 - val_accuracy: 0.8261 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "4378/4378 - 71s - loss: 1.6098 - accuracy: 0.2011 - val_loss: 4.2421 - val_accuracy: 0.0251 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "4378/4378 - 70s - loss: 1.6098 - accuracy: 0.1996 - val_loss: 5.5093 - val_accuracy: 0.8121 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.2013 - val_loss: 6.3199 - val_accuracy: 0.0253 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1964 - val_loss: 2.7798 - val_accuracy: 0.0296 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.1990 - val_loss: 1.7258 - val_accuracy: 0.8240 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1982 - val_loss: 5.3981 - val_accuracy: 0.8119 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1987 - val_loss: 2.0627 - val_accuracy: 0.0671 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.2001 - val_loss: 2.1611 - val_accuracy: 0.8156 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "4378/4378 - 69s - loss: 1.6098 - accuracy: 0.1963 - val_loss: 3.6751 - val_accuracy: 0.8118 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1999 - val_loss: 16.4243 - val_accuracy: 0.0661 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.1992 - val_loss: 1.8481 - val_accuracy: 0.0859 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1988 - val_loss: 3.2839 - val_accuracy: 0.0663 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.1983 - val_loss: 3.8633 - val_accuracy: 0.0655 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "4378/4378 - 69s - loss: 1.6096 - accuracy: 0.2025 - val_loss: 4.8948 - val_accuracy: 0.0085 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.2019 - val_loss: 4.8766 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1966 - val_loss: 2.5244 - val_accuracy: 0.0893 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.2003 - val_loss: 4.7962 - val_accuracy: 0.0409 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.1997 - val_loss: 13.2834 - val_accuracy: 0.8118 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.2014 - val_loss: 3.2107 - val_accuracy: 0.8121 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1980 - val_loss: 14.2068 - val_accuracy: 0.0747 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "4378/4378 - 70s - loss: 1.6096 - accuracy: 0.2000 - val_loss: 10.9122 - val_accuracy: 0.8129 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1992 - val_loss: 3.3194 - val_accuracy: 0.8276 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "4378/4378 - 70s - loss: 1.6096 - accuracy: 0.2011 - val_loss: 9.7537 - val_accuracy: 0.0652 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "4378/4378 - 69s - loss: 1.6096 - accuracy: 0.1991 - val_loss: 28.7956 - val_accuracy: 0.8118 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1999 - val_loss: 3.9686 - val_accuracy: 0.0739 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1986 - val_loss: 6.6822 - val_accuracy: 0.0747 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1989 - val_loss: 2.1172 - val_accuracy: 0.0215 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.1983 - val_loss: 6.5554 - val_accuracy: 0.0262 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "4378/4378 - 69s - loss: 1.6096 - accuracy: 0.1980 - val_loss: 2.1902 - val_accuracy: 0.0231 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.1989 - val_loss: 14.2797 - val_accuracy: 0.8123 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.2001 - val_loss: 9.1310 - val_accuracy: 0.0252 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1998 - val_loss: 16.7449 - val_accuracy: 0.0074 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1994 - val_loss: 11.4310 - val_accuracy: 0.0654 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.2008 - val_loss: 13.3459 - val_accuracy: 0.0256 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.2005 - val_loss: 13.3462 - val_accuracy: 0.8116 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.2001 - val_loss: 5.4615 - val_accuracy: 0.0072 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "4378/4378 - 70s - loss: 1.6096 - accuracy: 0.2006 - val_loss: 2.5065 - val_accuracy: 0.0894 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.2001 - val_loss: 5.2901 - val_accuracy: 0.0736 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1984 - val_loss: 20.4937 - val_accuracy: 0.0651 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1987 - val_loss: 6.3191 - val_accuracy: 0.0074 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "4378/4378 - 71s - loss: 1.6097 - accuracy: 0.1984 - val_loss: 13.3859 - val_accuracy: 0.0074 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "4378/4378 - 69s - loss: 1.6097 - accuracy: 0.1984 - val_loss: 6.6508 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "4378/4378 - 69s - loss: 1.6096 - accuracy: 0.2001 - val_loss: 2.3678 - val_accuracy: 0.0209 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "4378/4378 - 69s - loss: 1.6096 - accuracy: 0.1987 - val_loss: 24.3485 - val_accuracy: 0.0649 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "4378/4378 - 70s - loss: 1.6096 - accuracy: 0.1976 - val_loss: 2.0896 - val_accuracy: 0.0894 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1966 - val_loss: 9.0206 - val_accuracy: 0.8129 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.2004 - val_loss: 3.0336 - val_accuracy: 0.8252 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "4378/4378 - 69s - loss: 1.6096 - accuracy: 0.2011 - val_loss: 2.8636 - val_accuracy: 0.0809 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "4378/4378 - 70s - loss: 1.6096 - accuracy: 0.2009 - val_loss: 5.1768 - val_accuracy: 0.0747 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1976 - val_loss: 5.7657 - val_accuracy: 0.0652 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1975 - val_loss: 13.4996 - val_accuracy: 0.8118 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "4378/4378 - 70s - loss: 1.6096 - accuracy: 0.2000 - val_loss: 11.0721 - val_accuracy: 0.0076 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "4378/4378 - 70s - loss: 1.6097 - accuracy: 0.1997 - val_loss: 1.8381 - val_accuracy: 0.0866 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "4378/4378 - 70s - loss: 1.6096 - accuracy: 0.2006 - val_loss: 3.6764 - val_accuracy: 0.0409 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "4378/4378 - 70s - loss: 1.6096 - accuracy: 0.1988 - val_loss: 6.2417 - val_accuracy: 0.0651 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/100\n",
      "876/876 - 20s - loss: 1.6095 - accuracy: 0.1968 - val_loss: 7.4581 - val_accuracy: 0.0739 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2003 - val_loss: 2.4391 - val_accuracy: 0.0164 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "876/876 - 17s - loss: 1.6096 - accuracy: 0.1987 - val_loss: 2.3164 - val_accuracy: 0.0314 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 4/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 4.6902 - val_accuracy: 0.0739 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 5/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 10.8640 - val_accuracy: 0.0661 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 6/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 9.0521 - val_accuracy: 0.0262 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 3.4946 - val_accuracy: 0.8130 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 8/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 2.1841 - val_accuracy: 0.0262 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 7.1707 - val_accuracy: 0.0653 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 10/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2001 - val_loss: 3.2229 - val_accuracy: 0.0684 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 11/100\n",
      "876/876 - 17s - loss: 1.6096 - accuracy: 0.1968 - val_loss: 5.7273 - val_accuracy: 0.0735 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 12/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 8.1611 - val_accuracy: 0.0737 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 13/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 17.5611 - val_accuracy: 0.0074 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 14/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 2.4281 - val_accuracy: 0.0232 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 15/100\n",
      "876/876 - 17s - loss: 1.6096 - accuracy: 0.1968 - val_loss: 7.4705 - val_accuracy: 0.0661 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 16/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2010 - val_loss: 4.3966 - val_accuracy: 0.0072 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 17/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 17.2637 - val_accuracy: 0.8118 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 18/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 9.3134 - val_accuracy: 0.8129 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 19/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2001 - val_loss: 2.4878 - val_accuracy: 0.0770 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 20/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 8.5571 - val_accuracy: 0.0649 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 21/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 2.7183 - val_accuracy: 0.0809 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 22/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1956 - val_loss: 6.5960 - val_accuracy: 0.0085 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 23/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 3.1487 - val_accuracy: 0.0661 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 24/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 6.8057 - val_accuracy: 0.0261 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 4.5002 - val_accuracy: 0.0649 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2011 - val_loss: 2.6966 - val_accuracy: 0.0894 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 27/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 3.2511 - val_accuracy: 0.8276 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 28/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1963 - val_loss: 4.1454 - val_accuracy: 0.0737 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 29/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2007 - val_loss: 8.3853 - val_accuracy: 0.8118 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 30/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 17.7826 - val_accuracy: 0.0737 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 31/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 31.2783 - val_accuracy: 0.8116 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 32/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 12.3174 - val_accuracy: 0.0249 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 33/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 16.3445 - val_accuracy: 0.0085 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 34/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1965 - val_loss: 16.9089 - val_accuracy: 0.0649 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 35/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 28.5376 - val_accuracy: 0.0076 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 36/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2010 - val_loss: 4.2162 - val_accuracy: 0.0232 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 37/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 3.5726 - val_accuracy: 0.0232 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 38/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2003 - val_loss: 14.0793 - val_accuracy: 0.0651 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 39/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 28.4386 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 40/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2002 - val_loss: 3.1287 - val_accuracy: 0.0732 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 41/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 13.4887 - val_accuracy: 0.0739 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 42/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 10.7253 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 43/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 3.1169 - val_accuracy: 0.0770 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 44/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1970 - val_loss: 11.7837 - val_accuracy: 0.0262 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 45/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1964 - val_loss: 10.0596 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 46/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 3.3640 - val_accuracy: 0.8118 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 47/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 3.2553 - val_accuracy: 0.0681 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 48/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 4.3083 - val_accuracy: 0.0074 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 49/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 7.2596 - val_accuracy: 0.0739 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 50/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2004 - val_loss: 14.0989 - val_accuracy: 0.8121 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 51/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 5.2249 - val_accuracy: 0.0747 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 52/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 3.6094 - val_accuracy: 0.0809 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 53/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 16.3866 - val_accuracy: 0.0649 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 54/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 5.3540 - val_accuracy: 0.0661 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 55/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2003 - val_loss: 9.4265 - val_accuracy: 0.0747 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 56/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 16.7165 - val_accuracy: 0.0077 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 57/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2016 - val_loss: 16.1224 - val_accuracy: 0.0262 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 58/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 4.8320 - val_accuracy: 0.0252 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 59/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1965 - val_loss: 2.3397 - val_accuracy: 0.0809 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 60/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 9.9484 - val_accuracy: 0.0737 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 61/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 4.7163 - val_accuracy: 0.0252 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 62/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 3.2469 - val_accuracy: 0.8145 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 63/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 4.0650 - val_accuracy: 0.0072 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 64/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 4.5167 - val_accuracy: 0.0651 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 65/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 10.6725 - val_accuracy: 0.0252 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 66/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 15.5743 - val_accuracy: 0.0661 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 67/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 5.6456 - val_accuracy: 0.0661 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 68/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2004 - val_loss: 2.8661 - val_accuracy: 0.0809 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 69/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 2.7642 - val_accuracy: 0.0409 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 70/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 5.3757 - val_accuracy: 0.0076 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 71/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2004 - val_loss: 20.3496 - val_accuracy: 0.0653 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 72/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 5.7168 - val_accuracy: 0.0661 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 73/100\n",
      "876/876 - 16s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 15.9165 - val_accuracy: 0.0252 - lr: 0.0010 - 16s/epoch - 19ms/step\n",
      "Epoch 74/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2006 - val_loss: 4.5021 - val_accuracy: 0.8276 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 75/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1967 - val_loss: 9.4027 - val_accuracy: 0.0074 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 76/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 20.0387 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 77/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 15.5196 - val_accuracy: 0.0661 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 78/100\n",
      "876/876 - 17s - loss: 1.6096 - accuracy: 0.1977 - val_loss: 14.7884 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 79/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2024 - val_loss: 7.2543 - val_accuracy: 0.8116 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 80/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1962 - val_loss: 2.4099 - val_accuracy: 0.0231 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 81/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 13.5684 - val_accuracy: 0.0653 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 2.1995 - val_accuracy: 0.0808 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 83/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2023 - val_loss: 13.5858 - val_accuracy: 0.0747 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 84/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2018 - val_loss: 12.2648 - val_accuracy: 0.0739 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 85/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 12.8082 - val_accuracy: 0.0249 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 86/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 10.0045 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 87/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 3.5655 - val_accuracy: 0.8276 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 88/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 3.4041 - val_accuracy: 0.0409 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 89/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 8.1658 - val_accuracy: 0.0262 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 90/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 4.3291 - val_accuracy: 0.0735 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 91/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 3.7065 - val_accuracy: 0.0072 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 92/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 20.8591 - val_accuracy: 0.0737 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 93/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 6.0945 - val_accuracy: 0.0651 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 94/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 3.5702 - val_accuracy: 0.0809 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 95/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 12.9497 - val_accuracy: 0.0085 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 96/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 12.1078 - val_accuracy: 0.8116 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 26.2464 - val_accuracy: 0.0072 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 16.0573 - val_accuracy: 0.0649 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 99/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 4.9686 - val_accuracy: 0.8129 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 100/100\n",
      "876/876 - 17s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 3.0976 - val_accuracy: 0.0074 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/100\n",
      "176/176 - 11s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 2.8212 - val_accuracy: 0.8121 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 2/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 7.2911 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 3/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 13.4764 - val_accuracy: 0.0072 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 4/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 10.1724 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 5/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 2.7771 - val_accuracy: 0.0232 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 6/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 4.9113 - val_accuracy: 0.0654 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 7/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 10.2763 - val_accuracy: 0.0747 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 8/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 9.0464 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 9/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 14.7838 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 10/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2010 - val_loss: 11.0436 - val_accuracy: 0.8118 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 11/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 4.9582 - val_accuracy: 0.0072 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 12/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 2.3693 - val_accuracy: 0.0892 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 13/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 2.6600 - val_accuracy: 0.0232 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 14/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 2.0828 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 15/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 9.5633 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 16/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 14.6279 - val_accuracy: 0.0085 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 17/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 6.7068 - val_accuracy: 0.0073 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 18/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 10.4091 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 19/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 13.5026 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 20/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1967 - val_loss: 5.2571 - val_accuracy: 0.8121 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 21/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 4.1803 - val_accuracy: 0.0085 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 22/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 7.5538 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 23/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2020 - val_loss: 5.6762 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 24/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2003 - val_loss: 4.7604 - val_accuracy: 0.0747 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 25/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2005 - val_loss: 3.0736 - val_accuracy: 0.8142 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 26/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1965 - val_loss: 2.1023 - val_accuracy: 0.0894 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 27/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 4.8247 - val_accuracy: 0.8129 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 28/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 11.4650 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 29/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 12.6554 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 30/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 2.8369 - val_accuracy: 0.0806 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 31/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1965 - val_loss: 2.3963 - val_accuracy: 0.0409 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 32/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 3.6273 - val_accuracy: 0.8121 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 33/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 2.6156 - val_accuracy: 0.8129 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 34/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1969 - val_loss: 9.6083 - val_accuracy: 0.8116 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 35/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 17.1265 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 36/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 14.9041 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 37/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2004 - val_loss: 18.6434 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 38/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 2.1221 - val_accuracy: 0.0232 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 39/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 8.5104 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 40/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2008 - val_loss: 4.1517 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 41/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 3.8137 - val_accuracy: 0.0809 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 42/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 2.1707 - val_accuracy: 0.0894 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 43/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 20.6254 - val_accuracy: 0.8116 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 44/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 7.7255 - val_accuracy: 0.0252 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 45/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 10.3129 - val_accuracy: 0.0252 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 46/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 21.5253 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 47/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 11.1100 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 48/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 8.6143 - val_accuracy: 0.0072 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 49/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2012 - val_loss: 8.0651 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 50/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 3.3657 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 51/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 2.6977 - val_accuracy: 0.0409 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 52/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2003 - val_loss: 5.6755 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 53/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 2.7895 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 54/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 16.6753 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 55/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 7.8724 - val_accuracy: 0.0257 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 56/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 4.6083 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 57/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 3.9079 - val_accuracy: 0.0409 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 58/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 2.0819 - val_accuracy: 0.0408 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 59/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 2.1534 - val_accuracy: 0.0808 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 60/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 6.1272 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 61/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 2.6448 - val_accuracy: 0.0406 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 62/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1961 - val_loss: 3.5681 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 63/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2001 - val_loss: 12.4071 - val_accuracy: 0.0252 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 64/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 3.9541 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 65/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 10.2760 - val_accuracy: 0.8118 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 66/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 2.3344 - val_accuracy: 0.0808 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 67/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1965 - val_loss: 4.5512 - val_accuracy: 0.0651 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 68/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1959 - val_loss: 2.7125 - val_accuracy: 0.8119 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 69/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1967 - val_loss: 4.0819 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 70/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 6.0574 - val_accuracy: 0.0747 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 71/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1967 - val_loss: 5.1573 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 72/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 3.9163 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 73/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 3.6219 - val_accuracy: 0.0809 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 74/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 4.2595 - val_accuracy: 0.0651 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 75/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 8.5935 - val_accuracy: 0.0737 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 76/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 2.3373 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 77/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 5.8710 - val_accuracy: 0.0663 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 78/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1967 - val_loss: 2.8439 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 79/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 5.1741 - val_accuracy: 0.0737 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 80/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 7.4674 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 81/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 10.0188 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 82/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1968 - val_loss: 4.1759 - val_accuracy: 0.0894 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 83/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 2.4892 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 84/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 8.8397 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 85/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 4.1127 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 86/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 3.9799 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 87/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 10.1277 - val_accuracy: 0.0651 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 88/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 15.0440 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 89/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 8.5650 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 90/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 19.8664 - val_accuracy: 0.0072 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 91/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2004 - val_loss: 9.1359 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 92/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 5.7225 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 93/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.2009 - val_loss: 10.8756 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 94/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 4.0748 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 95/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 2.6047 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 96/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 3.6141 - val_accuracy: 0.0809 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 97/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 3.7062 - val_accuracy: 0.0249 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 98/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 7.6163 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 99/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 2.5337 - val_accuracy: 0.0809 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 100/100\n",
      "176/176 - 9s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 7.6366 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Loss: binary_crossentropy\n",
      "Epoch number: 75\n",
      "fitting with batch size: 20\n",
      "Epoch 1/75\n",
      "4378/4378 - 77s - loss: 0.5005 - accuracy: 0.1976 - val_loss: 0.6031 - val_accuracy: 0.0735 - lr: 0.0010 - 77s/epoch - 18ms/step\n",
      "Epoch 2/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1985 - val_loss: 0.5005 - val_accuracy: 0.8276 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 3/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.6007 - val_accuracy: 0.0737 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 4/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5081 - val_accuracy: 0.0808 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 5/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.2005 - val_loss: 0.5886 - val_accuracy: 0.0256 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 6/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5890 - val_accuracy: 0.8116 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 7/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1965 - val_loss: 0.5743 - val_accuracy: 0.0735 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 8/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.2016 - val_loss: 0.5889 - val_accuracy: 0.0254 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 9/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5563 - val_accuracy: 0.8116 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 10/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.6037 - val_accuracy: 0.0072 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 11/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1977 - val_loss: 0.5858 - val_accuracy: 0.0074 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 12/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5942 - val_accuracy: 0.0661 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 13/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1997 - val_loss: 0.5783 - val_accuracy: 0.0651 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 14/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.6005 - val_accuracy: 0.0254 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 15/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1990 - val_loss: 0.5561 - val_accuracy: 0.0771 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 16/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.2012 - val_loss: 0.5753 - val_accuracy: 0.0655 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 17/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1990 - val_loss: 0.5881 - val_accuracy: 0.0249 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 18/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1978 - val_loss: 0.5899 - val_accuracy: 0.0737 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 19/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1991 - val_loss: 0.5613 - val_accuracy: 0.0074 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 20/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.2023 - val_loss: 0.5151 - val_accuracy: 0.0215 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 21/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1996 - val_loss: 0.5894 - val_accuracy: 0.0653 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 22/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1995 - val_loss: 0.5015 - val_accuracy: 0.0806 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 23/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1981 - val_loss: 0.5531 - val_accuracy: 0.0251 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 24/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5903 - val_accuracy: 0.0262 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 25/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5908 - val_accuracy: 0.8116 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 26/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1998 - val_loss: 0.5520 - val_accuracy: 0.0649 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 27/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5440 - val_accuracy: 0.8132 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 28/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1980 - val_loss: 0.5670 - val_accuracy: 0.0074 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 29/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1995 - val_loss: 0.5871 - val_accuracy: 0.0651 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 30/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1986 - val_loss: 0.5865 - val_accuracy: 0.0076 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 31/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5080 - val_accuracy: 0.0390 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 32/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5743 - val_accuracy: 0.8125 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 33/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1994 - val_loss: 0.5848 - val_accuracy: 0.0085 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 34/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1989 - val_loss: 0.5933 - val_accuracy: 0.0651 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 35/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1993 - val_loss: 0.5842 - val_accuracy: 0.0262 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 36/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.2001 - val_loss: 0.5880 - val_accuracy: 0.8129 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 37/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1979 - val_loss: 0.5975 - val_accuracy: 0.0737 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 38/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.6045 - val_accuracy: 0.0252 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 39/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5913 - val_accuracy: 0.0649 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 40/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1994 - val_loss: 0.5376 - val_accuracy: 0.0657 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 41/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.6007 - val_accuracy: 0.0737 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 42/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5917 - val_accuracy: 0.0651 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 43/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5897 - val_accuracy: 0.0735 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 44/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5043 - val_accuracy: 0.0808 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 45/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.6016 - val_accuracy: 0.0249 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 46/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5214 - val_accuracy: 0.0667 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 47/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5740 - val_accuracy: 0.0649 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 48/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5903 - val_accuracy: 0.0661 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 49/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5703 - val_accuracy: 0.0079 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 50/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1993 - val_loss: 0.5805 - val_accuracy: 0.0741 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 51/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5802 - val_accuracy: 0.0747 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 52/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1976 - val_loss: 0.5970 - val_accuracy: 0.0739 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 53/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1971 - val_loss: 0.5797 - val_accuracy: 0.8129 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 54/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1969 - val_loss: 0.5743 - val_accuracy: 0.0258 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 55/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5798 - val_accuracy: 0.8129 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 56/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5060 - val_accuracy: 0.0894 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 57/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5835 - val_accuracy: 0.8129 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 58/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5813 - val_accuracy: 0.8129 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 59/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5603 - val_accuracy: 0.0653 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 60/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5757 - val_accuracy: 0.0252 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 61/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5647 - val_accuracy: 0.0085 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 62/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5800 - val_accuracy: 0.8118 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 63/75\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1976 - val_loss: 0.6007 - val_accuracy: 0.0074 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 64/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5051 - val_accuracy: 0.0409 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 65/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5953 - val_accuracy: 0.8121 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 66/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5888 - val_accuracy: 0.0735 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 67/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5213 - val_accuracy: 0.8224 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 68/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5895 - val_accuracy: 0.0254 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 69/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5974 - val_accuracy: 0.8116 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 70/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1977 - val_loss: 0.5145 - val_accuracy: 0.8208 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 71/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5074 - val_accuracy: 0.0231 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 72/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5884 - val_accuracy: 0.8116 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 73/75\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1974 - val_loss: 0.5730 - val_accuracy: 0.0747 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 74/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.6026 - val_accuracy: 0.0735 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 75/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5031 - val_accuracy: 0.0231 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/75\n",
      "876/876 - 21s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5973 - val_accuracy: 0.0252 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 2/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5868 - val_accuracy: 0.0252 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 3/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.6021 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 4/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5930 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 5/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5950 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 6/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.6025 - val_accuracy: 0.0649 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 7/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5902 - val_accuracy: 0.8116 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 8/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5821 - val_accuracy: 0.0076 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 9/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5788 - val_accuracy: 0.0741 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 10/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5981 - val_accuracy: 0.0072 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 11/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5258 - val_accuracy: 0.8167 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 12/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1963 - val_loss: 0.5945 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 13/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5138 - val_accuracy: 0.0853 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 14/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5678 - val_accuracy: 0.0085 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 15/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5918 - val_accuracy: 0.0737 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 16/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5919 - val_accuracy: 0.0651 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 17/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5072 - val_accuracy: 0.0894 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 18/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5119 - val_accuracy: 0.8157 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 19/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5936 - val_accuracy: 0.0072 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 20/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5977 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 21/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5963 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 22/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5063 - val_accuracy: 0.0894 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 23/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5915 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 24/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5975 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 25/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5920 - val_accuracy: 0.0072 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 26/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5811 - val_accuracy: 0.0737 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 27/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5032 - val_accuracy: 0.0231 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 28/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5743 - val_accuracy: 0.8116 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 29/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5038 - val_accuracy: 0.0894 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 30/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5062 - val_accuracy: 0.0232 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 31/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5537 - val_accuracy: 0.0072 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 32/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5785 - val_accuracy: 0.0076 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 33/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5973 - val_accuracy: 0.0072 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 34/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5991 - val_accuracy: 0.0737 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 35/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5969 - val_accuracy: 0.0249 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 36/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5967 - val_accuracy: 0.0649 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 37/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5750 - val_accuracy: 0.8121 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 38/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5617 - val_accuracy: 0.8119 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 39/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5672 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 40/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5786 - val_accuracy: 0.0651 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 41/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5868 - val_accuracy: 0.8116 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 42/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5736 - val_accuracy: 0.0649 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 43/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5814 - val_accuracy: 0.0653 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 44/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5968 - val_accuracy: 0.0252 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 45/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5911 - val_accuracy: 0.0076 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 46/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1963 - val_loss: 0.5691 - val_accuracy: 0.0649 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 47/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5968 - val_accuracy: 0.0649 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 48/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5039 - val_accuracy: 0.0808 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 49/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5727 - val_accuracy: 0.0088 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 50/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1963 - val_loss: 0.5034 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 51/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5056 - val_accuracy: 0.0809 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 52/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5937 - val_accuracy: 0.0249 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 53/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5750 - val_accuracy: 0.8129 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 54/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5768 - val_accuracy: 0.8121 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 55/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5936 - val_accuracy: 0.0649 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 56/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5950 - val_accuracy: 0.0249 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 57/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5875 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 58/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5728 - val_accuracy: 0.0739 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 59/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5867 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 60/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5939 - val_accuracy: 0.0653 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 61/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5817 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 62/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1963 - val_loss: 0.5641 - val_accuracy: 0.8130 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 63/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5973 - val_accuracy: 0.0649 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 64/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5903 - val_accuracy: 0.8118 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 65/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5016 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 66/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5935 - val_accuracy: 0.0262 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 67/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5691 - val_accuracy: 0.0085 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 68/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.4993 - val_accuracy: 0.8267 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 69/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5743 - val_accuracy: 0.0737 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 70/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5821 - val_accuracy: 0.0739 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 71/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5925 - val_accuracy: 0.0739 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 72/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5932 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 73/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5895 - val_accuracy: 0.8129 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 74/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5404 - val_accuracy: 0.0738 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 75/75\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5887 - val_accuracy: 0.0262 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/75\n",
      "176/176 - 11s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5847 - val_accuracy: 0.8129 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 2/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5880 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 3/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5787 - val_accuracy: 0.8129 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 4/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5128 - val_accuracy: 0.0268 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 5/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5056 - val_accuracy: 0.0232 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 6/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5862 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 7/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5247 - val_accuracy: 0.0741 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 8/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5909 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 9/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5916 - val_accuracy: 0.0249 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 10/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5575 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 11/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5951 - val_accuracy: 0.0651 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 12/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5523 - val_accuracy: 0.8118 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 13/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.6011 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 14/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1967 - val_loss: 0.5843 - val_accuracy: 0.0249 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 15/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5039 - val_accuracy: 0.0894 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 16/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5585 - val_accuracy: 0.0747 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 17/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5905 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 18/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5848 - val_accuracy: 0.0651 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 19/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5999 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 20/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5804 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 21/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5858 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 22/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5920 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 23/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1967 - val_loss: 0.5907 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 24/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5826 - val_accuracy: 0.0747 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 25/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5920 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 26/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5856 - val_accuracy: 0.8121 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 27/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5797 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 28/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5824 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 29/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5876 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 30/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5659 - val_accuracy: 0.0072 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 31/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5702 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 32/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5626 - val_accuracy: 0.0085 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 33/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1966 - val_loss: 0.5875 - val_accuracy: 0.8129 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 34/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5878 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 35/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5062 - val_accuracy: 0.0894 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 36/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5688 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 37/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5945 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 38/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5969 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 39/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5907 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 40/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5974 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 41/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5037 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 42/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5038 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 43/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5065 - val_accuracy: 0.0232 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 44/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5473 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 45/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5915 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 46/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5909 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 47/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5071 - val_accuracy: 0.0231 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 48/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5881 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 49/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5990 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 50/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5931 - val_accuracy: 0.8121 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 51/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5863 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 52/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5848 - val_accuracy: 0.8129 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 53/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5764 - val_accuracy: 0.0085 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 54/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5030 - val_accuracy: 0.0409 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 55/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5027 - val_accuracy: 0.0409 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 56/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5183 - val_accuracy: 0.0850 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 57/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5858 - val_accuracy: 0.8118 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 58/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5870 - val_accuracy: 0.8118 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 59/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5923 - val_accuracy: 0.8118 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 60/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5917 - val_accuracy: 0.0651 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 61/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5852 - val_accuracy: 0.0252 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 62/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5769 - val_accuracy: 0.0651 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 63/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5900 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 64/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5043 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 65/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5040 - val_accuracy: 0.0231 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 66/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5358 - val_accuracy: 0.8129 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 67/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5431 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 68/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5949 - val_accuracy: 0.0737 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 69/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5846 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 70/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5820 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 71/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5841 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 72/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5738 - val_accuracy: 0.0252 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 73/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5344 - val_accuracy: 0.0671 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 74/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5858 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 75/75\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5066 - val_accuracy: 0.0784 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch number: 100\n",
      "fitting with batch size: 20\n",
      "Epoch 1/100\n",
      "4378/4378 - 78s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5123 - val_accuracy: 0.8246 - lr: 0.0010 - 78s/epoch - 18ms/step\n",
      "Epoch 2/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1995 - val_loss: 0.5829 - val_accuracy: 0.0262 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1990 - val_loss: 0.5809 - val_accuracy: 0.8118 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1986 - val_loss: 0.5058 - val_accuracy: 0.0894 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1972 - val_loss: 0.5825 - val_accuracy: 0.0661 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1990 - val_loss: 0.5825 - val_accuracy: 0.0649 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5928 - val_accuracy: 0.8118 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5659 - val_accuracy: 0.0076 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5814 - val_accuracy: 0.0742 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5126 - val_accuracy: 0.0863 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5759 - val_accuracy: 0.0258 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1971 - val_loss: 0.5228 - val_accuracy: 0.0109 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5789 - val_accuracy: 0.8118 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1968 - val_loss: 0.5054 - val_accuracy: 0.0809 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5688 - val_accuracy: 0.0655 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.4976 - val_accuracy: 0.8276 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5322 - val_accuracy: 0.0072 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1969 - val_loss: 0.5334 - val_accuracy: 0.0114 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5195 - val_accuracy: 0.8187 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 20/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5647 - val_accuracy: 0.0268 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5812 - val_accuracy: 0.0737 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5859 - val_accuracy: 0.0085 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5912 - val_accuracy: 0.0254 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5543 - val_accuracy: 0.0251 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1982 - val_loss: 0.5488 - val_accuracy: 0.0267 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5469 - val_accuracy: 0.0077 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5038 - val_accuracy: 0.0230 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1980 - val_loss: 0.5576 - val_accuracy: 0.0258 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5638 - val_accuracy: 0.8129 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1972 - val_loss: 0.5345 - val_accuracy: 0.8151 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5631 - val_accuracy: 0.0736 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5722 - val_accuracy: 0.0737 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5197 - val_accuracy: 0.0120 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1964 - val_loss: 0.5744 - val_accuracy: 0.0252 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5398 - val_accuracy: 0.8123 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1974 - val_loss: 0.5259 - val_accuracy: 0.0846 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5782 - val_accuracy: 0.8118 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2019 - val_loss: 0.5888 - val_accuracy: 0.0737 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5132 - val_accuracy: 0.0193 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5689 - val_accuracy: 0.0073 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5634 - val_accuracy: 0.0663 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1964 - val_loss: 0.5841 - val_accuracy: 0.0249 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5250 - val_accuracy: 0.0855 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5701 - val_accuracy: 0.0655 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5728 - val_accuracy: 0.8129 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5779 - val_accuracy: 0.0072 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1977 - val_loss: 0.5853 - val_accuracy: 0.8121 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5642 - val_accuracy: 0.0254 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5533 - val_accuracy: 0.0255 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1967 - val_loss: 0.5646 - val_accuracy: 0.0654 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5810 - val_accuracy: 0.0661 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1990 - val_loss: 0.5655 - val_accuracy: 0.0748 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 53/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5502 - val_accuracy: 0.0737 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 54/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1966 - val_loss: 0.5858 - val_accuracy: 0.0085 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 55/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5722 - val_accuracy: 0.0653 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 56/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5833 - val_accuracy: 0.0075 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5454 - val_accuracy: 0.0256 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1997 - val_loss: 0.5066 - val_accuracy: 0.0382 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1965 - val_loss: 0.5463 - val_accuracy: 0.0748 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 60/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5042 - val_accuracy: 0.0803 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 61/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5271 - val_accuracy: 0.0083 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5112 - val_accuracy: 0.0389 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5674 - val_accuracy: 0.0735 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 64/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5628 - val_accuracy: 0.0748 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 65/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.4996 - val_accuracy: 0.8276 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 66/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1980 - val_loss: 0.5696 - val_accuracy: 0.0250 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5880 - val_accuracy: 0.0254 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 68/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5444 - val_accuracy: 0.8129 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 69/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5076 - val_accuracy: 0.0807 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 70/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5571 - val_accuracy: 0.0249 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 71/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5862 - val_accuracy: 0.0735 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 72/100\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1983 - val_loss: 0.5351 - val_accuracy: 0.0743 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5496 - val_accuracy: 0.0752 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 74/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.2001 - val_loss: 0.5089 - val_accuracy: 0.0349 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5773 - val_accuracy: 0.0747 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 76/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5149 - val_accuracy: 0.0851 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 77/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5505 - val_accuracy: 0.8133 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 78/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5366 - val_accuracy: 0.0083 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 79/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.2004 - val_loss: 0.5750 - val_accuracy: 0.0748 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 80/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1989 - val_loss: 0.5395 - val_accuracy: 0.0271 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 81/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5644 - val_accuracy: 0.0737 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 82/100\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1996 - val_loss: 0.5639 - val_accuracy: 0.0751 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 83/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1967 - val_loss: 0.5024 - val_accuracy: 0.0808 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 84/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5340 - val_accuracy: 0.0327 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 85/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5339 - val_accuracy: 0.0717 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 86/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5625 - val_accuracy: 0.0737 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 87/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5564 - val_accuracy: 0.0749 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1975 - val_loss: 0.5699 - val_accuracy: 0.0737 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1966 - val_loss: 0.4996 - val_accuracy: 0.0808 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5209 - val_accuracy: 0.0797 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5072 - val_accuracy: 0.8246 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "4378/4378 - 75s - loss: 0.5005 - accuracy: 0.1970 - val_loss: 0.5053 - val_accuracy: 0.0888 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 93/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5854 - val_accuracy: 0.0262 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5922 - val_accuracy: 0.0076 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5594 - val_accuracy: 0.8118 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "4378/4378 - 74s - loss: 0.5005 - accuracy: 0.1999 - val_loss: 0.5616 - val_accuracy: 0.0250 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 97/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5778 - val_accuracy: 0.0072 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5036 - val_accuracy: 0.0883 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5897 - val_accuracy: 0.8121 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 100/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5886 - val_accuracy: 0.0735 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/100\n",
      "876/876 - 21s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5977 - val_accuracy: 0.0735 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5961 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 3/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5664 - val_accuracy: 0.0651 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 4/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5316 - val_accuracy: 0.0147 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5837 - val_accuracy: 0.8117 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 6/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5859 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5702 - val_accuracy: 0.0737 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 8/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5770 - val_accuracy: 0.0651 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 9/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5076 - val_accuracy: 0.8245 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 10/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5504 - val_accuracy: 0.0260 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 11/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5494 - val_accuracy: 0.0658 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 12/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5318 - val_accuracy: 0.0752 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 13/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5387 - val_accuracy: 0.0280 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 14/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5087 - val_accuracy: 0.0698 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 15/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5603 - val_accuracy: 0.0262 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 16/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5553 - val_accuracy: 0.0743 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 17/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5570 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 18/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5559 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 19/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5259 - val_accuracy: 0.0264 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 20/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5058 - val_accuracy: 0.0867 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 21/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5345 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 22/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5023 - val_accuracy: 0.0232 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 23/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5548 - val_accuracy: 0.0076 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 24/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5613 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 25/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5318 - val_accuracy: 0.0316 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 26/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.4996 - val_accuracy: 0.8264 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 27/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5901 - val_accuracy: 0.0252 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 28/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5945 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 29/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5788 - val_accuracy: 0.0076 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 30/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5717 - val_accuracy: 0.0747 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 31/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5852 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 32/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5577 - val_accuracy: 0.8121 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 33/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1967 - val_loss: 0.5542 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 34/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5042 - val_accuracy: 0.0232 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 35/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5017 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 36/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5250 - val_accuracy: 0.0121 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 37/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5454 - val_accuracy: 0.0274 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 38/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5376 - val_accuracy: 0.0082 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 39/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5389 - val_accuracy: 0.0747 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5675 - val_accuracy: 0.0072 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 41/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5384 - val_accuracy: 0.0249 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 42/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5485 - val_accuracy: 0.0085 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 43/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5312 - val_accuracy: 0.0081 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 44/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5239 - val_accuracy: 0.8190 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 45/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5731 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 46/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5780 - val_accuracy: 0.8129 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 47/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5241 - val_accuracy: 0.0329 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 48/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5297 - val_accuracy: 0.0653 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 49/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5680 - val_accuracy: 0.0662 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 50/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5402 - val_accuracy: 0.0258 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5516 - val_accuracy: 0.0653 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 52/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5259 - val_accuracy: 0.8148 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5163 - val_accuracy: 0.0359 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 54/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5175 - val_accuracy: 0.0321 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 55/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5483 - val_accuracy: 0.0264 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 56/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5284 - val_accuracy: 0.0127 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 57/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5227 - val_accuracy: 0.8144 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 58/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5082 - val_accuracy: 0.8157 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 59/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5174 - val_accuracy: 0.0793 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 60/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5115 - val_accuracy: 0.0852 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 61/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5532 - val_accuracy: 0.8129 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 62/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5454 - val_accuracy: 0.0653 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 63/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5209 - val_accuracy: 0.8123 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 64/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5069 - val_accuracy: 0.0745 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 65/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5511 - val_accuracy: 0.0255 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 66/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5056 - val_accuracy: 0.0717 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 67/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5490 - val_accuracy: 0.0739 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5277 - val_accuracy: 0.0652 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 69/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5385 - val_accuracy: 0.0080 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 70/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5653 - val_accuracy: 0.0740 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 71/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5634 - val_accuracy: 0.0073 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 72/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5659 - val_accuracy: 0.0658 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 73/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5092 - val_accuracy: 0.0782 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 74/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5965 - val_accuracy: 0.0075 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 75/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5874 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 76/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5902 - val_accuracy: 0.0072 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 77/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5847 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 78/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5838 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 79/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5031 - val_accuracy: 0.0883 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 80/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5854 - val_accuracy: 0.0252 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 81/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5900 - val_accuracy: 0.0737 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 82/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5074 - val_accuracy: 0.0809 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 83/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5929 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 84/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5805 - val_accuracy: 0.8116 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 85/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5178 - val_accuracy: 0.0771 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 86/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5140 - val_accuracy: 0.0849 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 87/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5363 - val_accuracy: 0.0300 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 88/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1967 - val_loss: 0.5470 - val_accuracy: 0.0659 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 89/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5381 - val_accuracy: 0.0265 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 90/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5828 - val_accuracy: 0.0739 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 91/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5895 - val_accuracy: 0.0072 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 92/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5907 - val_accuracy: 0.8116 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 93/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5863 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 94/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5746 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 95/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1964 - val_loss: 0.5426 - val_accuracy: 0.8122 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 96/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5046 - val_accuracy: 0.0777 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 97/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5829 - val_accuracy: 0.0249 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 98/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5763 - val_accuracy: 0.0249 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 99/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5712 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 100/100\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5885 - val_accuracy: 0.0653 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/100\n",
      "176/176 - 11s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5855 - val_accuracy: 0.8121 - lr: 0.0010 - 11s/epoch - 65ms/step\n",
      "Epoch 2/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5806 - val_accuracy: 0.0654 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 3/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5001 - val_accuracy: 0.0803 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 4/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5303 - val_accuracy: 0.0652 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 5/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5503 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 6/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5642 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 7/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5735 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 8/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5415 - val_accuracy: 0.0263 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 9/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5760 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 10/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5115 - val_accuracy: 0.0341 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 11/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5212 - val_accuracy: 0.8180 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 12/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5401 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 13/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5639 - val_accuracy: 0.0650 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 14/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5801 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 15/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5890 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 16/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5742 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 17/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5479 - val_accuracy: 0.0096 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 18/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5657 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 19/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5768 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 20/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5793 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 21/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5019 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 22/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5044 - val_accuracy: 0.0894 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 23/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5471 - val_accuracy: 0.8129 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 24/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5641 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 25/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5740 - val_accuracy: 0.0737 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 26/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5406 - val_accuracy: 0.0259 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 27/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1963 - val_loss: 0.5425 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 28/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5656 - val_accuracy: 0.0255 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 29/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5035 - val_accuracy: 0.0409 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 30/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5173 - val_accuracy: 0.0705 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 31/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5370 - val_accuracy: 0.0257 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 32/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5127 - val_accuracy: 0.0364 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 33/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5075 - val_accuracy: 0.8241 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 34/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5113 - val_accuracy: 0.0199 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 35/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5747 - val_accuracy: 0.0657 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 36/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5652 - val_accuracy: 0.0257 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 37/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5813 - val_accuracy: 0.0658 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 38/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5668 - val_accuracy: 0.0747 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 39/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5531 - val_accuracy: 0.0252 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 40/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5013 - val_accuracy: 0.8275 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 41/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5034 - val_accuracy: 0.0794 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 42/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5788 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 43/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5321 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 44/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5135 - val_accuracy: 0.0782 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 45/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5671 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 46/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5024 - val_accuracy: 0.0808 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 47/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5037 - val_accuracy: 0.0880 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 48/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5452 - val_accuracy: 0.0737 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 49/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5448 - val_accuracy: 0.0737 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 50/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5552 - val_accuracy: 0.0669 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 51/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5577 - val_accuracy: 0.0075 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 52/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5597 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 53/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5403 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 54/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5736 - val_accuracy: 0.0737 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 55/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5671 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 56/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5426 - val_accuracy: 0.8125 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 57/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5467 - val_accuracy: 0.0743 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 58/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5313 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 59/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5527 - val_accuracy: 0.0249 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 60/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5496 - val_accuracy: 0.0073 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 61/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5466 - val_accuracy: 0.0072 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 62/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5378 - val_accuracy: 0.8119 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 63/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5392 - val_accuracy: 0.0653 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 64/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5449 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 65/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5774 - val_accuracy: 0.8118 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 66/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5692 - val_accuracy: 0.0651 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 67/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5530 - val_accuracy: 0.0742 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 68/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5744 - val_accuracy: 0.0256 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 69/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5357 - val_accuracy: 0.0278 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 70/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5330 - val_accuracy: 0.0683 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 71/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5842 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 72/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5764 - val_accuracy: 0.8121 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 73/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5708 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 74/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5683 - val_accuracy: 0.8116 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 75/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5724 - val_accuracy: 0.0649 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 76/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5696 - val_accuracy: 0.0249 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 77/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5013 - val_accuracy: 0.0893 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 78/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5585 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 79/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5517 - val_accuracy: 0.8121 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 80/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5555 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 81/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5056 - val_accuracy: 0.0347 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 82/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5562 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 83/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5624 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 84/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5022 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 85/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5244 - val_accuracy: 0.0077 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 86/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5321 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 87/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5647 - val_accuracy: 0.0747 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 88/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5261 - val_accuracy: 0.8129 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 89/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5544 - val_accuracy: 0.0655 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 90/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5010 - val_accuracy: 0.0232 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 91/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5081 - val_accuracy: 0.8154 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 92/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5845 - val_accuracy: 0.0262 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 93/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5780 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 94/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5781 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 95/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5021 - val_accuracy: 0.0232 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 96/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5721 - val_accuracy: 0.0739 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 97/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5832 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 98/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5735 - val_accuracy: 0.0076 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 99/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5772 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 100/100\n",
      "176/176 - 9s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5681 - val_accuracy: 0.0747 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Loss: huber_loss\n",
      "Epoch number: 75\n",
      "fitting with batch size: 20\n",
      "Epoch 1/75\n",
      "4378/4378 - 83s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0823 - val_accuracy: 0.0735 - lr: 0.0010 - 83s/epoch - 19ms/step\n",
      "Epoch 2/75\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0821 - val_accuracy: 0.0254 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 3/75\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0819 - val_accuracy: 0.0657 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 4/75\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0820 - val_accuracy: 0.0743 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 5/75\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0823 - val_accuracy: 0.0735 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 6/75\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0817 - val_accuracy: 0.8118 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 7/75\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0823 - val_accuracy: 0.0072 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 8/75\n",
      "4378/4378 - 85s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0804 - val_accuracy: 0.0408 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 9/75\n",
      "4378/4378 - 85s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0825 - val_accuracy: 0.0258 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 10/75\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.2024 - val_loss: 0.0813 - val_accuracy: 0.8121 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 11/75\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0802 - val_accuracy: 0.0789 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 12/75\n",
      "4378/4378 - 85s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0810 - val_accuracy: 0.8118 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 13/75\n",
      "4378/4378 - 85s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0818 - val_accuracy: 0.8116 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 14/75\n",
      "4378/4378 - 83s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0809 - val_accuracy: 0.8122 - lr: 0.0010 - 83s/epoch - 19ms/step\n",
      "Epoch 15/75\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0829 - val_accuracy: 0.0254 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 16/75\n",
      "4378/4378 - 83s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0822 - val_accuracy: 0.0072 - lr: 0.0010 - 83s/epoch - 19ms/step\n",
      "Epoch 17/75\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0786 - val_accuracy: 0.0231 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 18/75\n",
      "4378/4378 - 83s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0819 - val_accuracy: 0.0250 - lr: 0.0010 - 83s/epoch - 19ms/step\n",
      "Epoch 19/75\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0789 - val_accuracy: 0.8240 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 20/75\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0787 - val_accuracy: 0.8210 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 21/75\n",
      "4378/4378 - 70s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0822 - val_accuracy: 0.0651 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 22/75\n",
      "4378/4378 - 77s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0816 - val_accuracy: 0.0742 - lr: 0.0010 - 77s/epoch - 18ms/step\n",
      "Epoch 23/75\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0821 - val_accuracy: 0.0269 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 24/75\n",
      "4378/4378 - 88s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0816 - val_accuracy: 0.0769 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 25/75\n",
      "4378/4378 - 78s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0814 - val_accuracy: 0.0677 - lr: 0.0010 - 78s/epoch - 18ms/step\n",
      "Epoch 26/75\n",
      "4378/4378 - 94s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0818 - val_accuracy: 0.8119 - lr: 0.0010 - 94s/epoch - 22ms/step\n",
      "Epoch 27/75\n",
      "4378/4378 - 95s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0801 - val_accuracy: 0.0409 - lr: 0.0010 - 95s/epoch - 22ms/step\n",
      "Epoch 28/75\n",
      "4378/4378 - 88s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0821 - val_accuracy: 0.0653 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 29/75\n",
      "4378/4378 - 88s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0822 - val_accuracy: 0.0693 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 30/75\n",
      "4378/4378 - 85s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0815 - val_accuracy: 0.8118 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 31/75\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0817 - val_accuracy: 0.0254 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 32/75\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0789 - val_accuracy: 0.0809 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 33/75\n",
      "4378/4378 - 87s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0789 - val_accuracy: 0.8270 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 34/75\n",
      "4378/4378 - 87s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0814 - val_accuracy: 0.0655 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 35/75\n",
      "4378/4378 - 78s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0814 - val_accuracy: 0.8118 - lr: 0.0010 - 78s/epoch - 18ms/step\n",
      "Epoch 36/75\n",
      "4378/4378 - 91s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0783 - val_accuracy: 0.8274 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 37/75\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0819 - val_accuracy: 0.0661 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 38/75\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0818 - val_accuracy: 0.0651 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 39/75\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.1968 - val_loss: 0.0818 - val_accuracy: 0.0261 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 40/75\n",
      "4378/4378 - 94s - loss: 0.0800 - accuracy: 0.2015 - val_loss: 0.0816 - val_accuracy: 0.0076 - lr: 0.0010 - 94s/epoch - 21ms/step\n",
      "Epoch 41/75\n",
      "4378/4378 - 95s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0818 - val_accuracy: 0.0085 - lr: 0.0010 - 95s/epoch - 22ms/step\n",
      "Epoch 42/75\n",
      "4378/4378 - 94s - loss: 0.0800 - accuracy: 0.2032 - val_loss: 0.0801 - val_accuracy: 0.0381 - lr: 0.0010 - 94s/epoch - 21ms/step\n",
      "Epoch 43/75\n",
      "4378/4378 - 94s - loss: 0.0800 - accuracy: 0.2021 - val_loss: 0.0828 - val_accuracy: 0.0254 - lr: 0.0010 - 94s/epoch - 22ms/step\n",
      "Epoch 44/75\n",
      "4378/4378 - 90s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0786 - val_accuracy: 0.8253 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 45/75\n",
      "4378/4378 - 96s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0820 - val_accuracy: 0.0739 - lr: 0.0010 - 96s/epoch - 22ms/step\n",
      "Epoch 46/75\n",
      "4378/4378 - 90s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0817 - val_accuracy: 0.8129 - lr: 0.0010 - 90s/epoch - 20ms/step\n",
      "Epoch 47/75\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0811 - val_accuracy: 0.8117 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 48/75\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.1970 - val_loss: 0.0786 - val_accuracy: 0.8269 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 49/75\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.1976 - val_loss: 0.0818 - val_accuracy: 0.0739 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 50/75\n",
      "4378/4378 - 92s - loss: 0.0800 - accuracy: 0.2015 - val_loss: 0.0815 - val_accuracy: 0.0086 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 51/75\n",
      "4378/4378 - 92s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0831 - val_accuracy: 0.0764 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 52/75\n",
      "4378/4378 - 94s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0823 - val_accuracy: 0.0748 - lr: 0.0010 - 94s/epoch - 22ms/step\n",
      "Epoch 53/75\n",
      "4378/4378 - 97s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0809 - val_accuracy: 0.8119 - lr: 0.0010 - 97s/epoch - 22ms/step\n",
      "Epoch 54/75\n",
      "4378/4378 - 96s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0808 - val_accuracy: 0.0133 - lr: 0.0010 - 96s/epoch - 22ms/step\n",
      "Epoch 55/75\n",
      "4378/4378 - 95s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0798 - val_accuracy: 0.0398 - lr: 0.0010 - 95s/epoch - 22ms/step\n",
      "Epoch 56/75\n",
      "4378/4378 - 97s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0820 - val_accuracy: 0.0651 - lr: 0.0010 - 97s/epoch - 22ms/step\n",
      "Epoch 57/75\n",
      "4378/4378 - 96s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0816 - val_accuracy: 0.0739 - lr: 0.0010 - 96s/epoch - 22ms/step\n",
      "Epoch 58/75\n",
      "4378/4378 - 96s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0816 - val_accuracy: 0.8118 - lr: 0.0010 - 96s/epoch - 22ms/step\n",
      "Epoch 59/75\n",
      "4378/4378 - 98s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0816 - val_accuracy: 0.0254 - lr: 0.0010 - 98s/epoch - 22ms/step\n",
      "Epoch 60/75\n",
      "4378/4378 - 94s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0809 - val_accuracy: 0.8121 - lr: 0.0010 - 94s/epoch - 22ms/step\n",
      "Epoch 61/75\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0819 - val_accuracy: 0.0738 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 62/75\n",
      "4378/4378 - 91s - loss: 0.0800 - accuracy: 0.1970 - val_loss: 0.0823 - val_accuracy: 0.0649 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 63/75\n",
      "4378/4378 - 88s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0795 - val_accuracy: 0.0894 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 64/75\n",
      "4378/4378 - 92s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0809 - val_accuracy: 0.0704 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 65/75\n",
      "4378/4378 - 91s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0817 - val_accuracy: 0.0250 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 66/75\n",
      "4378/4378 - 92s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0813 - val_accuracy: 0.0748 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 67/75\n",
      "4378/4378 - 91s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0804 - val_accuracy: 0.8164 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 68/75\n",
      "4378/4378 - 92s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0814 - val_accuracy: 0.0762 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 69/75\n",
      "4378/4378 - 89s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0809 - val_accuracy: 0.0823 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 70/75\n",
      "4378/4378 - 89s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0829 - val_accuracy: 0.0074 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 71/75\n",
      "4378/4378 - 88s - loss: 0.0800 - accuracy: 0.2028 - val_loss: 0.0815 - val_accuracy: 0.0259 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 72/75\n",
      "4378/4378 - 88s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0816 - val_accuracy: 0.0742 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 73/75\n",
      "4378/4378 - 90s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0809 - val_accuracy: 0.0258 - lr: 0.0010 - 90s/epoch - 20ms/step\n",
      "Epoch 74/75\n",
      "4378/4378 - 90s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0821 - val_accuracy: 0.0735 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 75/75\n",
      "4378/4378 - 88s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0804 - val_accuracy: 0.8128 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/75\n",
      "876/876 - 31s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0817 - val_accuracy: 0.8129 - lr: 0.0010 - 31s/epoch - 35ms/step\n",
      "Epoch 2/75\n",
      "876/876 - 26s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0813 - val_accuracy: 0.0670 - lr: 0.0010 - 26s/epoch - 30ms/step\n",
      "Epoch 3/75\n",
      "876/876 - 27s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0815 - val_accuracy: 0.8118 - lr: 0.0010 - 27s/epoch - 30ms/step\n",
      "Epoch 4/75\n",
      "876/876 - 26s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0819 - val_accuracy: 0.0651 - lr: 0.0010 - 26s/epoch - 29ms/step\n",
      "Epoch 5/75\n",
      "876/876 - 26s - loss: 0.0800 - accuracy: 0.1968 - val_loss: 0.0817 - val_accuracy: 0.0662 - lr: 0.0010 - 26s/epoch - 29ms/step\n",
      "Epoch 6/75\n",
      "876/876 - 27s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0817 - val_accuracy: 0.0281 - lr: 0.0010 - 27s/epoch - 30ms/step\n",
      "Epoch 7/75\n",
      "876/876 - 26s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0820 - val_accuracy: 0.0076 - lr: 0.0010 - 26s/epoch - 30ms/step\n",
      "Epoch 8/75\n",
      "876/876 - 26s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0819 - val_accuracy: 0.0651 - lr: 0.0010 - 26s/epoch - 30ms/step\n",
      "Epoch 9/75\n",
      "876/876 - 23s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0818 - val_accuracy: 0.0079 - lr: 0.0010 - 23s/epoch - 27ms/step\n",
      "Epoch 10/75\n",
      "876/876 - 23s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0820 - val_accuracy: 0.0651 - lr: 0.0010 - 23s/epoch - 26ms/step\n",
      "Epoch 11/75\n",
      "876/876 - 23s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0794 - val_accuracy: 0.0808 - lr: 0.0010 - 23s/epoch - 26ms/step\n",
      "Epoch 12/75\n",
      "876/876 - 25s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0817 - val_accuracy: 0.0079 - lr: 0.0010 - 25s/epoch - 28ms/step\n",
      "Epoch 13/75\n",
      "876/876 - 23s - loss: 0.0800 - accuracy: 0.1949 - val_loss: 0.0818 - val_accuracy: 0.0741 - lr: 0.0010 - 23s/epoch - 26ms/step\n",
      "Epoch 14/75\n",
      "876/876 - 24s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0808 - val_accuracy: 0.0121 - lr: 0.0010 - 24s/epoch - 27ms/step\n",
      "Epoch 15/75\n",
      "876/876 - 25s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0817 - val_accuracy: 0.0085 - lr: 0.0010 - 25s/epoch - 29ms/step\n",
      "Epoch 16/75\n",
      "876/876 - 24s - loss: 0.0800 - accuracy: 0.1969 - val_loss: 0.0804 - val_accuracy: 0.0856 - lr: 0.0010 - 24s/epoch - 28ms/step\n",
      "Epoch 17/75\n",
      "876/876 - 24s - loss: 0.0800 - accuracy: 0.1960 - val_loss: 0.0816 - val_accuracy: 0.0254 - lr: 0.0010 - 24s/epoch - 27ms/step\n",
      "Epoch 18/75\n",
      "876/876 - 24s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0794 - val_accuracy: 0.8251 - lr: 0.0010 - 24s/epoch - 27ms/step\n",
      "Epoch 19/75\n",
      "876/876 - 24s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0792 - val_accuracy: 0.0894 - lr: 0.0010 - 24s/epoch - 27ms/step\n",
      "Epoch 20/75\n",
      "876/876 - 24s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0791 - val_accuracy: 0.0409 - lr: 0.0010 - 24s/epoch - 27ms/step\n",
      "Epoch 21/75\n",
      "876/876 - 24s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0819 - val_accuracy: 0.0651 - lr: 0.0010 - 24s/epoch - 28ms/step\n",
      "Epoch 22/75\n",
      "876/876 - 25s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0818 - val_accuracy: 0.0079 - lr: 0.0010 - 25s/epoch - 28ms/step\n",
      "Epoch 23/75\n",
      "876/876 - 22s - loss: 0.0800 - accuracy: 0.1969 - val_loss: 0.0813 - val_accuracy: 0.8123 - lr: 0.0010 - 22s/epoch - 25ms/step\n",
      "Epoch 24/75\n",
      "876/876 - 21s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0819 - val_accuracy: 0.0249 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 25/75\n",
      "876/876 - 21s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0820 - val_accuracy: 0.0739 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 26/75\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0817 - val_accuracy: 0.8116 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 27/75\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.2015 - val_loss: 0.0826 - val_accuracy: 0.0254 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 28/75\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0824 - val_accuracy: 0.0254 - lr: 0.0010 - 20s/epoch - 22ms/step\n",
      "Epoch 29/75\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0821 - val_accuracy: 0.0072 - lr: 0.0010 - 20s/epoch - 22ms/step\n",
      "Epoch 30/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0821 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 31/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0821 - val_accuracy: 0.0739 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 32/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0817 - val_accuracy: 0.0655 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 33/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0819 - val_accuracy: 0.0649 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 34/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1968 - val_loss: 0.0818 - val_accuracy: 0.0252 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 35/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0817 - val_accuracy: 0.0735 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 36/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0810 - val_accuracy: 0.8123 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 37/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0819 - val_accuracy: 0.0085 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 38/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0815 - val_accuracy: 0.0252 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 39/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0806 - val_accuracy: 0.0317 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 40/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0820 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 41/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0822 - val_accuracy: 0.0257 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 42/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0818 - val_accuracy: 0.0734 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 43/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0819 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 44/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0817 - val_accuracy: 0.0081 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 45/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0814 - val_accuracy: 0.0320 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 46/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0819 - val_accuracy: 0.0651 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 47/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0812 - val_accuracy: 0.0259 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 48/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0819 - val_accuracy: 0.0100 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 49/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0816 - val_accuracy: 0.8125 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 50/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0812 - val_accuracy: 0.0681 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 51/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0817 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 52/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0815 - val_accuracy: 0.0262 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 53/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0817 - val_accuracy: 0.0072 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 54/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0824 - val_accuracy: 0.0651 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 55/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1961 - val_loss: 0.0825 - val_accuracy: 0.0077 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 56/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0811 - val_accuracy: 0.8121 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 57/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0817 - val_accuracy: 0.0085 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 58/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0791 - val_accuracy: 0.8258 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 59/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0820 - val_accuracy: 0.0651 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 60/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2028 - val_loss: 0.0821 - val_accuracy: 0.0077 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 61/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0817 - val_accuracy: 0.0662 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 62/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0816 - val_accuracy: 0.0658 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 63/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0808 - val_accuracy: 0.8125 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 64/75\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0816 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 65/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0822 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 66/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0817 - val_accuracy: 0.8118 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 67/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0812 - val_accuracy: 0.8116 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 68/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0817 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 69/75\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0805 - val_accuracy: 0.0332 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 70/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0814 - val_accuracy: 0.0252 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 71/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0793 - val_accuracy: 0.0408 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 72/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0790 - val_accuracy: 0.0230 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 73/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0821 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 74/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0824 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 75/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0813 - val_accuracy: 0.0740 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/75\n",
      "176/176 - 13s - loss: 0.0800 - accuracy: 0.1968 - val_loss: 0.0814 - val_accuracy: 0.0743 - lr: 0.0010 - 13s/epoch - 75ms/step\n",
      "Epoch 2/75\n",
      "176/176 - 9s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0807 - val_accuracy: 0.0264 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 3/75\n",
      "176/176 - 9s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0791 - val_accuracy: 0.8272 - lr: 0.0010 - 9s/epoch - 53ms/step\n",
      "Epoch 4/75\n",
      "176/176 - 9s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0791 - val_accuracy: 0.8259 - lr: 0.0010 - 9s/epoch - 52ms/step\n",
      "Epoch 5/75\n",
      "176/176 - 9s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0793 - val_accuracy: 0.0228 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 6/75\n",
      "176/176 - 9s - loss: 0.0800 - accuracy: 0.1970 - val_loss: 0.0796 - val_accuracy: 0.0217 - lr: 0.0010 - 9s/epoch - 51ms/step\n",
      "Epoch 7/75\n",
      "176/176 - 9s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0790 - val_accuracy: 0.8275 - lr: 0.0010 - 9s/epoch - 50ms/step\n",
      "Epoch 8/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0792 - val_accuracy: 0.0888 - lr: 0.0010 - 11s/epoch - 65ms/step\n",
      "Epoch 9/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0801 - val_accuracy: 0.8185 - lr: 0.0010 - 12s/epoch - 69ms/step\n",
      "Epoch 10/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0817 - val_accuracy: 0.0072 - lr: 0.0010 - 12s/epoch - 67ms/step\n",
      "Epoch 11/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0814 - val_accuracy: 0.0738 - lr: 0.0010 - 12s/epoch - 67ms/step\n",
      "Epoch 12/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0816 - val_accuracy: 0.0250 - lr: 0.0010 - 12s/epoch - 68ms/step\n",
      "Epoch 13/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0789 - val_accuracy: 0.8275 - lr: 0.0010 - 12s/epoch - 68ms/step\n",
      "Epoch 14/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0796 - val_accuracy: 0.0228 - lr: 0.0010 - 12s/epoch - 68ms/step\n",
      "Epoch 15/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0793 - val_accuracy: 0.0230 - lr: 0.0010 - 12s/epoch - 68ms/step\n",
      "Epoch 16/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0807 - val_accuracy: 0.8125 - lr: 0.0010 - 12s/epoch - 68ms/step\n",
      "Epoch 17/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0794 - val_accuracy: 0.0795 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 18/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0792 - val_accuracy: 0.0408 - lr: 0.0010 - 11s/epoch - 63ms/step\n",
      "Epoch 19/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0820 - val_accuracy: 0.0651 - lr: 0.0010 - 12s/epoch - 67ms/step\n",
      "Epoch 20/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1971 - val_loss: 0.0809 - val_accuracy: 0.0663 - lr: 0.0010 - 11s/epoch - 60ms/step\n",
      "Epoch 21/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0815 - val_accuracy: 0.8118 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 22/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0822 - val_accuracy: 0.0249 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 23/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0812 - val_accuracy: 0.0740 - lr: 0.0010 - 11s/epoch - 61ms/step\n",
      "Epoch 24/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0806 - val_accuracy: 0.0811 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 25/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0816 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 26/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0818 - val_accuracy: 0.0651 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 27/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0808 - val_accuracy: 0.8119 - lr: 0.0010 - 10s/epoch - 59ms/step\n",
      "Epoch 28/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1966 - val_loss: 0.0816 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 29/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0810 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 30/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0811 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 31/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0813 - val_accuracy: 0.0073 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 32/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0812 - val_accuracy: 0.8118 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 33/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0811 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 34/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0807 - val_accuracy: 0.0681 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 35/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0807 - val_accuracy: 0.0316 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 36/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0818 - val_accuracy: 0.0739 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 37/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0811 - val_accuracy: 0.0662 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 38/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0815 - val_accuracy: 0.0256 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 39/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0816 - val_accuracy: 0.0651 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 40/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0818 - val_accuracy: 0.0252 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 41/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0817 - val_accuracy: 0.0250 - lr: 0.0010 - 11s/epoch - 61ms/step\n",
      "Epoch 42/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0816 - val_accuracy: 0.0654 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 43/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1970 - val_loss: 0.0812 - val_accuracy: 0.0259 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 44/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0804 - val_accuracy: 0.0291 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 45/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0801 - val_accuracy: 0.8155 - lr: 0.0010 - 10s/epoch - 59ms/step\n",
      "Epoch 46/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1965 - val_loss: 0.0793 - val_accuracy: 0.0223 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 47/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0795 - val_accuracy: 0.0784 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 48/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0814 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 49/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0802 - val_accuracy: 0.8150 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 50/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0802 - val_accuracy: 0.0682 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 51/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0794 - val_accuracy: 0.8206 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 52/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0805 - val_accuracy: 0.0690 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 53/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0799 - val_accuracy: 0.0150 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 54/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0802 - val_accuracy: 0.0756 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 55/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0809 - val_accuracy: 0.0253 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 56/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0805 - val_accuracy: 0.8141 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 57/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0804 - val_accuracy: 0.0099 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 58/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0803 - val_accuracy: 0.8144 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 59/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0812 - val_accuracy: 0.0072 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 60/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0812 - val_accuracy: 0.0651 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 61/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0822 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 62/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0816 - val_accuracy: 0.0077 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 63/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1967 - val_loss: 0.0812 - val_accuracy: 0.0073 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 64/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0817 - val_accuracy: 0.0072 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 65/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0818 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 66/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0816 - val_accuracy: 0.0253 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 67/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1968 - val_loss: 0.0809 - val_accuracy: 0.0267 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 68/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0790 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 69/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0793 - val_accuracy: 0.0393 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 70/75\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0805 - val_accuracy: 0.0092 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 71/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0813 - val_accuracy: 0.0653 - lr: 0.0010 - 12s/epoch - 69ms/step\n",
      "Epoch 72/75\n",
      "176/176 - 13s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0803 - val_accuracy: 0.0682 - lr: 0.0010 - 13s/epoch - 73ms/step\n",
      "Epoch 73/75\n",
      "176/176 - 13s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0817 - val_accuracy: 0.8117 - lr: 0.0010 - 13s/epoch - 73ms/step\n",
      "Epoch 74/75\n",
      "176/176 - 13s - loss: 0.0800 - accuracy: 0.1970 - val_loss: 0.0802 - val_accuracy: 0.0319 - lr: 0.0010 - 13s/epoch - 71ms/step\n",
      "Epoch 75/75\n",
      "176/176 - 13s - loss: 0.0800 - accuracy: 0.1970 - val_loss: 0.0813 - val_accuracy: 0.0098 - lr: 0.0010 - 13s/epoch - 74ms/step\n",
      "Epoch number: 100\n",
      "fitting with batch size: 20\n",
      "Epoch 1/100\n",
      "4378/4378 - 105s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0808 - val_accuracy: 0.8159 - lr: 0.0010 - 105s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0813 - val_accuracy: 0.8118 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 3/100\n",
      "4378/4378 - 80s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0811 - val_accuracy: 0.8118 - lr: 0.0010 - 80s/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0797 - val_accuracy: 0.0373 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0822 - val_accuracy: 0.0735 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "4378/4378 - 83s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0812 - val_accuracy: 0.0758 - lr: 0.0010 - 83s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0785 - val_accuracy: 0.8255 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0809 - val_accuracy: 0.0783 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0818 - val_accuracy: 0.0736 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0812 - val_accuracy: 0.8118 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.0767 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0819 - val_accuracy: 0.0252 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0819 - val_accuracy: 0.0652 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0833 - val_accuracy: 0.0651 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0809 - val_accuracy: 0.0125 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0818 - val_accuracy: 0.0262 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0824 - val_accuracy: 0.0673 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0810 - val_accuracy: 0.0656 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0817 - val_accuracy: 0.0739 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 20/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0803 - val_accuracy: 0.0729 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0822 - val_accuracy: 0.0737 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0793 - val_accuracy: 0.0894 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0809 - val_accuracy: 0.0306 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0793 - val_accuracy: 0.0860 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0817 - val_accuracy: 0.8121 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0815 - val_accuracy: 0.0770 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0831 - val_accuracy: 0.0747 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0818 - val_accuracy: 0.0659 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0802 - val_accuracy: 0.8177 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "4378/4378 - 80s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0790 - val_accuracy: 0.0232 - lr: 0.0010 - 80s/epoch - 18ms/step\n",
      "Epoch 31/100\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0821 - val_accuracy: 0.0072 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 32/100\n",
      "4378/4378 - 93s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0816 - val_accuracy: 0.8121 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 33/100\n",
      "4378/4378 - 90s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0799 - val_accuracy: 0.0378 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 34/100\n",
      "4378/4378 - 77s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0802 - val_accuracy: 0.0755 - lr: 0.0010 - 77s/epoch - 18ms/step\n",
      "Epoch 35/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0806 - val_accuracy: 0.8120 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "4378/4378 - 77s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0803 - val_accuracy: 0.8123 - lr: 0.0010 - 77s/epoch - 18ms/step\n",
      "Epoch 37/100\n",
      "4378/4378 - 92s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0820 - val_accuracy: 0.0737 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 38/100\n",
      "4378/4378 - 90s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0818 - val_accuracy: 0.0080 - lr: 0.0010 - 90s/epoch - 20ms/step\n",
      "Epoch 39/100\n",
      "4378/4378 - 91s - loss: 0.0800 - accuracy: 0.2028 - val_loss: 0.0793 - val_accuracy: 0.0894 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "4378/4378 - 82s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0820 - val_accuracy: 0.0734 - lr: 0.0010 - 82s/epoch - 19ms/step\n",
      "Epoch 41/100\n",
      "4378/4378 - 89s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0794 - val_accuracy: 0.0227 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 42/100\n",
      "4378/4378 - 77s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0792 - val_accuracy: 0.0409 - lr: 0.0010 - 77s/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0816 - val_accuracy: 0.0739 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0820 - val_accuracy: 0.0259 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "4378/4378 - 70s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0822 - val_accuracy: 0.0651 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0816 - val_accuracy: 0.0736 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0792 - val_accuracy: 0.0808 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.2021 - val_loss: 0.0798 - val_accuracy: 0.0894 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0817 - val_accuracy: 0.8118 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 50/100\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0825 - val_accuracy: 0.0255 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0821 - val_accuracy: 0.0254 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0818 - val_accuracy: 0.0649 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 53/100\n",
      "4378/4378 - 77s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0815 - val_accuracy: 0.8117 - lr: 0.0010 - 77s/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0780 - val_accuracy: 0.8275 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "4378/4378 - 80s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0820 - val_accuracy: 0.0651 - lr: 0.0010 - 80s/epoch - 18ms/step\n",
      "Epoch 56/100\n",
      "4378/4378 - 83s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0815 - val_accuracy: 0.0651 - lr: 0.0010 - 83s/epoch - 19ms/step\n",
      "Epoch 57/100\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0824 - val_accuracy: 0.0263 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0817 - val_accuracy: 0.0748 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0813 - val_accuracy: 0.8129 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "4378/4378 - 81s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0821 - val_accuracy: 0.0668 - lr: 0.0010 - 81s/epoch - 18ms/step\n",
      "Epoch 61/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0816 - val_accuracy: 0.0661 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0828 - val_accuracy: 0.0252 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0814 - val_accuracy: 0.8121 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 64/100\n",
      "4378/4378 - 85s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0808 - val_accuracy: 0.0796 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 65/100\n",
      "4378/4378 - 87s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0818 - val_accuracy: 0.8129 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 66/100\n",
      "4378/4378 - 89s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0799 - val_accuracy: 0.0894 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 67/100\n",
      "4378/4378 - 92s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0817 - val_accuracy: 0.0739 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "4378/4378 - 87s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0818 - val_accuracy: 0.0739 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 69/100\n",
      "4378/4378 - 87s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0814 - val_accuracy: 0.0747 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 70/100\n",
      "4378/4378 - 85s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0817 - val_accuracy: 0.0074 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 71/100\n",
      "4378/4378 - 87s - loss: 0.0800 - accuracy: 0.1956 - val_loss: 0.0821 - val_accuracy: 0.0074 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 72/100\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0817 - val_accuracy: 0.0739 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 73/100\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0802 - val_accuracy: 0.0847 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 74/100\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.2019 - val_loss: 0.0826 - val_accuracy: 0.0649 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 75/100\n",
      "4378/4378 - 78s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0815 - val_accuracy: 0.0078 - lr: 0.0010 - 78s/epoch - 18ms/step\n",
      "Epoch 76/100\n",
      "4378/4378 - 85s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0825 - val_accuracy: 0.0259 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 77/100\n",
      "4378/4378 - 85s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0828 - val_accuracy: 0.0250 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 78/100\n",
      "4378/4378 - 89s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0802 - val_accuracy: 0.0132 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 79/100\n",
      "4378/4378 - 87s - loss: 0.0800 - accuracy: 0.2018 - val_loss: 0.0812 - val_accuracy: 0.8118 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 80/100\n",
      "4378/4378 - 82s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0823 - val_accuracy: 0.0740 - lr: 0.0010 - 82s/epoch - 19ms/step\n",
      "Epoch 81/100\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0824 - val_accuracy: 0.0653 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 82/100\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0813 - val_accuracy: 0.8116 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 83/100\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0805 - val_accuracy: 0.0144 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 84/100\n",
      "4378/4378 - 81s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0811 - val_accuracy: 0.8149 - lr: 0.0010 - 81s/epoch - 19ms/step\n",
      "Epoch 85/100\n",
      "4378/4378 - 92s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0805 - val_accuracy: 0.0757 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 86/100\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0821 - val_accuracy: 0.0655 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 87/100\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0805 - val_accuracy: 0.0723 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 88/100\n",
      "4378/4378 - 80s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0788 - val_accuracy: 0.0894 - lr: 0.0010 - 80s/epoch - 18ms/step\n",
      "Epoch 89/100\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1976 - val_loss: 0.0805 - val_accuracy: 0.8126 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "4378/4378 - 90s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0795 - val_accuracy: 0.0229 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 91/100\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0808 - val_accuracy: 0.8126 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 92/100\n",
      "4378/4378 - 84s - loss: 0.0800 - accuracy: 0.1969 - val_loss: 0.0810 - val_accuracy: 0.0784 - lr: 0.0010 - 84s/epoch - 19ms/step\n",
      "Epoch 93/100\n",
      "4378/4378 - 86s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0823 - val_accuracy: 0.0261 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 94/100\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0805 - val_accuracy: 0.8179 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1965 - val_loss: 0.0820 - val_accuracy: 0.0074 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0798 - val_accuracy: 0.0894 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 97/100\n",
      "4378/4378 - 81s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0820 - val_accuracy: 0.0653 - lr: 0.0010 - 81s/epoch - 19ms/step\n",
      "Epoch 98/100\n",
      "4378/4378 - 89s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0822 - val_accuracy: 0.0250 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 99/100\n",
      "4378/4378 - 88s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0808 - val_accuracy: 0.0712 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 100/100\n",
      "4378/4378 - 82s - loss: 0.0800 - accuracy: 0.2018 - val_loss: 0.0809 - val_accuracy: 0.8116 - lr: 0.0010 - 82s/epoch - 19ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/100\n",
      "876/876 - 22s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0818 - val_accuracy: 0.0254 - lr: 0.0010 - 22s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0822 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 3/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1965 - val_loss: 0.0793 - val_accuracy: 0.0894 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 4/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0787 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0794 - val_accuracy: 0.0808 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 6/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0817 - val_accuracy: 0.8118 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 7/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0819 - val_accuracy: 0.0252 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 8/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0790 - val_accuracy: 0.0806 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 9/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0795 - val_accuracy: 0.0385 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 10/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0792 - val_accuracy: 0.0865 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 11/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0794 - val_accuracy: 0.0843 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 12/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0799 - val_accuracy: 0.0380 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 13/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0813 - val_accuracy: 0.0701 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 14/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0816 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 15/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0811 - val_accuracy: 0.0750 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 16/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0824 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 17/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0808 - val_accuracy: 0.0143 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 18/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0814 - val_accuracy: 0.8117 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 19/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0815 - val_accuracy: 0.0089 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 20/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0811 - val_accuracy: 0.0076 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 21/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0809 - val_accuracy: 0.0655 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 22/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0814 - val_accuracy: 0.0748 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 23/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0820 - val_accuracy: 0.0252 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 24/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0798 - val_accuracy: 0.0165 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0797 - val_accuracy: 0.8198 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0795 - val_accuracy: 0.8198 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 27/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0802 - val_accuracy: 0.8181 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 28/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0797 - val_accuracy: 0.0855 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 29/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0818 - val_accuracy: 0.0251 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 30/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0784 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 31/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0813 - val_accuracy: 0.8141 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 32/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1961 - val_loss: 0.0813 - val_accuracy: 0.0094 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 33/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0812 - val_accuracy: 0.0740 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 34/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1964 - val_loss: 0.0817 - val_accuracy: 0.0256 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 35/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0817 - val_accuracy: 0.0075 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 36/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0816 - val_accuracy: 0.8120 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 37/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0818 - val_accuracy: 0.0251 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 38/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0822 - val_accuracy: 0.0736 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 39/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0820 - val_accuracy: 0.0649 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 40/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0797 - val_accuracy: 0.0367 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 41/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0817 - val_accuracy: 0.0651 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 42/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0813 - val_accuracy: 0.8131 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 43/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0819 - val_accuracy: 0.0742 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 44/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0817 - val_accuracy: 0.8120 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 45/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0822 - val_accuracy: 0.0076 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 46/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0816 - val_accuracy: 0.0072 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 47/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1966 - val_loss: 0.0819 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 48/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0816 - val_accuracy: 0.0650 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 49/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0819 - val_accuracy: 0.0263 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 50/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0787 - val_accuracy: 0.8272 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0817 - val_accuracy: 0.8119 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 52/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0819 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0815 - val_accuracy: 0.0078 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 54/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0823 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 55/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0825 - val_accuracy: 0.0080 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 56/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0812 - val_accuracy: 0.8120 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 57/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0819 - val_accuracy: 0.0077 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 58/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0820 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 59/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1976 - val_loss: 0.0795 - val_accuracy: 0.0345 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 60/100\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0814 - val_accuracy: 0.0262 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 61/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0803 - val_accuracy: 0.0315 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 62/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0788 - val_accuracy: 0.8275 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 63/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0815 - val_accuracy: 0.8119 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 64/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1971 - val_loss: 0.0822 - val_accuracy: 0.0254 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 65/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0819 - val_accuracy: 0.0745 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 66/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0813 - val_accuracy: 0.0660 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 67/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0818 - val_accuracy: 0.8119 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 68/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1965 - val_loss: 0.0812 - val_accuracy: 0.0283 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 69/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0820 - val_accuracy: 0.0076 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 70/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1967 - val_loss: 0.0812 - val_accuracy: 0.8121 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 71/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0818 - val_accuracy: 0.0744 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 72/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0814 - val_accuracy: 0.0262 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 73/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0814 - val_accuracy: 0.0652 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 74/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0813 - val_accuracy: 0.0260 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 75/100\n",
      "876/876 - 17s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0816 - val_accuracy: 0.8133 - lr: 0.0010 - 17s/epoch - 20ms/step\n",
      "Epoch 76/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1953 - val_loss: 0.0802 - val_accuracy: 0.8150 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 77/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0794 - val_accuracy: 0.0782 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 78/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1964 - val_loss: 0.0793 - val_accuracy: 0.8240 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 79/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0808 - val_accuracy: 0.0738 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 80/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0804 - val_accuracy: 0.0151 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 81/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0818 - val_accuracy: 0.0650 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 82/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0787 - val_accuracy: 0.8255 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 83/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0815 - val_accuracy: 0.0080 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 84/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0819 - val_accuracy: 0.0739 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 85/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0813 - val_accuracy: 0.0652 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 86/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0817 - val_accuracy: 0.0741 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 87/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0822 - val_accuracy: 0.0252 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 88/100\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0822 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 89/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0809 - val_accuracy: 0.8144 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 90/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0817 - val_accuracy: 0.0662 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 91/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0816 - val_accuracy: 0.8129 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 92/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0815 - val_accuracy: 0.8120 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 93/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0816 - val_accuracy: 0.0738 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 94/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0808 - val_accuracy: 0.8119 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 95/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0817 - val_accuracy: 0.0256 - lr: 0.0010 - 20s/epoch - 22ms/step\n",
      "Epoch 96/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0815 - val_accuracy: 0.0253 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 97/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0808 - val_accuracy: 0.0279 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 98/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0801 - val_accuracy: 0.0742 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 99/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0819 - val_accuracy: 0.0747 - lr: 0.0010 - 20s/epoch - 22ms/step\n",
      "Epoch 100/100\n",
      "876/876 - 20s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0820 - val_accuracy: 0.0736 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/100\n",
      "176/176 - 14s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0822 - val_accuracy: 0.0649 - lr: 0.0010 - 14s/epoch - 81ms/step\n",
      "Epoch 2/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0819 - val_accuracy: 0.8116 - lr: 0.0010 - 11s/epoch - 61ms/step\n",
      "Epoch 3/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0819 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 59ms/step\n",
      "Epoch 4/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0816 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 5/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0335 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 6/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0819 - val_accuracy: 0.0651 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0819 - val_accuracy: 0.0737 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 8/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0814 - val_accuracy: 0.8118 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 9/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0820 - val_accuracy: 0.0737 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 10/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0819 - val_accuracy: 0.0252 - lr: 0.0010 - 11s/epoch - 60ms/step\n",
      "Epoch 11/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0816 - val_accuracy: 0.0653 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 12/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1958 - val_loss: 0.0813 - val_accuracy: 0.0661 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 13/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0789 - val_accuracy: 0.8275 - lr: 0.0010 - 11s/epoch - 63ms/step\n",
      "Epoch 14/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0792 - val_accuracy: 0.0216 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 15/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0795 - val_accuracy: 0.0206 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 16/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1971 - val_loss: 0.0800 - val_accuracy: 0.0853 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 17/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1970 - val_loss: 0.0811 - val_accuracy: 0.0661 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 18/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0819 - val_accuracy: 0.0078 - lr: 0.0010 - 11s/epoch - 61ms/step\n",
      "Epoch 19/100\n",
      "176/176 - 9s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0789 - val_accuracy: 0.8274 - lr: 0.0010 - 9s/epoch - 49ms/step\n",
      "Epoch 20/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0817 - val_accuracy: 0.0276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 21/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0816 - val_accuracy: 0.0093 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 22/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0809 - val_accuracy: 0.8140 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 23/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0797 - val_accuracy: 0.0761 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 24/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0813 - val_accuracy: 0.0078 - lr: 0.0010 - 10s/epoch - 54ms/step\n",
      "Epoch 25/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0797 - val_accuracy: 0.0185 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 26/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0798 - val_accuracy: 0.0367 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 27/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0816 - val_accuracy: 0.0656 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 28/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0808 - val_accuracy: 0.0339 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 29/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0814 - val_accuracy: 0.0662 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 30/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0809 - val_accuracy: 0.0751 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 31/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0810 - val_accuracy: 0.0752 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 32/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0813 - val_accuracy: 0.0079 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 33/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0820 - val_accuracy: 0.0249 - lr: 0.0010 - 10s/epoch - 54ms/step\n",
      "Epoch 34/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0814 - val_accuracy: 0.0747 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 35/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0818 - val_accuracy: 0.0085 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 36/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0819 - val_accuracy: 0.0651 - lr: 0.0010 - 11s/epoch - 61ms/step\n",
      "Epoch 37/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0819 - val_accuracy: 0.0252 - lr: 0.0010 - 11s/epoch - 61ms/step\n",
      "Epoch 38/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0817 - val_accuracy: 0.0651 - lr: 0.0010 - 11s/epoch - 63ms/step\n",
      "Epoch 39/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0812 - val_accuracy: 0.8123 - lr: 0.0010 - 11s/epoch - 63ms/step\n",
      "Epoch 40/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1965 - val_loss: 0.0817 - val_accuracy: 0.0252 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 41/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0803 - val_accuracy: 0.0293 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 42/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0813 - val_accuracy: 0.0260 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 43/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1969 - val_loss: 0.0811 - val_accuracy: 0.0687 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 44/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0813 - val_accuracy: 0.0745 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 45/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0808 - val_accuracy: 0.0752 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 46/100\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0811 - val_accuracy: 0.0089 - lr: 0.0010 - 12s/epoch - 68ms/step\n",
      "Epoch 47/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0811 - val_accuracy: 0.0745 - lr: 0.0010 - 11s/epoch - 63ms/step\n",
      "Epoch 48/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0798 - val_accuracy: 0.0779 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 49/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0812 - val_accuracy: 0.0660 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 50/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0816 - val_accuracy: 0.0258 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 51/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1976 - val_loss: 0.0818 - val_accuracy: 0.0657 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 52/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0809 - val_accuracy: 0.0687 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 53/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0814 - val_accuracy: 0.0655 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 54/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1966 - val_loss: 0.0802 - val_accuracy: 0.0150 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 55/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0799 - val_accuracy: 0.0764 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 56/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.8181 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 57/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0814 - val_accuracy: 0.0739 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 58/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0814 - val_accuracy: 0.0740 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 59/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0813 - val_accuracy: 0.0076 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 60/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0816 - val_accuracy: 0.8124 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 61/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0813 - val_accuracy: 0.0743 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 62/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0817 - val_accuracy: 0.0653 - lr: 0.0010 - 11s/epoch - 60ms/step\n",
      "Epoch 63/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1958 - val_loss: 0.0814 - val_accuracy: 0.0740 - lr: 0.0010 - 11s/epoch - 63ms/step\n",
      "Epoch 64/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0817 - val_accuracy: 0.0254 - lr: 0.0010 - 11s/epoch - 65ms/step\n",
      "Epoch 65/100\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0814 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 66ms/step\n",
      "Epoch 66/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0792 - val_accuracy: 0.0231 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 67/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1976 - val_loss: 0.0815 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 68/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1967 - val_loss: 0.0794 - val_accuracy: 0.0891 - lr: 0.0010 - 11s/epoch - 65ms/step\n",
      "Epoch 69/100\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0819 - val_accuracy: 0.0074 - lr: 0.0010 - 12s/epoch - 66ms/step\n",
      "Epoch 70/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0821 - val_accuracy: 0.0072 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 71/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0815 - val_accuracy: 0.0735 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 72/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1951 - val_loss: 0.0820 - val_accuracy: 0.0249 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 73/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0823 - val_accuracy: 0.0250 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 74/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0815 - val_accuracy: 0.8128 - lr: 0.0010 - 11s/epoch - 63ms/step\n",
      "Epoch 75/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0817 - val_accuracy: 0.0264 - lr: 0.0010 - 11s/epoch - 65ms/step\n",
      "Epoch 76/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0815 - val_accuracy: 0.0745 - lr: 0.0010 - 11s/epoch - 65ms/step\n",
      "Epoch 77/100\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0815 - val_accuracy: 0.8132 - lr: 0.0010 - 12s/epoch - 65ms/step\n",
      "Epoch 78/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1966 - val_loss: 0.0792 - val_accuracy: 0.0880 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 79/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0819 - val_accuracy: 0.0252 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 80/100\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0821 - val_accuracy: 0.0735 - lr: 0.0010 - 12s/epoch - 67ms/step\n",
      "Epoch 81/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0812 - val_accuracy: 0.8119 - lr: 0.0010 - 11s/epoch - 61ms/step\n",
      "Epoch 82/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0822 - val_accuracy: 0.0649 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 83/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0820 - val_accuracy: 0.8117 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 84/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0820 - val_accuracy: 0.0649 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 85/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0821 - val_accuracy: 0.0737 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 86/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0820 - val_accuracy: 0.0737 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 87/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0817 - val_accuracy: 0.0074 - lr: 0.0010 - 11s/epoch - 62ms/step\n",
      "Epoch 88/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0821 - val_accuracy: 0.0735 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 89/100\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0821 - val_accuracy: 0.0649 - lr: 0.0010 - 12s/epoch - 66ms/step\n",
      "Epoch 90/100\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0822 - val_accuracy: 0.0735 - lr: 0.0010 - 12s/epoch - 66ms/step\n",
      "Epoch 91/100\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0818 - val_accuracy: 0.8121 - lr: 0.0010 - 12s/epoch - 66ms/step\n",
      "Epoch 92/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0819 - val_accuracy: 0.0074 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 93/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0818 - val_accuracy: 0.0254 - lr: 0.0010 - 11s/epoch - 64ms/step\n",
      "Epoch 94/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0820 - val_accuracy: 0.0076 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 95/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0820 - val_accuracy: 0.0654 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 96/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0819 - val_accuracy: 0.0740 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 97/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1969 - val_loss: 0.0816 - val_accuracy: 0.0085 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 98/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0819 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 58ms/step\n",
      "Epoch 99/100\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0790 - val_accuracy: 0.0408 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 100/100\n",
      "176/176 - 11s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0790 - val_accuracy: 0.0808 - lr: 0.0010 - 11s/epoch - 65ms/step\n",
      "Loss: kullback_leibler_divergence\n",
      "Epoch number: 75\n",
      "fitting with batch size: 20\n",
      "Epoch 1/75\n",
      "4378/4378 - 85s - loss: 1.6096 - accuracy: 0.1987 - val_loss: 1.6107 - val_accuracy: 0.0407 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 2/75\n",
      "4378/4378 - 74s - loss: 1.6096 - accuracy: 0.2029 - val_loss: 1.6070 - val_accuracy: 0.8262 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 3/75\n",
      "4378/4378 - 73s - loss: 1.6096 - accuracy: 0.1971 - val_loss: 1.8462 - val_accuracy: 0.0076 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 4/75\n",
      "4378/4378 - 76s - loss: 1.6096 - accuracy: 0.1975 - val_loss: 1.8540 - val_accuracy: 0.0747 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 5/75\n",
      "4378/4378 - 89s - loss: 1.6096 - accuracy: 0.1997 - val_loss: 1.6900 - val_accuracy: 0.8155 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 6/75\n",
      "4378/4378 - 78s - loss: 1.6096 - accuracy: 0.2000 - val_loss: 1.8225 - val_accuracy: 0.0651 - lr: 0.0010 - 78s/epoch - 18ms/step\n",
      "Epoch 7/75\n",
      "4378/4378 - 73s - loss: 1.6097 - accuracy: 0.1979 - val_loss: 1.8081 - val_accuracy: 0.0249 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 8/75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\UFS\\F2 - Copia\\Conv1\\Conv3_data_augm2.ipynb CÃ©lula: 28\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfitting with batch size: \u001b[39m\u001b[39m{\u001b[39;00mbs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m loss_range[t], optimizer\u001b[39m=\u001b[39madam, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                         epochs\u001b[39m=\u001b[39;49mepochs_range[i], \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                         batch_size\u001b[39m=\u001b[39;49mbatch_range[n], \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                         verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                         validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                         callbacks\u001b[39m=\u001b[39;49m[lrate])\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     n \u001b[39m=\u001b[39m n\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/UFS/F2%20-%20Copia/Conv1/Conv3_data_augm2.ipynb#X40sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m n\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m    \n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#epochs = 0\n",
    "batch_range = [20, 100, 500]#20, 100, 500, 1500, 2500\n",
    "epochs_range= [75,100]#25,50,75,100\n",
    "loss_range=['categorical_crossentropy','binary_crossentropy','huber_loss','kullback_leibler_divergence','poisson','kullback_leibler_divergence']\n",
    "n=0\n",
    "i=0\n",
    "t=0\n",
    "#optimizer_range= [adamax,adam]\n",
    "#itertools\n",
    "for lsr in loss_range:\n",
    "    print(f\"Loss: {loss_range[t]}\")\n",
    "    for ep in epochs_range:\n",
    "        print(f\"Epoch number: {ep}\")\n",
    "        for bs in batch_range:\n",
    "            print(f\"fitting with batch size: {bs}\")\n",
    "            model.compile(loss= loss_range[t], optimizer=adam, metrics=['accuracy'])\n",
    "            history = model.fit(X_train, y_train, \n",
    "                                epochs=epochs_range[i], \n",
    "                                batch_size=batch_range[n], \n",
    "                                verbose=2, \n",
    "                                validation_data=(X_test, y_test), \n",
    "                                callbacks=[lrate])\n",
    "            n = n+1\n",
    "        n=0    \n",
    "        i=i+1\n",
    "    i=0\n",
    "    t=t + 1\n",
    "t= 0       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "d43023d26a87e3c4702b96bea5962c990c76aa0a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, batch_size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "20cfe7f5891e3c26c599fa4cd728ac0a499ac70e",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87     18118\n",
      "           1       0.18      0.69      0.28       556\n",
      "           2       0.58      0.80      0.67      1448\n",
      "           3       0.10      0.75      0.17       162\n",
      "           4       0.76      0.90      0.83      1608\n",
      "\n",
      "    accuracy                           0.79     21892\n",
      "   macro avg       0.52      0.79      0.56     21892\n",
      "weighted avg       0.91      0.79      0.83     21892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "017f2431a45766fb0d4b2ef17ce613c1142ca085",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking-based average precision : 0.884\n",
      "Ranking loss : 0.072\n",
      "Coverage_error : 1.287\n"
     ]
    }
   ],
   "source": [
    "print(\"ranking-based average precision : {:.3f}\".format(label_ranking_average_precision_score(y_test, y_pred)))\n",
    "print(\"Ranking loss : {:.3f}\".format(label_ranking_loss(y_test, y_pred)))\n",
    "print(\"Coverage_error : {:.3f}\".format(coverage_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],normalize=True,\n",
    "                      title='Confusion matrix, with normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "RECALL = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "SPECIFICITY = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PRECISION = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "#F1-score\n",
    "F1 = 2*((RECALL*PRECISION)/(RECALL+PRECISION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 20ms/step - loss: 0.7355 - accuracy: 0.7908\n",
      "44/44 [==============================] - 1s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Accuracy: 73.55%\n",
      "Accuracy: 79.08%\n",
      "Precision: 51.87%\n",
      "Specificity: 94.13%\n",
      "Recall :78.62%\n",
      "F1-Score :56.42%\n",
      "Recall:78.62%\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median\n",
    "from tkinter import N\n",
    "scores = model.evaluate((X_test), y_test, batch_size = 500)\n",
    "scores2 = model.evaluate(X_test, y_pred, batch_size = 500)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[0]*100))\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "PRE = mean(PRECISION)\n",
    "print(\"Precision: %.2f%%\"% (PRE*100))\n",
    "#print(\"Precision: \", PRECISION)\n",
    "SPE = mean(SPECIFICITY)\n",
    "print(\"Specificity: %.2f%%\"% (SPE*100))\n",
    "#print(\"Specificity\", SPECIFICITY)\n",
    "RE = mean(RECALL)\n",
    "print(\"Recall :%.2f%%\"% (RE*100))\n",
    "#print(\"Recall\", RECALL)\n",
    "#print(\"F1: \", F1)\n",
    "F1S = mean(F1)\n",
    "print(\"F1-Score :%.2f%%\"% (F1S*100))\n",
    "Z= mean(1-FNR)*100\n",
    "print(\"Recall:%.2f%%\"%Z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e06ff7da33dc9620448857a90ad8b5f428f0d573d205a934d2841c8aee45ea32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
