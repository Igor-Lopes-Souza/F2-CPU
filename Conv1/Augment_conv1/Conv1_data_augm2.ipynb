{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mitbih_test.csv', 'mitbih_test.csv.zip', 'mitbih_train.csv', 'mitbih_train.csv.zip', 'ptbdb_abnormal.csv', 'ptbdb_abnormal.csv.zip', 'ptbdb_normal.csv', 'ptbdb_normal.csv.zip']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed0\n",
    "# For example, here's several helpful packages to load in \n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import pickle\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Softmax, Add, Flatten, Activation , Dropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, Adamax,SGD\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"C:/Users/Usuario/Documents/F2 - Copia/database\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"C:/Users/Usuario/Documents/F2 - Copia/database/mitbih_train.csv\", header=None)\n",
    "test_df = pd.read_csv(\"C:/Users/Usuario/Documents/F2 - Copia/database/mitbih_test.csv\", header=None)\n",
    "#df = pd.concat([df, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "494fc8a26ba40beb73fc1a4f7b219b213fb7705e",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.154412</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.085784</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.356808</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.977941  0.926471  0.681373  0.245098  0.154412  0.191176  0.151961   \n",
       "1  0.960114  0.863248  0.461538  0.196581  0.094017  0.125356  0.099715   \n",
       "2  1.000000  0.659459  0.186486  0.070270  0.070270  0.059459  0.056757   \n",
       "3  0.925414  0.665746  0.541436  0.276243  0.196133  0.077348  0.071823   \n",
       "4  0.967136  1.000000  0.830986  0.586854  0.356808  0.248826  0.145540   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.085784  0.058824  0.049020  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.088319  0.074074  0.082621  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.043243  0.054054  0.045946  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.060773  0.066298  0.058011  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.089202  0.117371  0.150235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "5281cb19f54f3bd379f875c24ae52b3b15fcafaf",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87554 entries, 0 to 87553\n",
      "Columns: 188 entries, 0 to 187\n",
      "dtypes: float64(188)\n",
      "memory usage: 125.6 MB\n",
      "17510\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "dataset_row = train_df.shape[0]\n",
    "dataset_size= int(dataset_row/5)\n",
    "print(dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    72471\n",
      "4     6431\n",
      "2     5788\n",
      "1     2223\n",
      "3      641\n",
      "Name: 187, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df[187]=train_df[187].astype(int)\n",
    "equilibre= train_df[187].value_counts()\n",
    "print(equilibre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "0fac0fb658ea34b48055838b4ad85078e883360d",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_df[187].value_counts()\n",
    "equilibre = train_df[187].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "plt.pie(equilibre, labels=['n','q','v','s','f'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "k=72471\n",
    "#dataset_size= 2000\n",
    "df_1=train_df[train_df[187]==1]\n",
    "df_2=train_df[train_df[187]==2]\n",
    "df_3=train_df[train_df[187]==3]\n",
    "df_4=train_df[train_df[187]==4]\n",
    "df_0=(train_df[train_df[187]==0]).sample(n=dataset_size,random_state=42)\n",
    "\n",
    "df_1_upsample=resample(df_1,replace=True,n_samples=dataset_size,random_state=123)\n",
    "df_2_upsample=resample(df_2,replace=True,n_samples=dataset_size,random_state=124)\n",
    "df_3_upsample=resample(df_3,replace=True,n_samples=dataset_size,random_state=125)\n",
    "df_4_upsample=resample(df_4,replace=True,n_samples=dataset_size,random_state=126)\n",
    "\n",
    "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17510\n",
      "1    17510\n",
      "2    17510\n",
      "3    17510\n",
      "4    17510\n",
      "Name: 187, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "equilibre=train_df[187].value_counts()\n",
    "print(equilibre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(equilibre, labels=['n','q','v','s','f'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "147b7604bd8a389d7f6aa111f38ae308af7c4eb7",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "M = train_df.values\n",
    "X = M[:, :-1]\n",
    "y = M[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "504d95532114efa4cc581d80bf02159c3ce519c6",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#del train_df\n",
    "#del test_df\n",
    "#del M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(signal):\n",
    "    noise=np.random.normal(0,0.5,186)\n",
    "    return (signal+noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tempo=c.iloc[0,:186]\n",
    "#bruiter=add_gaussian_noise(tempo)\n",
    "\n",
    "#plt.subplot(2,1,1)\n",
    "#plt.plot(c.iloc[0,:186])\n",
    "\n",
    "#plt.subplot(2,1,2)\n",
    "#plt.plot(bruiter)\n",
    "\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train_df[187]\n",
    "target_test=test_df[187]\n",
    "y_train=to_categorical(target_train)\n",
    "y_test=to_categorical(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df.iloc[:,:186].values\n",
    "X_test=test_df.iloc[:,:186].values\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i,:186]= add_gaussian_noise(X_train[i,:186])\n",
    "X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
    "X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train_df[187]\n",
    "target_test=test_df[187]\n",
    "y_train=to_categorical(target_train)\n",
    "y_test=to_categorical(target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c269ab78773e4b5a960a5e55d2b48c53d5f9c446"
   },
   "source": [
    "# Data augmentation\n",
    "\n",
    "To train properly the model, we sould have to augment all data to the same level. Nevertheless, for a first try, we will just augment the smallest class to the same level as class 1. With that we will be able to have a test set of around 5x800 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c42605d020fd51885437f4af3cf10cebbeafc9bb"
   },
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "16c106c2702045790367fc49d7223560fc613d75",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (87550, 186, 1)\n",
      "y_train (87550, 5)\n",
      "X_test (21892, 186, 1)\n",
      "y_test (21892, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4de23b85abe34a726eab268171da0e827bafa35"
   },
   "source": [
    "# Model\n",
    "\n",
    "Now let's re-create the model from the ArXiv Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "fb0dc9775ddfa761c0ad948d59020fcbd2681c57",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_obs, feature, depth = X_train.shape\n",
    "batch_size = 1500\n",
    "#batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "e70fab0b07290e042ba9cd7c6cba37462a457b03",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 186, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 182, 32)      192         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 182, 32)      5152        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 182, 32)      0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 182, 32)      5152        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 182, 32)      0           ['conv1d_2[0][0]',               \n",
      "                                                                  'conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 182, 32)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 89, 32)       0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 89, 32)       5152        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 89, 32)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 89, 32)       5152        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 89, 32)       0           ['conv1d_4[0][0]',               \n",
      "                                                                  'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 89, 32)       0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 43, 32)      0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 43, 32)       5152        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 43, 32)       0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 43, 32)       5152        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 43, 32)       0           ['conv1d_6[0][0]',               \n",
      "                                                                  'max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 43, 32)       0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 20, 32)      0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 20, 32)       5152        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 20, 32)       0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 20, 32)       5152        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 20, 32)       0           ['conv1d_8[0][0]',               \n",
      "                                                                  'max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 20, 32)       0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 8, 32)       0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 8, 32)        5152        ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 8, 32)        0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 8, 32)        5152        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 32)        0           ['conv1d_10[0][0]',              \n",
      "                                                                  'max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 8, 32)        0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 2, 32)       0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2, 32)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           2080        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 32)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           1056        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5)            165         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 5)            0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 55,013\n",
      "Trainable params: 55,013\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inp = Input(shape=(feature, depth))\n",
    "C = Conv1D(filters=32, kernel_size=5, strides=1)(inp)\n",
    "C11 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(C)\n",
    "A11 = Activation('softmax')(C11)\n",
    "C12 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A11)\n",
    "S11 = Add()([C12, C])\n",
    "A12 = Activation('softmax')(S11)\n",
    "M11 = MaxPooling1D(pool_size=5, strides=2)(A12)\n",
    "\n",
    "\n",
    "C21 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M11)\n",
    "A21 = Activation('softmax')(C21)\n",
    "C22 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A21)\n",
    "S21 = Add()([C22, M11])\n",
    "A22 = Activation('softmax')(S21)\n",
    "M21 = MaxPooling1D(pool_size=5, strides=2)(A22)\n",
    "\n",
    "\n",
    "C31 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M21)\n",
    "A31 = Activation('softmax')(C31)\n",
    "C32 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A31)\n",
    "S31 = Add()([C32, M21])\n",
    "A32 = Activation('softmax')(S31)\n",
    "M31 = MaxPooling1D(pool_size=5, strides=2)(A32)\n",
    "\n",
    "\n",
    "C41 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M31)\n",
    "A41 = Activation('softmax')(C41)\n",
    "C42 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A41)\n",
    "S41 = Add()([C42, M31])\n",
    "A42 = Activation('softmax')(S41)\n",
    "M41 = MaxPooling1D(pool_size=5, strides=2)(A42)\n",
    "\n",
    "\n",
    "C51 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M41)\n",
    "A51 = Activation('softmax')(C51)\n",
    "C52 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A51)\n",
    "S51 = Add()([C52, M41])\n",
    "A52 = Activation('softmax')(S51)\n",
    "M51 = MaxPooling1D(pool_size=5, strides=2)(A52)\n",
    "\n",
    "M52 = (Dropout(0.25))(M51)\n",
    "\n",
    "F1 = Flatten()(M52)\n",
    "\n",
    "D1 = Dense(32)(F1)\n",
    "A6 = Activation('softmax')(D1)\n",
    "D2 = Dense(32)(A6)\n",
    "D3 = Dense(5)(D2)\n",
    "A7 = Softmax()(D3)\n",
    "\n",
    "model = Model(inputs=inp, outputs=A7)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "fdc0d8aa8475330af8d8e652d0b9ce214da66956",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    k = 0.75\n",
    "    t = n_obs//(10000 * batch_size)  # every epoch we do n_obs/batch_size iteration\n",
    "    lrate = initial_lrate * math.exp(-k*t)\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(exp_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "abcd2f0e8488c8f3b33cd6ed9ca7fd60fa44404b",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "adam3 = SGD(learning_rate = 0.01)\n",
    "adam2 = Adamax(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "adam = Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "812e637ae56f6a4be9c8e98d3b501cfb11ef78cb",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "1e6ef643f6a55ab5b3c1b46126832c3ac45a6a2b",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: 0\n",
      "Loss: categorical_crossentropy\n",
      "Epoch number: 25\n",
      "fitting with batch size: 20\n",
      "Epoch 1/25\n",
      "4378/4378 - 82s - loss: 1.6095 - accuracy: 0.2008 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 82s/epoch - 19ms/step\n",
      "Epoch 2/25\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6116 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 3/25\n",
      "4378/4378 - 76s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6146 - val_accuracy: 0.0254 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 4/25\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1969 - val_loss: 1.6076 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 5/25\n",
      "4378/4378 - 70s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6048 - val_accuracy: 0.8276 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 6/25\n",
      "4378/4378 - 70s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 7/25\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6131 - val_accuracy: 0.0735 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 8/25\n",
      "4378/4378 - 72s - loss: 1.6095 - accuracy: 0.1968 - val_loss: 1.6140 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 9/25\n",
      "4378/4378 - 70s - loss: 1.6095 - accuracy: 0.1959 - val_loss: 1.6171 - val_accuracy: 0.0661 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 10/25\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6157 - val_accuracy: 0.0254 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 11/25\n",
      "4378/4378 - 72s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6086 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 12/25\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.2004 - val_loss: 1.6059 - val_accuracy: 0.0735 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 13/25\n",
      "4378/4378 - 70s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6037 - val_accuracy: 0.8276 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 14/25\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6076 - val_accuracy: 0.0735 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 15/25\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 1.6140 - val_accuracy: 0.0254 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 16/25\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6124 - val_accuracy: 0.0074 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 17/25\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6118 - val_accuracy: 0.0735 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 18/25\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6063 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 19/25\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6003 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 20/25\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6142 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 21/25\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 1.6141 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 22/25\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 1.6125 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 23/25\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6106 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 24/25\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1972 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 25/25\n",
      "4378/4378 - 67s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 1.6135 - val_accuracy: 0.0074 - lr: 0.0010 - 67s/epoch - 15ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/25\n",
      "876/876 - 21s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6114 - val_accuracy: 0.0074 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 2/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6107 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 3/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6091 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 4/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 5/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 1.6087 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 6/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 7/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 8/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1956 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 9/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 10/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 11/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 12/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 13/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1970 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 14/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 15/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.2001 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 16/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1969 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 17/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 18/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1972 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 19/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1964 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 20/25\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1966 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 21/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 22/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 23/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 24/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 25/25\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/25\n",
      "176/176 - 13s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 13s/epoch - 72ms/step\n",
      "Epoch 2/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2018 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 3/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6100 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 4/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6101 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 5/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6102 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 6/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 8/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 9/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2011 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 10/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 11/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 12/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 13/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 14/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 15/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 16/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1967 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 17/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 18/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1973 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 19/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 20/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 21/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 22/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 23/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 24/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 25/25\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/25\n",
      "59/59 - 12s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 202ms/step\n",
      "Epoch 2/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2022 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 3/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 4/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 5/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 6/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2021 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 7/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 8/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 9/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 10/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 11/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 12/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 13/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2025 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 14/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 15/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 16/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2010 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 17/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 18/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 19/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 20/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2013 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 21/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 22/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 23/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 24/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2021 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 25/25\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/25\n",
      "36/36 - 12s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 325ms/step\n",
      "Epoch 2/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2022 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 3/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 4/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 5/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2025 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 6/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 7/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 8/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 9/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 10/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2022 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 11/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 12/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 13/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 14/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 15/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 16/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 17/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6100 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 18/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6100 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 19/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6100 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 20/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6101 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 21/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6100 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 22/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 23/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6101 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 24/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6100 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 25/25\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6100 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch number: 50\n",
      "fitting with batch size: 20\n",
      "Epoch 1/50\n",
      "4378/4378 - 70s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6112 - val_accuracy: 0.0661 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 2/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6077 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6128 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6150 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 6/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2005 - val_loss: 1.6106 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "4378/4378 - 67s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6076 - val_accuracy: 0.0735 - lr: 0.0010 - 67s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 1.6062 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2006 - val_loss: 1.6165 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2009 - val_loss: 1.6024 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6106 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 12/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6027 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 14/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 1.6107 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "4378/4378 - 67s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 1.6038 - val_accuracy: 0.8276 - lr: 0.0010 - 67s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 1.6129 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6082 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 19/50\n",
      "4378/4378 - 67s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 1.6079 - val_accuracy: 0.0254 - lr: 0.0010 - 67s/epoch - 15ms/step\n",
      "Epoch 20/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6090 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2011 - val_loss: 1.6087 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6030 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 23/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 1.6037 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 24/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6103 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 25/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 1.6059 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 26/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6074 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 27/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6057 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 28/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6049 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 29/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6136 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 1.6080 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 31/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1956 - val_loss: 1.6067 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 32/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6105 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 33/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6050 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 34/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 1.6119 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 35/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 1.6181 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 36/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 37/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 1.6102 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 38/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6090 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 39/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6160 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 40/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6060 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 41/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 1.6133 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 42/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 1.6044 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 43/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 1.6080 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 44/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 1.6117 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 45/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6107 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 46/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6065 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 47/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1968 - val_loss: 1.6067 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 48/50\n",
      "4378/4378 - 67s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6080 - val_accuracy: 0.0735 - lr: 0.0010 - 67s/epoch - 15ms/step\n",
      "Epoch 49/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 1.6114 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 50/50\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/50\n",
      "876/876 - 20s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 2/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6086 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 3/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1970 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 4/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 5/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6104 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 6/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 1.6103 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 7/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6100 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 8/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6087 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 9/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 10/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 11/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 12/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6093 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 13/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 14/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 15/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1967 - val_loss: 1.6091 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 16/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 17/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 18/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 19/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 20/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 21/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1962 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 22/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 23/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 24/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 25/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 26/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 27/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6090 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 28/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 29/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 30/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 31/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6085 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 32/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 33/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 34/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 35/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 36/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 37/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 38/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6092 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 39/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1965 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 40/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 41/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6083 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 42/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1966 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 43/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6089 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 44/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 45/50\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6099 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 46/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6093 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 47/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6090 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 48/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6091 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 49/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6091 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 50/50\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6091 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/50\n",
      "176/176 - 12s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 12s/epoch - 67ms/step\n",
      "Epoch 2/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 3/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 4/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 5/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6091 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 6/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 8/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 9/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6091 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 10/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 11/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 12/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1972 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 13/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6091 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 14/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 15/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 59ms/step\n",
      "Epoch 16/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 17/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2016 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 18/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 19/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 20/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1964 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 21/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2010 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 22/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 23/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 24/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 25/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6093 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 26/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1969 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 27/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 28/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 29/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2028 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 30/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 31/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 32/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 33/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 34/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1971 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 35/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 36/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 37/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 38/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 39/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 40/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 41/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1967 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 42/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 43/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 44/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 45/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 46/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 47/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 48/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6093 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 49/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 50/50\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/50\n",
      "59/59 - 11s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 11s/epoch - 185ms/step\n",
      "Epoch 2/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 3/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 4/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 5/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 6/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2010 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 7/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 8/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 9/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2014 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 10/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 11/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 12/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 13/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 14/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 15/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 16/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2025 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 17/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 18/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 19/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 20/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2011 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 21/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 22/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 23/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 24/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 25/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 26/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 27/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 28/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 29/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 30/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 31/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 32/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 33/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2014 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 34/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 35/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 36/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 37/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 38/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 39/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 40/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 41/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2021 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 42/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 43/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 44/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 45/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 46/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 47/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 48/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 49/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 50/50\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/50\n",
      "36/36 - 11s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 11s/epoch - 306ms/step\n",
      "Epoch 2/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2020 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 3/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 4/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 5/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 6/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 7/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6102 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 8/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6102 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 9/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6103 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 10/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6102 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 11/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 12/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 13/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 14/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 15/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 16/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 17/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2016 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 18/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 19/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 20/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 21/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 22/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 23/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2021 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 24/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 25/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 26/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 27/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1973 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 28/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2019 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 29/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6092 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 30/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6091 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 31/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6091 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 32/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 33/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 34/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 35/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2019 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 36/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 37/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 38/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 39/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 40/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2011 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 41/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 42/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 43/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 44/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 45/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 46/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 47/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 48/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 49/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 50/50\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch number: 75\n",
      "fitting with batch size: 20\n",
      "Epoch 1/75\n",
      "4378/4378 - 70s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6067 - val_accuracy: 0.8276 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 2/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6093 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 3/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 1.6082 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 4/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6021 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 5/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6075 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 6/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 1.6077 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 7/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6123 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 8/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6114 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 9/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6057 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 10/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.2002 - val_loss: 1.6142 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 11/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.2011 - val_loss: 1.6058 - val_accuracy: 0.0735 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 12/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6101 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 13/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6066 - val_accuracy: 0.0735 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 14/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6175 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 15/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6064 - val_accuracy: 0.0254 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 16/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 1.6069 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 17/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6114 - val_accuracy: 0.0735 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 18/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6132 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 19/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6064 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 20/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6110 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 21/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6143 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 22/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6062 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 23/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 1.6068 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 24/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 25/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6110 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 26/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1968 - val_loss: 1.6069 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 27/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 1.6140 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 28/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6119 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 29/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6041 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 30/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6119 - val_accuracy: 0.0254 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 31/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6074 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 32/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6123 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 33/75\n",
      "4378/4378 - 72s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6073 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 34/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6054 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 35/75\n",
      "4378/4378 - 72s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6119 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 36/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6134 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 37/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6112 - val_accuracy: 0.0735 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 38/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.2005 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 39/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6089 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 40/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.2002 - val_loss: 1.6138 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 41/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 42/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.2003 - val_loss: 1.6068 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 43/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 1.6129 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 44/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6023 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 45/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1963 - val_loss: 1.6086 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 46/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6058 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 47/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1962 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 48/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6071 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 49/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6139 - val_accuracy: 0.0735 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 50/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6118 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 51/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1972 - val_loss: 1.6176 - val_accuracy: 0.0254 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 52/75\n",
      "4378/4378 - 70s - loss: 1.6095 - accuracy: 0.1960 - val_loss: 1.6099 - val_accuracy: 0.0254 - lr: 0.0010 - 70s/epoch - 16ms/step\n",
      "Epoch 53/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6048 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 54/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 1.6141 - val_accuracy: 0.0254 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 55/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6072 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 56/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6086 - val_accuracy: 0.0254 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 57/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6045 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 58/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 1.6105 - val_accuracy: 0.0735 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 59/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.5988 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 60/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 1.6061 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 61/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6028 - val_accuracy: 0.0735 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 62/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 1.6058 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 63/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1964 - val_loss: 1.6121 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 64/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1964 - val_loss: 1.6063 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 65/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 1.6069 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 66/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 1.6130 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 67/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 1.6078 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 68/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1970 - val_loss: 1.6069 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 69/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6165 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 70/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6058 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 71/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 72/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6125 - val_accuracy: 0.0254 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 73/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 74/75\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 1.6033 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 75/75\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6110 - val_accuracy: 0.0254 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/75\n",
      "876/876 - 20s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6101 - val_accuracy: 0.0254 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 2/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 1.6103 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 3/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 4/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6099 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 5/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 6/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6100 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 7/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1958 - val_loss: 1.6101 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 8/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6106 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 9/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2011 - val_loss: 1.6100 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 10/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 1.6098 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 11/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6099 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 12/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1961 - val_loss: 1.6101 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 13/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6102 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 14/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1972 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 15/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 16/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 17/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6087 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 18/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 19/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 20/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 21/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1972 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 22/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 23/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 24/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 25/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 26/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6093 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 27/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 28/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 1.6090 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 29/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6092 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 30/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1969 - val_loss: 1.6091 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 31/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 32/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 33/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 34/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 35/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1967 - val_loss: 1.6104 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 36/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 37/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6092 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 38/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 39/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 40/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1970 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 41/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1972 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 42/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 43/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 44/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1968 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 45/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 46/75\n",
      "876/876 - 20s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 47/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6102 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 48/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 49/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6085 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 50/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 51/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 52/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1963 - val_loss: 1.6092 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 53/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 54/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 55/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6085 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 56/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 57/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 58/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6092 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 59/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 60/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 61/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 62/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 63/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 64/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 65/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 66/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 67/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 68/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 69/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 70/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 71/75\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 1.6101 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 72/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 73/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 74/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 75/75\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/75\n",
      "176/176 - 12s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6093 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 69ms/step\n",
      "Epoch 2/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 3/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 4/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 5/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 6/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 8/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 9/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 10/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 11/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 12/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1970 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 13/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 14/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 15/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 16/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2017 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 17/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 18/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6093 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 19/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 20/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 21/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 22/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 23/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 24/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 25/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 26/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 27/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 28/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 29/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 30/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 31/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 32/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 33/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 34/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 35/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 36/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 37/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 38/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2013 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 39/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 40/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 41/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 42/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 43/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 44/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 45/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 46/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 47/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 48/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 49/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 50/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 51/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 52/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 53/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 54/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 55/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 56/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 57/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 58/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2019 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 59/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 60/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1969 - val_loss: 1.6099 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 61/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1971 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 62/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 63/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 64/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 65/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1967 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 66/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 67/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 68/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 69/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 70/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6098 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 71/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 72/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 73/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1972 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 74/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6098 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 75/75\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/75\n",
      "59/59 - 11s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 11s/epoch - 185ms/step\n",
      "Epoch 2/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2013 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 3/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 4/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 5/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 6/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 7/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 8/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 9/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 10/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1972 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 11/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 12/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2018 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 13/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 14/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 15/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 16/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 17/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2011 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 18/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 19/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 20/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2026 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 21/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 22/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1965 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 23/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2018 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 24/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 25/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 26/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 27/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 28/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 29/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 30/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 31/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 32/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 33/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 34/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 35/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 36/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 37/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 38/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2021 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 39/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 40/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2011 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 41/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 42/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 43/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 44/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 45/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 46/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2011 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 47/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 48/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 49/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 50/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 51/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 52/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 53/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 54/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 55/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 56/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 57/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1967 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 58/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 59/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 60/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1973 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 61/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1971 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 62/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 63/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 64/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 65/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 66/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 67/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 68/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 69/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 70/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 71/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 72/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 73/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2023 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 74/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 75/75\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/75\n",
      "36/36 - 11s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 11s/epoch - 296ms/step\n",
      "Epoch 2/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2015 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 3/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2013 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 4/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2031 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 5/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 6/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 7/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 8/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2017 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 9/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 10/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2017 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 11/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 12/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2013 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 13/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 14/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 15/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 16/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 17/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 18/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2011 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 19/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 20/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 21/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 22/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2015 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 23/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6100 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 24/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 25/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 26/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 27/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 28/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 29/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2016 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 30/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 31/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 32/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 33/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 34/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 35/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 36/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6101 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 37/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 38/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6104 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 39/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2020 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 40/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 41/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6106 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 42/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6105 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 43/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 44/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 45/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 46/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 47/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 48/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 49/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 50/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 51/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2014 - val_loss: 1.6101 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 52/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6101 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 53/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2025 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 54/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 55/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 56/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6101 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 57/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 58/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 59/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2016 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 239ms/step\n",
      "Epoch 60/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 61/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 62/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 63/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 64/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2013 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 65/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 66/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 67/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 68/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 69/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 70/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 71/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2010 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 72/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1971 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 73/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 74/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 75/75\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch number: 100\n",
      "fitting with batch size: 20\n",
      "Epoch 1/100\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6009 - val_accuracy: 0.8276 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6070 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6082 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 1.6038 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 5/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6040 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6140 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6123 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 8/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1971 - val_loss: 1.6053 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 9/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.2009 - val_loss: 1.6037 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2008 - val_loss: 1.6107 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6059 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2007 - val_loss: 1.6104 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 1.6045 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 1.6038 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6131 - val_accuracy: 0.0735 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2007 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1972 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 18/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6046 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2004 - val_loss: 1.6026 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6193 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1997 - val_loss: 1.6148 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6126 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2009 - val_loss: 1.5996 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 1.6069 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 1.6126 - val_accuracy: 0.0254 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6090 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 1.6174 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 1.6185 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1963 - val_loss: 1.6150 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2010 - val_loss: 1.6126 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6058 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 1.6118 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "4378/4378 - 67s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 1.6074 - val_accuracy: 0.0254 - lr: 0.0010 - 67s/epoch - 15ms/step\n",
      "Epoch 37/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6151 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1966 - val_loss: 1.6070 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1969 - val_loss: 1.6104 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6110 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6116 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6066 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6050 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1990 - val_loss: 1.6103 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 45/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6149 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 1.6131 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6073 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1967 - val_loss: 1.6083 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1952 - val_loss: 1.6086 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 1.6156 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2001 - val_loss: 1.6133 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "4378/4378 - 68s - loss: 1.6094 - accuracy: 0.2018 - val_loss: 1.6130 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 1.6067 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 1.6083 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 56/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6072 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 57/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6108 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6073 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6074 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 60/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1985 - val_loss: 1.6040 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1970 - val_loss: 1.6063 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1998 - val_loss: 1.6054 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 1.6037 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6146 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6058 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 1.6122 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1963 - val_loss: 1.6044 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "4378/4378 - 71s - loss: 1.6095 - accuracy: 0.2002 - val_loss: 1.6112 - val_accuracy: 0.0074 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1981 - val_loss: 1.6048 - val_accuracy: 0.8276 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2001 - val_loss: 1.6071 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6080 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2003 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6036 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6109 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6049 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6142 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1996 - val_loss: 1.6117 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 1.6102 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "4378/4378 - 67s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 1.6057 - val_accuracy: 0.0735 - lr: 0.0010 - 67s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 1.6133 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1979 - val_loss: 1.6113 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 1.6039 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 85/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2002 - val_loss: 1.6084 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1978 - val_loss: 1.6048 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 88/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6046 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1957 - val_loss: 1.6064 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6064 - val_accuracy: 0.0074 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1983 - val_loss: 1.6124 - val_accuracy: 0.0074 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1999 - val_loss: 1.6074 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 93/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2000 - val_loss: 1.6007 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6123 - val_accuracy: 0.0661 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 95/100\n",
      "4378/4378 - 69s - loss: 1.6095 - accuracy: 0.1970 - val_loss: 1.6113 - val_accuracy: 0.0661 - lr: 0.0010 - 69s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6102 - val_accuracy: 0.0254 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.2005 - val_loss: 1.6034 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 68s/epoch - 15ms/step\n",
      "Epoch 99/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1994 - val_loss: 1.6077 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "4378/4378 - 68s - loss: 1.6095 - accuracy: 0.1975 - val_loss: 1.6043 - val_accuracy: 0.8276 - lr: 0.0010 - 68s/epoch - 16ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/100\n",
      "876/876 - 20s - loss: 1.6095 - accuracy: 0.2001 - val_loss: 1.6071 - val_accuracy: 0.8276 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 1.6084 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 4/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 5/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 6/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6093 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 8/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6090 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1995 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 10/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6093 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 11/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 12/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 13/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1971 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 14/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1965 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 15/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 16/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 17/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 18/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1969 - val_loss: 1.6098 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 19/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1964 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 20/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 21/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1970 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 22/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 23/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 24/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6093 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1963 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 27/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 28/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1991 - val_loss: 1.6093 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 29/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 30/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 31/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1976 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 32/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 33/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1962 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 34/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 35/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 36/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 37/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 38/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1965 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 39/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6087 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 40/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 41/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 1.6102 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 42/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1986 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 43/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1961 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 44/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 45/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1980 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 46/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6102 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 47/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1977 - val_loss: 1.6102 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 48/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1972 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 49/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 50/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1982 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 51/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 52/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6103 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 53/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6089 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 54/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 55/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 56/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1987 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 57/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 58/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 59/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1992 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 60/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6086 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 61/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1973 - val_loss: 1.6085 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 62/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1970 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 63/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 64/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6105 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 65/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1993 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 66/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6092 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 67/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6100 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 68/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 69/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6086 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 70/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6092 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 71/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6089 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 72/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1984 - val_loss: 1.6086 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 73/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6084 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 74/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6092 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 75/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1953 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 76/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 77/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1989 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 78/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1966 - val_loss: 1.6101 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 79/100\n",
      "876/876 - 20s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 80/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 81/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1974 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 82/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6102 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 83/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 84/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 85/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 86/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 87/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6089 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 88/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 89/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 90/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 91/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 92/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6091 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 93/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1968 - val_loss: 1.6091 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 94/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6081 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 95/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6082 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 96/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6089 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 99/100\n",
      "876/876 - 18s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "Epoch 100/100\n",
      "876/876 - 18s - loss: 1.6095 - accuracy: 0.1973 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 20ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/100\n",
      "176/176 - 12s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 12s/epoch - 67ms/step\n",
      "Epoch 2/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1958 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 3/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 4/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 5/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 6/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 8/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 9/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 10/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 11/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 12/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1980 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 13/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 14/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 15/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 16/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 17/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 18/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 19/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 20/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 21/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2020 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 22/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1979 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 23/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 24/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 25/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2010 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 26/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 27/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 28/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 29/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 30/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 31/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 32/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 33/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 34/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 35/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6097 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 36/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6100 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 37/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6099 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 38/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6096 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 39/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 40/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6094 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 41/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6095 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 42/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 43/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6094 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 44/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 45/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 46/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 47/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1998 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 48/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 49/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 50/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6088 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 51/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 52/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 53/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 54/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 55/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 56/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 57/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 58/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6093 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 59/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 60/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 61/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 62/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 63/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 64/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 65/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1966 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 66/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 67/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 68/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 69/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2010 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 70/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 71/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 72/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1975 - val_loss: 1.6095 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 73/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 74/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2016 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 75/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1971 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 76/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6098 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 77/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 78/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6101 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 79/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 80/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 81/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2010 - val_loss: 1.6101 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 82/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 83/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6100 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 84/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6099 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 85/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 86/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 87/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 88/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 89/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2013 - val_loss: 1.6092 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 90/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 91/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 92/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 93/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 94/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 95/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 96/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 97/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 98/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 99/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 100/100\n",
      "176/176 - 10s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/100\n",
      "59/59 - 11s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 11s/epoch - 185ms/step\n",
      "Epoch 2/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 3/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 4/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 5/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 6/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 7/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 8/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6090 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 9/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 10/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6091 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 11/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 12/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 13/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 14/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2015 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 15/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2019 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 16/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 17/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2014 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 18/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 19/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 20/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 21/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 22/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 23/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 24/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 25/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 26/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 27/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6092 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 28/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 29/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2010 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 30/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 31/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 32/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 33/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 34/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2020 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 35/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2017 - val_loss: 1.6093 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 36/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2015 - val_loss: 1.6093 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 37/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2020 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 38/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 39/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 40/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 41/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2010 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 42/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 43/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 44/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 45/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 46/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 47/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 48/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 49/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 50/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 51/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 52/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 53/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 54/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 55/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2017 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 56/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 57/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 58/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 59/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 60/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 61/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 62/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 63/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1988 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 64/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 65/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2026 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 66/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2017 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 67/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1968 - val_loss: 1.6094 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 68/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2022 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 69/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 70/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 71/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 72/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 73/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 74/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 75/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 76/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 77/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 78/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 79/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1969 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 80/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 81/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2028 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 82/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 83/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 84/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 85/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 86/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 87/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1976 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 88/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 89/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 90/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 91/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 92/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 93/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 94/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 95/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 96/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2018 - val_loss: 1.6096 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 97/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 98/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2013 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 99/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2015 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 100/100\n",
      "59/59 - 9s - loss: 1.6094 - accuracy: 0.2024 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/100\n",
      "36/36 - 11s - loss: 1.6094 - accuracy: 0.2017 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 11s/epoch - 310ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6096 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6095 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6097 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 13/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2016 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 14/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 15/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2021 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 16/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 17/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 18/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 19/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6089 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 20/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6089 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 21/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2026 - val_loss: 1.6090 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 22/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2000 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 23/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 24/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 25/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 26/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6090 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 27/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1958 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 28/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2030 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 29/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1973 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 30/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6090 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 31/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2001 - val_loss: 1.6090 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 32/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6089 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 33/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 34/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6090 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 35/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2019 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 36/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1977 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 37/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 38/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2019 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 39/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6094 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 40/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6092 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 41/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6089 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 42/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6089 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 43/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 44/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2019 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 45/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2021 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 46/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 47/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1972 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 48/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 49/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6095 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 50/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2006 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 51/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 52/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2007 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 53/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 54/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6091 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 55/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2004 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 56/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2008 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 57/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6093 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 58/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6092 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 59/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6094 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 60/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 61/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1992 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 62/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 63/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6097 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 64/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6096 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 65/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 66/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 67/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1969 - val_loss: 1.6101 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 68/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2022 - val_loss: 1.6103 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 69/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2020 - val_loss: 1.6104 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 70/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6103 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 71/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1985 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 72/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2003 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 73/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2005 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 74/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6105 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 75/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1986 - val_loss: 1.6105 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 76/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2020 - val_loss: 1.6105 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 77/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6103 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 78/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1974 - val_loss: 1.6101 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 79/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1989 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 80/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1982 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 81/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1981 - val_loss: 1.6101 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 82/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2002 - val_loss: 1.6099 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 83/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1997 - val_loss: 1.6101 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 84/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1999 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 85/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2021 - val_loss: 1.6098 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 86/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2011 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 87/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2017 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 88/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 89/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1994 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 90/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1990 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 91/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2009 - val_loss: 1.6098 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 92/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.2015 - val_loss: 1.6097 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 93/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1995 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 94/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1978 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 95/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1983 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 96/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1993 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 97/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1991 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 98/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1984 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 99/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1996 - val_loss: 1.6099 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 100/100\n",
      "36/36 - 9s - loss: 1.6094 - accuracy: 0.1987 - val_loss: 1.6100 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Loss: binary_crossentropy\n",
      "Epoch number: 25\n",
      "fitting with batch size: 20\n",
      "Epoch 1/25\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 2/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 3/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 4/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 5/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 6/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 7/25\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 8/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 9/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 10/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 11/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 12/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 13/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 14/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 15/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 16/25\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1966 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 17/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 18/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 19/25\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 20/25\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5003 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 21/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 22/25\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 23/25\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 24/25\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 25/25\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/25\n",
      "876/876 - 21s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 2/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 3/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 4/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2021 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 5/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 6/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 7/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 8/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 9/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 10/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 11/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 12/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 13/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2019 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 14/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 15/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 16/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 17/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 18/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 19/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 20/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 21/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 22/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 23/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 24/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 25/25\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/25\n",
      "176/176 - 12s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 12s/epoch - 69ms/step\n",
      "Epoch 2/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 3/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 4/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 5/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 6/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 8/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 9/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 10/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 11/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 12/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 13/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 14/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 15/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2024 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 16/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 17/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 18/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 19/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 20/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 21/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 22/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 23/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 24/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 25/25\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/25\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 12s/epoch - 198ms/step\n",
      "Epoch 2/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 3/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 4/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 5/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 6/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 7/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2022 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 8/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 9/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 10/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 11/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 12/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 13/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 14/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 15/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 16/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 17/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 18/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 19/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 20/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 21/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 22/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 23/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 24/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 25/25\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/25\n",
      "36/36 - 11s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 11s/epoch - 301ms/step\n",
      "Epoch 2/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 3/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 4/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 5/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 6/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 7/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 8/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 9/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 10/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 11/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 12/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 13/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 14/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 15/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 16/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 17/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 18/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 19/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 20/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 21/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 22/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 23/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 24/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 25/25\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch number: 50\n",
      "fitting with batch size: 20\n",
      "Epoch 1/50\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5002 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 3/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 4/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 5/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 6/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 8/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1961 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5006 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 11/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 12/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 14/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 15/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 16/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 17/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1955 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 19/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5002 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5001 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 22/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 23/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1959 - val_loss: 0.5006 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 24/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 25/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1958 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 26/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 27/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5003 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 28/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 29/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 30/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5001 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 31/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5002 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 32/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 33/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 34/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 35/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5003 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 36/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 37/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5002 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 38/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 39/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1949 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 40/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1967 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 41/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1961 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 42/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 43/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5007 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 44/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 45/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 46/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 47/50\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 48/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 49/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/50\n",
      "876/876 - 21s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 2/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 3/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 4/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 5/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 6/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2020 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 7/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 8/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 9/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 10/50\n",
      "876/876 - 20s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 20s/epoch - 22ms/step\n",
      "Epoch 11/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 12/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 13/50\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 14/50\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 15/50\n",
      "876/876 - 18s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 16/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 17/50\n",
      "876/876 - 20s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 20s/epoch - 23ms/step\n",
      "Epoch 18/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 19/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 20/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 21/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 22/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 23/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 24/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 25/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 26/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 27/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 28/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 29/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 30/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 31/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 32/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 33/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 34/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 35/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 36/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 37/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 38/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 39/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 40/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 41/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 42/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 43/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 44/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 45/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 46/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 47/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 48/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 49/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 50/50\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/50\n",
      "176/176 - 12s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 12s/epoch - 69ms/step\n",
      "Epoch 2/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 3/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 4/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 5/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 6/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 7/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 8/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2019 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 9/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2021 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 10/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 11/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 12/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1964 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 13/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 14/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 15/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 16/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 17/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 18/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 19/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 20/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 21/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 22/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 23/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 24/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 25/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 26/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 27/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 28/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2018 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 29/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 30/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 31/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 32/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 33/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 34/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 35/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 36/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 37/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 38/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 39/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 40/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 41/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 42/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2026 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 43/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 44/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 45/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 46/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 47/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 48/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 49/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 50/50\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/50\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 12s/epoch - 202ms/step\n",
      "Epoch 2/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 3/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 4/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 5/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 6/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 7/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2028 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 8/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2027 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 9/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 10/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 11/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2036 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 12/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 13/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 14/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 15/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 153ms/step\n",
      "Epoch 16/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 153ms/step\n",
      "Epoch 17/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 18/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 19/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 20/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 21/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 22/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 23/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 24/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 153ms/step\n",
      "Epoch 25/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 26/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 27/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 28/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2028 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 153ms/step\n",
      "Epoch 29/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 30/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 31/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 32/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 33/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 34/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 153ms/step\n",
      "Epoch 35/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 36/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 37/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 38/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 39/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 40/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 41/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 42/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 43/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 153ms/step\n",
      "Epoch 44/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 45/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 153ms/step\n",
      "Epoch 46/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 47/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 48/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 49/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 50/50\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 153ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/50\n",
      "36/36 - 11s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 11s/epoch - 301ms/step\n",
      "Epoch 2/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 3/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 4/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 5/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 6/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 243ms/step\n",
      "Epoch 7/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 8/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 9/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 10/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 11/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 12/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 13/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 14/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2038 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 15/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 16/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 17/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 18/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 243ms/step\n",
      "Epoch 19/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 20/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 21/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 22/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 23/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 24/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 25/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 26/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 27/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 28/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 29/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 30/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2026 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 31/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 32/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 33/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2033 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 34/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 35/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 36/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 37/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 38/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 39/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 40/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 41/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2018 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 42/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 43/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 44/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 45/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 46/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 47/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 48/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 49/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 50/50\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch number: 75\n",
      "fitting with batch size: 20\n",
      "Epoch 1/75\n",
      "4378/4378 - 75s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5003 - val_accuracy: 0.0074 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 2/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5003 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 3/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 4/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 5/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 6/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 7/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 8/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 9/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 10/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 11/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 12/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 13/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 14/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 15/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 16/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 17/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 18/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 19/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 20/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5007 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 21/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5006 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 22/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5006 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 23/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 24/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 25/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 26/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 27/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 28/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 29/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1966 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 30/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1966 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 31/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 32/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1960 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 33/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 34/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1958 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 35/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 36/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 37/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 38/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 39/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 40/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 41/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 42/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 43/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 44/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 45/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 46/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 47/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1960 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 48/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 49/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 50/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 51/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 52/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 53/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 54/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5006 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 55/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 56/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 57/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 58/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 59/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 60/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 61/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 62/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5007 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 63/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5008 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 64/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1958 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 65/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 66/75\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 67/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5003 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 68/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 69/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 70/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5007 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 71/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 72/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 73/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5006 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 74/75\n",
      "4378/4378 - 72s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 75/75\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/75\n",
      "876/876 - 21s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 2/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 3/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 4/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 5/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 6/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 7/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 8/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 9/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 10/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 11/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 12/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 13/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 14/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 15/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 16/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 17/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 18/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 19/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 20/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 21/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 22/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 23/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 24/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 25/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 26/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 27/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 28/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 29/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 30/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 31/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 32/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2026 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 33/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 34/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 35/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 36/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 37/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 38/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 39/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 40/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 41/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 42/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 43/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 44/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 45/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 46/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 47/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 48/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 49/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 50/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1963 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 51/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 52/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 53/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 54/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 55/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2019 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 56/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 57/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 58/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 59/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1961 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 60/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2050 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 61/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 62/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 63/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 64/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 22ms/step\n",
      "Epoch 65/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 66/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 67/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 68/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 69/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2023 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 70/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 71/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 72/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 73/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 74/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 75/75\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/75\n",
      "176/176 - 12s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 12s/epoch - 69ms/step\n",
      "Epoch 2/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 3/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 4/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 5/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 6/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 7/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 8/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 9/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 10/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2022 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 11/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 12/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 13/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 14/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 15/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 16/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2018 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 17/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 18/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 19/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 20/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 21/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2022 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 22/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 23/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 24/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 25/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 26/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 27/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 28/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 29/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 30/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 31/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 32/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 33/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2020 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 34/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 35/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 36/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1960 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 37/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 38/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 39/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 40/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 41/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 42/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 43/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2026 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 44/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 45/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2021 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 46/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 47/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 48/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 49/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 50/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 51/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 52/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 53/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 54/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2034 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 55/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 56/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 57/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 58/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 59/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 60/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 61/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2019 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 62/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 63/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 64/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 65/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 66/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 67/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2029 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 68/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 69/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 70/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 71/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2021 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 72/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 73/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2030 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 74/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2032 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 75/75\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 12s/epoch - 196ms/step\n",
      "Epoch 2/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 146ms/step\n",
      "Epoch 3/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 145ms/step\n",
      "Epoch 4/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1959 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 148ms/step\n",
      "Epoch 5/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 146ms/step\n",
      "Epoch 6/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 148ms/step\n",
      "Epoch 7/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 147ms/step\n",
      "Epoch 8/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 149ms/step\n",
      "Epoch 9/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 146ms/step\n",
      "Epoch 10/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 147ms/step\n",
      "Epoch 11/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 146ms/step\n",
      "Epoch 12/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2033 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 146ms/step\n",
      "Epoch 13/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 146ms/step\n",
      "Epoch 14/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 145ms/step\n",
      "Epoch 15/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 161ms/step\n",
      "Epoch 16/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 146ms/step\n",
      "Epoch 17/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 147ms/step\n",
      "Epoch 18/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2022 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 19/75\n",
      "59/59 - 10s - loss: 0.5004 - accuracy: 0.2019 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 165ms/step\n",
      "Epoch 20/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 158ms/step\n",
      "Epoch 21/75\n",
      "59/59 - 10s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 166ms/step\n",
      "Epoch 22/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 146ms/step\n",
      "Epoch 23/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 157ms/step\n",
      "Epoch 24/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 159ms/step\n",
      "Epoch 25/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1963 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 158ms/step\n",
      "Epoch 26/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 159ms/step\n",
      "Epoch 27/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 159ms/step\n",
      "Epoch 28/75\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 159ms/step\n",
      "Epoch 29/75\n",
      "59/59 - 10s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 166ms/step\n",
      "Epoch 30/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 199ms/step\n",
      "Epoch 31/75\n",
      "59/59 - 11s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 11s/epoch - 191ms/step\n",
      "Epoch 32/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 201ms/step\n",
      "Epoch 33/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 200ms/step\n",
      "Epoch 34/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 202ms/step\n",
      "Epoch 35/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 201ms/step\n",
      "Epoch 36/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 205ms/step\n",
      "Epoch 37/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 12s/epoch - 206ms/step\n",
      "Epoch 38/75\n",
      "59/59 - 11s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 11s/epoch - 183ms/step\n",
      "Epoch 39/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 202ms/step\n",
      "Epoch 40/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 200ms/step\n",
      "Epoch 41/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 203ms/step\n",
      "Epoch 42/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 206ms/step\n",
      "Epoch 43/75\n",
      "59/59 - 10s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 173ms/step\n",
      "Epoch 44/75\n",
      "59/59 - 10s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 176ms/step\n",
      "Epoch 45/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 222ms/step\n",
      "Epoch 46/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 223ms/step\n",
      "Epoch 47/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 209ms/step\n",
      "Epoch 48/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 201ms/step\n",
      "Epoch 49/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 206ms/step\n",
      "Epoch 50/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 200ms/step\n",
      "Epoch 51/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 198ms/step\n",
      "Epoch 52/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2020 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 212ms/step\n",
      "Epoch 53/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 224ms/step\n",
      "Epoch 54/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 219ms/step\n",
      "Epoch 55/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 220ms/step\n",
      "Epoch 56/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 222ms/step\n",
      "Epoch 57/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 222ms/step\n",
      "Epoch 58/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 214ms/step\n",
      "Epoch 59/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2033 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 218ms/step\n",
      "Epoch 60/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 219ms/step\n",
      "Epoch 61/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 224ms/step\n",
      "Epoch 62/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 211ms/step\n",
      "Epoch 63/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 219ms/step\n",
      "Epoch 64/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 222ms/step\n",
      "Epoch 65/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 222ms/step\n",
      "Epoch 66/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 217ms/step\n",
      "Epoch 67/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 12s/epoch - 208ms/step\n",
      "Epoch 68/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 206ms/step\n",
      "Epoch 69/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 208ms/step\n",
      "Epoch 70/75\n",
      "59/59 - 12s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 204ms/step\n",
      "Epoch 71/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 216ms/step\n",
      "Epoch 72/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 222ms/step\n",
      "Epoch 73/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 224ms/step\n",
      "Epoch 74/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 223ms/step\n",
      "Epoch 75/75\n",
      "59/59 - 13s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 13s/epoch - 222ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/75\n",
      "36/36 - 15s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 15s/epoch - 415ms/step\n",
      "Epoch 2/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 328ms/step\n",
      "Epoch 3/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 333ms/step\n",
      "Epoch 4/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 331ms/step\n",
      "Epoch 5/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2035 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 321ms/step\n",
      "Epoch 6/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 329ms/step\n",
      "Epoch 7/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 329ms/step\n",
      "Epoch 8/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 343ms/step\n",
      "Epoch 9/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 342ms/step\n",
      "Epoch 10/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 341ms/step\n",
      "Epoch 11/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 351ms/step\n",
      "Epoch 12/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 348ms/step\n",
      "Epoch 13/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 330ms/step\n",
      "Epoch 14/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2023 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 327ms/step\n",
      "Epoch 15/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 323ms/step\n",
      "Epoch 16/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 332ms/step\n",
      "Epoch 17/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 328ms/step\n",
      "Epoch 18/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 330ms/step\n",
      "Epoch 19/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 344ms/step\n",
      "Epoch 20/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 349ms/step\n",
      "Epoch 21/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.2020 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 351ms/step\n",
      "Epoch 22/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 344ms/step\n",
      "Epoch 23/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 335ms/step\n",
      "Epoch 24/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 345ms/step\n",
      "Epoch 25/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 349ms/step\n",
      "Epoch 26/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 368ms/step\n",
      "Epoch 27/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 354ms/step\n",
      "Epoch 28/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2025 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 343ms/step\n",
      "Epoch 29/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 340ms/step\n",
      "Epoch 30/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 351ms/step\n",
      "Epoch 31/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.2020 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 358ms/step\n",
      "Epoch 32/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 356ms/step\n",
      "Epoch 33/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 348ms/step\n",
      "Epoch 34/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 332ms/step\n",
      "Epoch 35/75\n",
      "36/36 - 11s - loss: 0.5004 - accuracy: 0.2022 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 11s/epoch - 319ms/step\n",
      "Epoch 36/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 324ms/step\n",
      "Epoch 37/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 334ms/step\n",
      "Epoch 38/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 340ms/step\n",
      "Epoch 39/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2022 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 343ms/step\n",
      "Epoch 40/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 337ms/step\n",
      "Epoch 41/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 322ms/step\n",
      "Epoch 42/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 347ms/step\n",
      "Epoch 43/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 13s/epoch - 356ms/step\n",
      "Epoch 44/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 13s/epoch - 359ms/step\n",
      "Epoch 45/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 13s/epoch - 355ms/step\n",
      "Epoch 46/75\n",
      "36/36 - 14s - loss: 0.5004 - accuracy: 0.1964 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 14s/epoch - 377ms/step\n",
      "Epoch 47/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 13s/epoch - 373ms/step\n",
      "Epoch 48/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 12s/epoch - 345ms/step\n",
      "Epoch 49/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 13s/epoch - 347ms/step\n",
      "Epoch 50/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 12s/epoch - 340ms/step\n",
      "Epoch 51/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 13s/epoch - 350ms/step\n",
      "Epoch 52/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 12s/epoch - 341ms/step\n",
      "Epoch 53/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 13s/epoch - 349ms/step\n",
      "Epoch 54/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2028 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 12s/epoch - 334ms/step\n",
      "Epoch 55/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.2021 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 354ms/step\n",
      "Epoch 56/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 351ms/step\n",
      "Epoch 57/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 13s/epoch - 348ms/step\n",
      "Epoch 58/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 13s/epoch - 352ms/step\n",
      "Epoch 59/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 13s/epoch - 353ms/step\n",
      "Epoch 60/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 13s/epoch - 350ms/step\n",
      "Epoch 61/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 13s/epoch - 354ms/step\n",
      "Epoch 62/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 12s/epoch - 346ms/step\n",
      "Epoch 63/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 339ms/step\n",
      "Epoch 64/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 338ms/step\n",
      "Epoch 65/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 337ms/step\n",
      "Epoch 66/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 12s/epoch - 331ms/step\n",
      "Epoch 67/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 12s/epoch - 330ms/step\n",
      "Epoch 68/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 352ms/step\n",
      "Epoch 69/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 351ms/step\n",
      "Epoch 70/75\n",
      "36/36 - 12s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 12s/epoch - 342ms/step\n",
      "Epoch 71/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 354ms/step\n",
      "Epoch 72/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 369ms/step\n",
      "Epoch 73/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 369ms/step\n",
      "Epoch 74/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 359ms/step\n",
      "Epoch 75/75\n",
      "36/36 - 13s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 371ms/step\n",
      "Epoch number: 100\n",
      "fitting with batch size: 20\n",
      "Epoch 1/100\n",
      "4378/4378 - 95s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 95s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 3/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 4/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5002 - val_accuracy: 0.0661 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 6/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 7/100\n",
      "4378/4378 - 93s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5003 - val_accuracy: 0.0254 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 8/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 10/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 11/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 12/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 13/100\n",
      "4378/4378 - 87s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 14/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 15/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 16/100\n",
      "4378/4378 - 86s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 17/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 18/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 19/100\n",
      "4378/4378 - 86s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5003 - val_accuracy: 0.0661 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 20/100\n",
      "4378/4378 - 86s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 21/100\n",
      "4378/4378 - 86s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 22/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 23/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 90s/epoch - 20ms/step\n",
      "Epoch 24/100\n",
      "4378/4378 - 87s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5003 - val_accuracy: 0.0254 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 26/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 27/100\n",
      "4378/4378 - 93s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 28/100\n",
      "4378/4378 - 93s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 29/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 30/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 31/100\n",
      "4378/4378 - 93s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 32/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 90s/epoch - 20ms/step\n",
      "Epoch 33/100\n",
      "4378/4378 - 93s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 34/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 35/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.4999 - val_accuracy: 0.8276 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 36/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 37/100\n",
      "4378/4378 - 93s - loss: 0.5004 - accuracy: 0.1967 - val_loss: 0.5003 - val_accuracy: 0.0661 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 38/100\n",
      "4378/4378 - 93s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5001 - val_accuracy: 0.8276 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 39/100\n",
      "4378/4378 - 94s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5003 - val_accuracy: 0.0074 - lr: 0.0010 - 94s/epoch - 22ms/step\n",
      "Epoch 40/100\n",
      "4378/4378 - 87s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 41/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5001 - val_accuracy: 0.8276 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 42/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5001 - val_accuracy: 0.8276 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 43/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 90s/epoch - 20ms/step\n",
      "Epoch 44/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 45/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5003 - val_accuracy: 0.0254 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 46/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 90s/epoch - 20ms/step\n",
      "Epoch 47/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5001 - val_accuracy: 0.8276 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 48/100\n",
      "4378/4378 - 87s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 49/100\n",
      "4378/4378 - 87s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5008 - val_accuracy: 0.0074 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 50/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 51/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 52/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5001 - val_accuracy: 0.8276 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 53/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 54/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 55/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 56/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 57/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 58/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 59/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5002 - val_accuracy: 0.8276 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 60/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 61/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1982 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 62/100\n",
      "4378/4378 - 93s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5007 - val_accuracy: 0.0074 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 63/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5007 - val_accuracy: 0.0735 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 64/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 65/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 66/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 67/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5005 - val_accuracy: 0.0661 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "4378/4378 - 93s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 93s/epoch - 21ms/step\n",
      "Epoch 69/100\n",
      "4378/4378 - 92s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 70/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 71/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5003 - val_accuracy: 0.0074 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 72/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5002 - val_accuracy: 0.0074 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 73/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5002 - val_accuracy: 0.0074 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 74/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 75/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 76/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 77/100\n",
      "4378/4378 - 91s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 91s/epoch - 21ms/step\n",
      "Epoch 78/100\n",
      "4378/4378 - 89s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 79/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 80/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 81/100\n",
      "4378/4378 - 90s - loss: 0.5004 - accuracy: 0.1962 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 90s/epoch - 21ms/step\n",
      "Epoch 82/100\n",
      "4378/4378 - 87s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5005 - val_accuracy: 0.0735 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 83/100\n",
      "4378/4378 - 88s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 88s/epoch - 20ms/step\n",
      "Epoch 84/100\n",
      "4378/4378 - 87s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 85/100\n",
      "4378/4378 - 85s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5003 - val_accuracy: 0.0735 - lr: 0.0010 - 85s/epoch - 19ms/step\n",
      "Epoch 86/100\n",
      "4378/4378 - 80s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 80s/epoch - 18ms/step\n",
      "Epoch 87/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5006 - val_accuracy: 0.0661 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5006 - val_accuracy: 0.0254 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "4378/4378 - 73s - loss: 0.5004 - accuracy: 0.1960 - val_loss: 0.5003 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 93/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5006 - val_accuracy: 0.0074 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5003 - val_accuracy: 0.8276 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 97/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5001 - val_accuracy: 0.8276 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5001 - val_accuracy: 0.8276 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 100/100\n",
      "4378/4378 - 74s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/100\n",
      "876/876 - 21s - loss: 0.5004 - accuracy: 0.2018 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 3/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 4/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 6/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 7/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 8/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 9/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 10/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 11/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 12/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 13/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 14/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 15/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 16/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 17/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 18/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 19/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 20/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 21/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 22/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1953 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 23/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 24/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 25/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 26/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 27/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 28/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 29/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 30/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 31/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 32/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 33/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1973 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 34/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 35/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 36/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1951 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 37/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1965 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 38/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 39/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 40/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 41/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 42/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 43/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 44/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 45/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 46/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 47/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2021 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 48/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 49/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 50/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 51/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 52/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 53/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 54/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2020 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 55/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 56/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 57/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1967 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 58/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 59/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 60/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 61/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 62/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 63/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 64/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 65/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 66/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 67/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 69/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 70/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 71/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 72/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 73/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 74/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 75/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 76/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 77/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 78/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 79/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 80/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 81/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2024 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 82/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 83/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 84/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 85/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 86/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 87/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 88/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 89/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 90/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 91/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 92/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 93/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 94/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 95/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 96/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 97/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.2031 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 98/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 99/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 100/100\n",
      "876/876 - 19s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/100\n",
      "176/176 - 12s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 12s/epoch - 69ms/step\n",
      "Epoch 2/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 3/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 4/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 5/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 6/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 8/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2025 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 9/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 10/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5005 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 11/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 12/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 13/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 14/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1970 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 15/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 16/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 17/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 18/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 19/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 20/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 21/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 22/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 23/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2028 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 24/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 25/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 26/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 27/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2021 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 28/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1969 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 29/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1971 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 30/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 31/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 32/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 33/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 34/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 35/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 36/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 37/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 38/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1964 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 39/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 40/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 41/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 42/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 55ms/step\n",
      "Epoch 43/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2020 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 44/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 45/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 46/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 47/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 48/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 49/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 50/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 51/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 52/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 53/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 54/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2026 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 55/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 56/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 57/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 58/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2020 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 59/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 60/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 61/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 62/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 63/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 64/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 65/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 66/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 67/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 68/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 69/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 70/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 71/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 72/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 73/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 74/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 75/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 76/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 77/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 78/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2023 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 79/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 80/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 81/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1981 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 82/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 83/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 84/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 85/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 86/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 87/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 88/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 89/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 90/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 91/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 92/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 93/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 94/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 95/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 96/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 97/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 98/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 99/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 100/100\n",
      "176/176 - 10s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/100\n",
      "59/59 - 11s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 11s/epoch - 189ms/step\n",
      "Epoch 2/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 3/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1980 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 4/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5004 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 5/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 6/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 7/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 8/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 9/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 10/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 11/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 12/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 13/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 14/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 15/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 16/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 17/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 18/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 19/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 20/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 21/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 22/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 23/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1963 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 24/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 25/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 26/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 27/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 28/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 29/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 30/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 31/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 32/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 33/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 34/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 35/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 36/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 37/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 38/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 39/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 40/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 41/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 42/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 43/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 44/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 45/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 46/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 47/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 48/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 49/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 50/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 51/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 52/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 53/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 54/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 55/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 56/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 57/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 58/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 59/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 60/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 61/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 62/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 63/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 64/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 65/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 66/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 67/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2010 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 68/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 69/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 70/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 71/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1987 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 72/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 73/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 74/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 75/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 76/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 77/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 78/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 79/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 80/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 81/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 82/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 83/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 84/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 85/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2018 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 86/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 87/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 88/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 89/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 90/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 91/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 92/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 93/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 94/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 95/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 96/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 97/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 98/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1972 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 99/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.2011 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 100/100\n",
      "59/59 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/100\n",
      "36/36 - 11s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 11s/epoch - 306ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2032 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2002 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 13/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 14/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 15/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2021 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 16/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2007 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 17/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 18/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 19/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 20/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 21/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 22/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 23/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 24/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 25/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 26/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 27/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 28/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1974 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 29/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 30/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 31/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1976 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 32/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 33/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2018 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 34/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 35/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2018 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 36/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 37/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 38/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 39/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 40/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 41/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1993 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 42/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 43/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 44/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 45/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 46/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2018 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 47/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 48/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1985 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 49/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 50/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1967 - val_loss: 0.5004 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 51/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 52/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1995 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 53/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 54/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 55/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 56/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2026 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 57/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 58/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1999 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 59/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2015 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 60/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1979 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 61/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 62/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 63/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 64/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1988 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 65/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 66/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1984 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 67/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2000 - val_loss: 0.5004 - val_accuracy: 0.8276 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 68/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 69/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2017 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 70/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1994 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 71/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1977 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 72/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2003 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 73/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 74/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1983 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 75/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1991 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 76/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2009 - val_loss: 0.5004 - val_accuracy: 0.0074 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 77/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1989 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 78/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 79/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1990 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 242ms/step\n",
      "Epoch 80/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1978 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 81/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1996 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 82/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1975 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 83/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5005 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 84/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2018 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 85/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 86/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2001 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 87/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 88/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2005 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 89/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1992 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 90/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 91/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1986 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 92/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2014 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 93/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2008 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 94/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 95/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1968 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 96/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2012 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 97/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2006 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 98/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2004 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 99/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.1998 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 100/100\n",
      "36/36 - 9s - loss: 0.5004 - accuracy: 0.2022 - val_loss: 0.5004 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Loss: huber_loss\n",
      "Epoch number: 25\n",
      "fitting with batch size: 20\n",
      "Epoch 1/25\n",
      "4378/4378 - 77s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 77s/epoch - 18ms/step\n",
      "Epoch 2/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 3/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 4/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 5/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2016 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 6/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 7/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 8/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 9/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 10/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 11/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 12/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 13/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1971 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 14/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 15/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 16/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 17/25\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 18/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 19/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 20/25\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 21/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 22/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 23/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 24/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 25/25\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/25\n",
      "876/876 - 21s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 21s/epoch - 23ms/step\n",
      "Epoch 2/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 3/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 4/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 5/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2026 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 6/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 7/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 8/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 9/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 10/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 11/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 12/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 13/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 14/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 15/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 16/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 17/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 18/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 19/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 20/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 21/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 22/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 23/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2019 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 24/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 25/25\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1976 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/25\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 12s/epoch - 69ms/step\n",
      "Epoch 2/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 3/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 4/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 5/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 6/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 8/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 9/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 10/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 11/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 12/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 13/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 14/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 15/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 16/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 17/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 18/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 19/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 20/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 21/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 22/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 23/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 24/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 25/25\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/25\n",
      "59/59 - 11s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 11s/epoch - 187ms/step\n",
      "Epoch 2/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 3/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 4/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 5/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 6/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 7/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 8/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 9/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 10/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 11/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 12/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 13/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 14/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 15/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 16/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 17/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 18/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 19/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 20/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 21/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2021 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 22/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 23/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 24/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 25/25\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/25\n",
      "36/36 - 11s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 11s/epoch - 300ms/step\n",
      "Epoch 2/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 3/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 4/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 5/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 6/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 7/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 8/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2018 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 9/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 10/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 11/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 12/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 13/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2028 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 14/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 15/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 16/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2015 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 17/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 18/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2016 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 19/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 20/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 21/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 22/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 23/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 24/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 25/25\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch number: 50\n",
      "fitting with batch size: 20\n",
      "Epoch 1/50\n",
      "4378/4378 - 78s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 78s/epoch - 18ms/step\n",
      "Epoch 2/50\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 3/50\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 4/50\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 5/50\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 6/50\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 7/50\n",
      "4378/4378 - 75s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 75s/epoch - 17ms/step\n",
      "Epoch 8/50\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 9/50\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 10/50\n",
      "4378/4378 - 76s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 76s/epoch - 17ms/step\n",
      "Epoch 11/50\n",
      "4378/4378 - 77s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 77s/epoch - 18ms/step\n",
      "Epoch 12/50\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1961 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 13/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 14/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 17/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 19/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 22/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 23/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 24/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 25/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 26/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 27/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 28/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 29/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 31/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 32/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 33/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1965 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 34/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 35/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 36/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 37/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 38/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 39/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 40/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 41/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 42/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 43/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 44/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 45/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 46/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 47/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1959 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 48/50\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 49/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 50/50\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/50\n",
      "876/876 - 21s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 2/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1967 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 3/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1969 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 4/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 5/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 6/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 7/50\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2036 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 8/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 9/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2020 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 10/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 11/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 12/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 13/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 14/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 15/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 16/50\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 17/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 18/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2034 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 19/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 20/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2027 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 21/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 22/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 23/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 24/50\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2024 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 25/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 26/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 27/50\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 28/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 29/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 30/50\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 31/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 32/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2016 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 33/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 34/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 35/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 36/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 37/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 38/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1971 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 39/50\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 40/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 41/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2019 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 42/50\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 43/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 44/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 45/50\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 46/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2025 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 47/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 48/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 49/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 50/50\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/50\n",
      "176/176 - 13s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 13s/epoch - 75ms/step\n",
      "Epoch 2/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2018 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 3/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 4/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 5/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 6/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 8/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 9/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2032 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 10/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 11/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 12/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 13/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1966 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 14/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2016 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 15/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 16/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 17/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 18/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 19/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 20/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 21/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 22/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 23/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 24/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 25/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2031 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 26/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 27/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 28/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2016 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 29/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 30/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2019 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 31/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 32/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 33/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2023 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 34/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 35/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 36/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2038 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 37/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 38/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 39/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 57ms/step\n",
      "Epoch 40/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 41/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 42/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 43/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 44/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 45/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 46/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 47/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 48/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 49/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 50/50\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/50\n",
      "59/59 - 11s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 11s/epoch - 188ms/step\n",
      "Epoch 2/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 3/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 4/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 5/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 6/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 7/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 8/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1966 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 9/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 150ms/step\n",
      "Epoch 10/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 11/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 12/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 13/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 14/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2023 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 15/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 16/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 17/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 18/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 19/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 20/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 21/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2023 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 22/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 23/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 24/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 25/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 26/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 27/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 28/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2038 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 29/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 30/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2029 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 31/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 32/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 33/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 34/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2019 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 35/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 36/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 37/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 38/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 39/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 40/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 41/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 42/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 43/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2018 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 44/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 45/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 46/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 47/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 48/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 49/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 50/50\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/50\n",
      "36/36 - 11s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 11s/epoch - 302ms/step\n",
      "Epoch 2/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 3/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 4/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 5/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 6/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 7/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 8/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 9/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 10/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 11/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 12/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 13/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 14/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 15/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2018 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 16/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 17/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 18/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 19/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 20/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 21/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 22/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 23/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 24/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 25/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 26/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 27/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 28/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 29/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 30/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2014 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 31/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 32/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 33/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 34/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 35/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1976 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 36/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 37/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2028 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 38/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 39/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 40/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 41/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 42/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 43/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 44/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2016 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 45/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2005 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 46/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 47/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 48/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 241ms/step\n",
      "Epoch 49/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch 50/50\n",
      "36/36 - 9s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 9s/epoch - 240ms/step\n",
      "Epoch number: 75\n",
      "fitting with batch size: 20\n",
      "Epoch 1/75\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.2015 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 2/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 3/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 4/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 5/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 6/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 7/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 8/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 9/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 10/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 11/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 12/75\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 13/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 14/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 15/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1977 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 16/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 17/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 18/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 19/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 20/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 21/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 22/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 23/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 24/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 25/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 26/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 27/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 28/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 29/75\n",
      "4378/4378 - 71s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 71s/epoch - 16ms/step\n",
      "Epoch 30/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 31/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 32/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 33/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 34/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 35/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 36/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 37/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 38/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 39/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 40/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 41/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 42/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 43/75\n",
      "4378/4378 - 74s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 74s/epoch - 17ms/step\n",
      "Epoch 44/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 45/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 46/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 47/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 48/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 49/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 50/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 51/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2015 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 52/75\n",
      "4378/4378 - 73s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 73s/epoch - 17ms/step\n",
      "Epoch 53/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1971 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 54/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 55/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 56/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 57/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 58/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 59/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 60/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 61/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 62/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 63/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 64/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 65/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1965 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 66/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0661 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 67/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 68/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 17ms/step\n",
      "Epoch 69/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 70/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 71/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 72/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 73/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 74/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1975 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "Epoch 75/75\n",
      "4378/4378 - 72s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 72s/epoch - 16ms/step\n",
      "fitting with batch size: 100\n",
      "Epoch 1/75\n",
      "876/876 - 21s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 21s/epoch - 24ms/step\n",
      "Epoch 2/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 3/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 4/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 5/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 6/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 7/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 8/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 9/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 10/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 11/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 12/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 13/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2018 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 14/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 15/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 16/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 17/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 18/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 19/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 20/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 21/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 22/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 23/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 24/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 25/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 26/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 27/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 28/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2019 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 29/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 30/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 31/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 32/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 33/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 34/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 35/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 36/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 37/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 38/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 39/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 40/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 41/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 42/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 43/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 44/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 45/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 46/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 47/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 48/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 49/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 50/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 51/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 52/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 53/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.8276 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 54/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 55/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 56/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 57/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 58/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 59/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2019 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 60/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 61/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2016 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 62/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 63/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 64/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 65/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 66/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 67/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 68/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 69/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "Epoch 70/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 71/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 72/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 73/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 74/75\n",
      "876/876 - 18s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 18s/epoch - 21ms/step\n",
      "Epoch 75/75\n",
      "876/876 - 19s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 19s/epoch - 21ms/step\n",
      "fitting with batch size: 500\n",
      "Epoch 1/75\n",
      "176/176 - 12s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 12s/epoch - 68ms/step\n",
      "Epoch 2/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 3/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 4/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 5/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0074 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 6/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 7/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1976 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 8/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 9/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 10/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 11/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 12/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 13/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 14/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 15/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2019 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 16/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 17/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 18/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 19/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 20/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 21/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 22/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1981 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 23/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 24/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 25/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 26/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1969 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 27/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 28/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1971 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 29/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 30/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2003 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 31/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1970 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 32/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 33/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1983 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 34/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 35/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2013 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 36/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 37/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1967 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 38/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 39/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2019 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 40/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 41/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1976 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 42/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 43/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 44/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 45/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 46/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 47/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 48/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 49/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 50/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1965 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 51/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2032 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 52/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 53/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 54/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 55/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 56/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 57/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0254 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 58/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 59/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 60/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 61/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 62/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2021 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 63/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 64/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2002 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 65/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 66/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 67/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 68/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2028 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 69/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1996 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 70/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 71/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2024 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 72/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 73/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 74/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "Epoch 75/75\n",
      "176/176 - 10s - loss: 0.0800 - accuracy: 0.1991 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 10s/epoch - 56ms/step\n",
      "fitting with batch size: 1500\n",
      "Epoch 1/75\n",
      "59/59 - 11s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 11s/epoch - 187ms/step\n",
      "Epoch 2/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1980 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 3/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 4/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 5/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2020 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 6/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2006 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 7/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1979 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 8/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 9/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 10/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 11/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 12/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1974 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 13/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 14/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 15/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2022 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 16/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1993 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 17/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2023 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 18/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1972 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 19/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1987 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 20/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 21/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2025 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 22/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1999 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 23/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2016 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 24/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 25/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 26/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 27/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2015 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 28/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 29/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 30/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2029 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 31/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 32/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1998 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 33/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1992 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 34/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 35/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 36/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1959 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 37/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 38/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 39/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 40/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1966 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 41/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 42/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2000 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 43/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2001 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 44/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2008 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 45/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 46/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2011 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 47/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 48/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 49/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 50/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1988 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 51/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1989 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 52/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2007 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 53/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1973 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 54/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 55/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1982 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 56/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1978 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 57/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 58/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1984 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 59/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1994 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 60/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2010 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 61/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1985 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 62/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 63/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2009 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 64/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1990 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 65/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1986 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 66/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 67/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2024 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 68/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2020 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 69/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1997 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 70/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2017 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 71/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2018 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 72/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.1995 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 73/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2004 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 152ms/step\n",
      "Epoch 74/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "Epoch 75/75\n",
      "59/59 - 9s - loss: 0.0800 - accuracy: 0.2012 - val_loss: 0.0800 - val_accuracy: 0.0735 - lr: 0.0010 - 9s/epoch - 151ms/step\n",
      "fitting with batch size: 2500\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv1d_9/Conv1D' defined at (most recent call last):\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8468\\4211327711.py\", line 21, in <cell line: 12>\n      history = model.fit(X_train, y_train,\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d_9/Conv1D'\nOOM when allocating tensor with shape[2500,32,1,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv1d_9/Conv1D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_18107927]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\F2 - Copia\\Conv1\\Augment_conv1\\Conv1_data_augm2.ipynb CÃ©lula 27\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfitting with batch size: \u001b[39m\u001b[39m{\u001b[39;00mbs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m loss_range[t], optimizer\u001b[39m=\u001b[39m optimizer_range[j], metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                         epochs\u001b[39m=\u001b[39;49mepochs_range[i], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m                         batch_size\u001b[39m=\u001b[39;49mbatch_range[n], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                         verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                         validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m                         callbacks\u001b[39m=\u001b[39;49m[lrate])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     n \u001b[39m=\u001b[39m n\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/F2%20-%20Copia/Conv1/Augment_conv1/Conv1_data_augm2.ipynb#X35sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m n\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m    \n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv1d_9/Conv1D' defined at (most recent call last):\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8468\\4211327711.py\", line 21, in <cell line: 12>\n      history = model.fit(X_train, y_train,\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d_9/Conv1D'\nOOM when allocating tensor with shape[2500,32,1,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv1d_9/Conv1D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_18107927]"
     ]
    }
   ],
   "source": [
    "#epochs = 0\n",
    "optimizer_range=[adam3]\n",
    "batch_range = [20, 100, 500, 1500, 2500]#20, 100, 500, 1500, 2500\n",
    "epochs_range= [25,50,75,100]#25,50,75,100\n",
    "loss_range=['categorical_crossentropy','binary_crossentropy','huber_loss','kullback_leibler_divergence']#'categorical_crossentropy','binary_crossentropy','huber_loss','kullback_leibler_divergence','poisson'\n",
    "n=0\n",
    "i=0\n",
    "t=0\n",
    "j=0\n",
    "#optimizer_range= [adamax,adam]\n",
    "#itertools\n",
    "for opr in optimizer_range:\n",
    "    print(f\"optimizer: {j}\")\n",
    "    for lsr in loss_range:\n",
    "        print(f\"Loss: {loss_range[t]}\")\n",
    "        for ep in epochs_range:\n",
    "            print(f\"Epoch number: {ep}\")\n",
    "            for bs in batch_range:\n",
    "                print(f\"fitting with batch size: {bs}\")\n",
    "                model.compile(loss= loss_range[t], optimizer= optimizer_range[j], metrics=['accuracy'])\n",
    "                history = model.fit(X_train, y_train, \n",
    "                                    epochs=epochs_range[i], \n",
    "                                    batch_size=batch_range[n], \n",
    "                                    verbose=2, \n",
    "                                    validation_data=(X_test, y_test), \n",
    "                                    callbacks=[lrate])\n",
    "                n = n+1\n",
    "            n=0    \n",
    "            i=i+1\n",
    "        i=0\n",
    "        t=t + 1\n",
    "t= 0\n",
    "j=0       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 9s - loss: 0.0364 - accuracy: 0.9889 - val_loss: 2.8556 - val_accuracy: 0.6855 - lr: 0.0010 - 9s/epoch - 260ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 7s - loss: 0.0402 - accuracy: 0.9876 - val_loss: 2.7909 - val_accuracy: 0.6851 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 7s - loss: 0.0367 - accuracy: 0.9888 - val_loss: 2.8062 - val_accuracy: 0.6910 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 7s - loss: 0.0372 - accuracy: 0.9885 - val_loss: 2.7817 - val_accuracy: 0.6895 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 7s - loss: 0.0349 - accuracy: 0.9890 - val_loss: 2.7713 - val_accuracy: 0.6900 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 7s - loss: 0.0369 - accuracy: 0.9884 - val_loss: 2.8256 - val_accuracy: 0.6853 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 7s - loss: 0.0347 - accuracy: 0.9890 - val_loss: 2.7374 - val_accuracy: 0.6961 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 7s - loss: 0.0361 - accuracy: 0.9891 - val_loss: 2.8371 - val_accuracy: 0.6881 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 7s - loss: 0.0361 - accuracy: 0.9890 - val_loss: 2.7808 - val_accuracy: 0.6912 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 7s - loss: 0.0388 - accuracy: 0.9882 - val_loss: 2.7581 - val_accuracy: 0.6883 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 7s - loss: 0.0369 - accuracy: 0.9887 - val_loss: 2.8612 - val_accuracy: 0.6849 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 7s - loss: 0.0357 - accuracy: 0.9888 - val_loss: 2.7276 - val_accuracy: 0.6919 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 13/100\n",
      "36/36 - 7s - loss: 0.0350 - accuracy: 0.9895 - val_loss: 2.8290 - val_accuracy: 0.6857 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 14/100\n",
      "36/36 - 7s - loss: 0.0379 - accuracy: 0.9878 - val_loss: 2.8432 - val_accuracy: 0.6888 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 15/100\n",
      "36/36 - 7s - loss: 0.0386 - accuracy: 0.9881 - val_loss: 2.8114 - val_accuracy: 0.6902 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 16/100\n",
      "36/36 - 7s - loss: 0.0381 - accuracy: 0.9884 - val_loss: 2.9069 - val_accuracy: 0.6865 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 17/100\n",
      "36/36 - 7s - loss: 0.0369 - accuracy: 0.9880 - val_loss: 2.8901 - val_accuracy: 0.6852 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 18/100\n",
      "36/36 - 7s - loss: 0.0384 - accuracy: 0.9882 - val_loss: 2.8477 - val_accuracy: 0.6871 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 19/100\n",
      "36/36 - 7s - loss: 0.0386 - accuracy: 0.9882 - val_loss: 2.8139 - val_accuracy: 0.6935 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 20/100\n",
      "36/36 - 7s - loss: 0.0395 - accuracy: 0.9883 - val_loss: 2.7711 - val_accuracy: 0.6914 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 21/100\n",
      "36/36 - 7s - loss: 0.0339 - accuracy: 0.9896 - val_loss: 2.8433 - val_accuracy: 0.6874 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 22/100\n",
      "36/36 - 7s - loss: 0.0338 - accuracy: 0.9898 - val_loss: 2.8194 - val_accuracy: 0.6898 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 23/100\n",
      "36/36 - 7s - loss: 0.0330 - accuracy: 0.9902 - val_loss: 2.7997 - val_accuracy: 0.6928 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 24/100\n",
      "36/36 - 7s - loss: 0.0313 - accuracy: 0.9902 - val_loss: 2.8814 - val_accuracy: 0.6888 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 25/100\n",
      "36/36 - 7s - loss: 0.0319 - accuracy: 0.9904 - val_loss: 2.9484 - val_accuracy: 0.6842 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 26/100\n",
      "36/36 - 7s - loss: 0.0330 - accuracy: 0.9900 - val_loss: 2.8669 - val_accuracy: 0.6868 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 27/100\n",
      "36/36 - 7s - loss: 0.0354 - accuracy: 0.9893 - val_loss: 2.8432 - val_accuracy: 0.6871 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 28/100\n",
      "36/36 - 7s - loss: 0.0348 - accuracy: 0.9899 - val_loss: 2.8429 - val_accuracy: 0.6857 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 29/100\n",
      "36/36 - 7s - loss: 0.0328 - accuracy: 0.9897 - val_loss: 2.7860 - val_accuracy: 0.6932 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 30/100\n",
      "36/36 - 7s - loss: 0.0339 - accuracy: 0.9898 - val_loss: 2.8823 - val_accuracy: 0.6857 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 31/100\n",
      "36/36 - 7s - loss: 0.0317 - accuracy: 0.9902 - val_loss: 2.9568 - val_accuracy: 0.6807 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 32/100\n",
      "36/36 - 7s - loss: 0.0323 - accuracy: 0.9905 - val_loss: 2.9500 - val_accuracy: 0.6819 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 33/100\n",
      "36/36 - 7s - loss: 0.0366 - accuracy: 0.9893 - val_loss: 2.8743 - val_accuracy: 0.6874 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 34/100\n",
      "36/36 - 7s - loss: 0.0324 - accuracy: 0.9899 - val_loss: 2.9130 - val_accuracy: 0.6887 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 35/100\n",
      "36/36 - 7s - loss: 0.0330 - accuracy: 0.9898 - val_loss: 2.9228 - val_accuracy: 0.6854 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 36/100\n",
      "36/36 - 7s - loss: 0.0334 - accuracy: 0.9896 - val_loss: 2.8276 - val_accuracy: 0.6944 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 37/100\n",
      "36/36 - 7s - loss: 0.0328 - accuracy: 0.9901 - val_loss: 2.9109 - val_accuracy: 0.6860 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 38/100\n",
      "36/36 - 7s - loss: 0.0342 - accuracy: 0.9894 - val_loss: 2.9558 - val_accuracy: 0.6822 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 39/100\n",
      "36/36 - 7s - loss: 0.0341 - accuracy: 0.9897 - val_loss: 2.9156 - val_accuracy: 0.6852 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 40/100\n",
      "36/36 - 7s - loss: 0.0400 - accuracy: 0.9878 - val_loss: 2.8203 - val_accuracy: 0.6890 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 41/100\n",
      "36/36 - 7s - loss: 0.0345 - accuracy: 0.9891 - val_loss: 2.8679 - val_accuracy: 0.6866 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 42/100\n",
      "36/36 - 7s - loss: 0.0333 - accuracy: 0.9899 - val_loss: 2.9295 - val_accuracy: 0.6853 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 43/100\n",
      "36/36 - 7s - loss: 0.0334 - accuracy: 0.9899 - val_loss: 2.8938 - val_accuracy: 0.6877 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 44/100\n",
      "36/36 - 7s - loss: 0.0348 - accuracy: 0.9891 - val_loss: 2.9274 - val_accuracy: 0.6868 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 45/100\n",
      "36/36 - 7s - loss: 0.0332 - accuracy: 0.9899 - val_loss: 2.9358 - val_accuracy: 0.6881 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 46/100\n",
      "36/36 - 7s - loss: 0.0317 - accuracy: 0.9903 - val_loss: 2.9549 - val_accuracy: 0.6854 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 47/100\n",
      "36/36 - 7s - loss: 0.0330 - accuracy: 0.9901 - val_loss: 2.9252 - val_accuracy: 0.6886 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 48/100\n",
      "36/36 - 7s - loss: 0.0312 - accuracy: 0.9908 - val_loss: 3.0117 - val_accuracy: 0.6856 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 49/100\n",
      "36/36 - 7s - loss: 0.0359 - accuracy: 0.9896 - val_loss: 2.9053 - val_accuracy: 0.6900 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 50/100\n",
      "36/36 - 7s - loss: 0.0370 - accuracy: 0.9884 - val_loss: 2.9421 - val_accuracy: 0.6916 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 51/100\n",
      "36/36 - 7s - loss: 0.0338 - accuracy: 0.9900 - val_loss: 2.8954 - val_accuracy: 0.6903 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 52/100\n",
      "36/36 - 7s - loss: 0.0351 - accuracy: 0.9890 - val_loss: 2.9026 - val_accuracy: 0.6900 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 53/100\n",
      "36/36 - 7s - loss: 0.0333 - accuracy: 0.9900 - val_loss: 2.9094 - val_accuracy: 0.6900 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 54/100\n",
      "36/36 - 7s - loss: 0.0318 - accuracy: 0.9901 - val_loss: 2.8890 - val_accuracy: 0.6913 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 55/100\n",
      "36/36 - 7s - loss: 0.0343 - accuracy: 0.9893 - val_loss: 2.8815 - val_accuracy: 0.6919 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 56/100\n",
      "36/36 - 7s - loss: 0.0337 - accuracy: 0.9895 - val_loss: 2.8580 - val_accuracy: 0.6916 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 57/100\n",
      "36/36 - 7s - loss: 0.0343 - accuracy: 0.9896 - val_loss: 2.9268 - val_accuracy: 0.6871 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 58/100\n",
      "36/36 - 7s - loss: 0.0326 - accuracy: 0.9902 - val_loss: 2.8575 - val_accuracy: 0.6935 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 59/100\n",
      "36/36 - 7s - loss: 0.0364 - accuracy: 0.9885 - val_loss: 2.9108 - val_accuracy: 0.6895 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 60/100\n",
      "36/36 - 7s - loss: 0.0328 - accuracy: 0.9897 - val_loss: 2.8892 - val_accuracy: 0.6894 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 61/100\n",
      "36/36 - 7s - loss: 0.0306 - accuracy: 0.9905 - val_loss: 2.9390 - val_accuracy: 0.6844 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 62/100\n",
      "36/36 - 7s - loss: 0.0325 - accuracy: 0.9901 - val_loss: 2.8750 - val_accuracy: 0.6887 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 63/100\n",
      "36/36 - 7s - loss: 0.0325 - accuracy: 0.9898 - val_loss: 2.8946 - val_accuracy: 0.6871 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 64/100\n",
      "36/36 - 7s - loss: 0.0323 - accuracy: 0.9902 - val_loss: 2.8467 - val_accuracy: 0.6928 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 65/100\n",
      "36/36 - 7s - loss: 0.0329 - accuracy: 0.9902 - val_loss: 2.9066 - val_accuracy: 0.6903 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 66/100\n",
      "36/36 - 7s - loss: 0.0301 - accuracy: 0.9909 - val_loss: 2.8780 - val_accuracy: 0.6929 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 67/100\n",
      "36/36 - 7s - loss: 0.0312 - accuracy: 0.9906 - val_loss: 2.8699 - val_accuracy: 0.6950 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 68/100\n",
      "36/36 - 7s - loss: 0.0333 - accuracy: 0.9898 - val_loss: 2.9052 - val_accuracy: 0.6873 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 69/100\n",
      "36/36 - 7s - loss: 0.0320 - accuracy: 0.9904 - val_loss: 2.9199 - val_accuracy: 0.6896 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 70/100\n",
      "36/36 - 7s - loss: 0.0310 - accuracy: 0.9907 - val_loss: 2.9283 - val_accuracy: 0.6931 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 71/100\n",
      "36/36 - 7s - loss: 0.0336 - accuracy: 0.9897 - val_loss: 2.9571 - val_accuracy: 0.6906 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 72/100\n",
      "36/36 - 7s - loss: 0.0325 - accuracy: 0.9905 - val_loss: 2.9623 - val_accuracy: 0.6889 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 73/100\n",
      "36/36 - 7s - loss: 0.0321 - accuracy: 0.9902 - val_loss: 2.9932 - val_accuracy: 0.6861 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 74/100\n",
      "36/36 - 7s - loss: 0.0308 - accuracy: 0.9904 - val_loss: 2.9556 - val_accuracy: 0.6837 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 75/100\n",
      "36/36 - 7s - loss: 0.0328 - accuracy: 0.9899 - val_loss: 2.9767 - val_accuracy: 0.6833 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 76/100\n",
      "36/36 - 7s - loss: 0.0323 - accuracy: 0.9899 - val_loss: 2.9534 - val_accuracy: 0.6881 - lr: 0.0010 - 7s/epoch - 202ms/step\n",
      "Epoch 77/100\n",
      "36/36 - 7s - loss: 0.0352 - accuracy: 0.9892 - val_loss: 2.9023 - val_accuracy: 0.6904 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 78/100\n",
      "36/36 - 7s - loss: 0.0367 - accuracy: 0.9888 - val_loss: 2.8458 - val_accuracy: 0.6878 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 79/100\n",
      "36/36 - 7s - loss: 0.0323 - accuracy: 0.9900 - val_loss: 2.9247 - val_accuracy: 0.6897 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 80/100\n",
      "36/36 - 7s - loss: 0.0322 - accuracy: 0.9906 - val_loss: 2.8919 - val_accuracy: 0.6929 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 81/100\n",
      "36/36 - 7s - loss: 0.0365 - accuracy: 0.9888 - val_loss: 2.7752 - val_accuracy: 0.6969 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 82/100\n",
      "36/36 - 7s - loss: 0.0340 - accuracy: 0.9895 - val_loss: 2.8902 - val_accuracy: 0.6863 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 83/100\n",
      "36/36 - 7s - loss: 0.0321 - accuracy: 0.9902 - val_loss: 2.8844 - val_accuracy: 0.6913 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 84/100\n",
      "36/36 - 7s - loss: 0.0311 - accuracy: 0.9902 - val_loss: 2.9061 - val_accuracy: 0.6891 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 85/100\n",
      "36/36 - 7s - loss: 0.0315 - accuracy: 0.9905 - val_loss: 2.9035 - val_accuracy: 0.6882 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 86/100\n",
      "36/36 - 7s - loss: 0.0345 - accuracy: 0.9895 - val_loss: 2.8783 - val_accuracy: 0.6908 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 87/100\n",
      "36/36 - 7s - loss: 0.0320 - accuracy: 0.9904 - val_loss: 2.9011 - val_accuracy: 0.6916 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 88/100\n",
      "36/36 - 7s - loss: 0.0342 - accuracy: 0.9896 - val_loss: 2.9204 - val_accuracy: 0.6895 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 89/100\n",
      "36/36 - 7s - loss: 0.0338 - accuracy: 0.9894 - val_loss: 2.9152 - val_accuracy: 0.6895 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 90/100\n",
      "36/36 - 7s - loss: 0.0369 - accuracy: 0.9889 - val_loss: 2.8231 - val_accuracy: 0.6900 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 91/100\n",
      "36/36 - 7s - loss: 0.0421 - accuracy: 0.9872 - val_loss: 2.9248 - val_accuracy: 0.6877 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 92/100\n",
      "36/36 - 7s - loss: 0.0335 - accuracy: 0.9895 - val_loss: 3.0019 - val_accuracy: 0.6821 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 93/100\n",
      "36/36 - 7s - loss: 0.0340 - accuracy: 0.9896 - val_loss: 2.9680 - val_accuracy: 0.6842 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 94/100\n",
      "36/36 - 7s - loss: 0.0336 - accuracy: 0.9899 - val_loss: 3.0168 - val_accuracy: 0.6833 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 95/100\n",
      "36/36 - 7s - loss: 0.0334 - accuracy: 0.9897 - val_loss: 2.9170 - val_accuracy: 0.6910 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 96/100\n",
      "36/36 - 7s - loss: 0.0316 - accuracy: 0.9904 - val_loss: 2.9630 - val_accuracy: 0.6872 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 97/100\n",
      "36/36 - 7s - loss: 0.0323 - accuracy: 0.9904 - val_loss: 2.9663 - val_accuracy: 0.6897 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 98/100\n",
      "36/36 - 7s - loss: 0.0340 - accuracy: 0.9897 - val_loss: 2.9590 - val_accuracy: 0.6918 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 99/100\n",
      "36/36 - 7s - loss: 0.0355 - accuracy: 0.9888 - val_loss: 3.0074 - val_accuracy: 0.6813 - lr: 0.0010 - 7s/epoch - 201ms/step\n",
      "Epoch 100/100\n",
      "36/36 - 7s - loss: 0.0335 - accuracy: 0.9900 - val_loss: 3.0233 - val_accuracy: 0.6841 - lr: 0.0010 - 7s/epoch - 201ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss= 'categorical_crossentropy', optimizer= adam, metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, \n",
    "                                epochs=100, \n",
    "                                batch_size=2500, \n",
    "                                verbose=2, \n",
    "                                validation_data=(X_test, y_test), \n",
    "                                callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d43023d26a87e3c4702b96bea5962c990c76aa0a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, batch_size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20cfe7f5891e3c26c599fa4cd728ac0a499ac70e",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78     18118\n",
      "           1       0.17      0.67      0.27       556\n",
      "           2       0.33      0.87      0.47      1448\n",
      "           3       0.07      0.80      0.14       162\n",
      "           4       0.69      0.90      0.78      1608\n",
      "\n",
      "    accuracy                           0.68     21892\n",
      "   macro avg       0.45      0.78      0.49     21892\n",
      "weighted avg       0.89      0.68      0.74     21892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "017f2431a45766fb0d4b2ef17ce613c1142ca085",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking-based average precision : 0.806\n",
      "Ranking loss : 0.143\n",
      "Coverage_error : 1.574\n"
     ]
    }
   ],
   "source": [
    "print(\"ranking-based average precision : {:.3f}\".format(label_ranking_average_precision_score(y_test, y_pred)))\n",
    "print(\"Ranking loss : {:.3f}\".format(label_ranking_loss(y_test, y_pred)))\n",
    "print(\"Coverage_error : {:.3f}\".format(coverage_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],normalize=True,\n",
    "                      title='Confusion matrix, with normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "RECALL = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "SPECIFICITY = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PRECISION = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "#F1-score\n",
    "F1 = 2*((RECALL*PRECISION)/(RECALL+PRECISION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 19ms/step - loss: 3.0233 - accuracy: 0.6841\n",
      "44/44 [==============================] - 1s 17ms/step - loss: 0.1745 - accuracy: 1.0000\n",
      "Accuracy: 302.33%\n",
      "Accuracy: 68.41%\n",
      "Precision: 44.80%\n",
      "Specificity: 92.47%\n",
      "Recall :77.52%\n",
      "F1-Score :48.78%\n",
      "Recall:77.52%\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median\n",
    "from tkinter import N\n",
    "scores = model.evaluate((X_test), y_test, batch_size = 500)\n",
    "scores2 = model.evaluate(X_test, y_pred, batch_size = 500)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[0]*100))\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "PRE = mean(PRECISION)\n",
    "print(\"Precision: %.2f%%\"% (PRE*100))\n",
    "#print(\"Precision: \", PRECISION)\n",
    "SPE = mean(SPECIFICITY)\n",
    "print(\"Specificity: %.2f%%\"% (SPE*100))\n",
    "#print(\"Specificity\", SPECIFICITY)\n",
    "RE = mean(RECALL)\n",
    "print(\"Recall :%.2f%%\"% (RE*100))\n",
    "#print(\"Recall\", RECALL)\n",
    "#print(\"F1: \", F1)\n",
    "F1S = mean(F1)\n",
    "print(\"F1-Score :%.2f%%\"% (F1S*100))\n",
    "Z= mean(1-FNR)*100\n",
    "print(\"Recall:%.2f%%\"%Z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e06ff7da33dc9620448857a90ad8b5f428f0d573d205a934d2841c8aee45ea32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
